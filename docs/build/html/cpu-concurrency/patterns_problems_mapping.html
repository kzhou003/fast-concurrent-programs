

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Why Different Approaches for CPU-bound vs I/O-bound Problems? &mdash; Triton GPU Programming Guide 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="GPU Fundamentals" href="../gpu-concepts/gpu-fundamentals.html" />
    <link rel="prev" title="Semaphore Explained" href="semaphore_explained.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Triton GPU Programming Guide
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">CPU Concurrency</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="key_concepts.html">Key Concepts in Concurrent Programming</a><ul>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html#id1">Concurrency vs Parallelism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#concurrency">Concurrency</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#parallelism">Parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#visual-comparison">Visual Comparison</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html#id2">Threading vs Multiprocessing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#threading-concurrent-futures-threadpoolexecutor">Threading (concurrent.futures.ThreadPoolExecutor)</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#multiprocessing-concurrent-futures-processpoolexecutor">Multiprocessing (concurrent.futures.ProcessPoolExecutor)</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#when-to-use-what">When to Use What</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html#id3">The Global Interpreter Lock (GIL)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#what-is-the-gil">What is the GIL?</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#key-points">Key Points:</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#impact-on-performance">Impact on Performance:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="key_concepts.html#with-gil-threads-don-t-help-cpu-bound-tasks">With GIL, threads don’t help CPU-bound tasks:</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_concepts.html#gil-is-released-during-i-o-so-threading-helps">GIL is released during I/O, so threading helps:</a><ul>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html#id4">Asyncio and Event Loops</a><ul>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#event-loop">Event Loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#how-it-works-from-script-07">How It Works (from script 07):</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#event-loop-lifecycle">Event Loop Lifecycle:</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#modern-vs-old-patterns">Modern vs Old Patterns:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html#id5">Coroutines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#what-are-coroutines">What are Coroutines?</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#defining-coroutines">Defining Coroutines:</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#key-features">Key Features:</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#example-from-script-08">Example from Script 08:</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#execution-flow">Execution Flow:</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#important-rules">Important Rules:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html#id6">Tasks and Futures</a><ul>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#tasks">Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#task-characteristics">Task Characteristics:</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#example-from-script-09">Example from Script 09:</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#futures">Futures</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#waiting-for-multiple-tasks">Waiting for Multiple Tasks:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html#id9">CPU-bound vs I/O-bound Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#cpu-bound-operations">CPU-bound Operations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="key_concepts.html#use-processpoolexecutor-for-cpu-bound-tasks">Use ProcessPoolExecutor for CPU-bound tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_concepts.html#combine-approaches">Combine approaches:</a><ul>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html#id10">Python 3.12 Migration Changes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#time-measurement-time-clock-time-perf-counter">1. Time Measurement (<code class="docutils literal notranslate"><span class="pre">time.clock()</span></code> → <code class="docutils literal notranslate"><span class="pre">time.perf*counter()</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#coroutine-syntax-asyncio-coroutine-async-def">2. Coroutine Syntax (<code class="docutils literal notranslate"><span class="pre">&#64;asyncio.coroutine</span></code> → <code class="docutils literal notranslate"><span class="pre">async</span> <span class="pre">def</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#task-creation-asyncio-task-asyncio-create-task">3. Task Creation (<code class="docutils literal notranslate"><span class="pre">asyncio.Task()</span></code> → <code class="docutils literal notranslate"><span class="pre">asyncio.create*task()</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#event-loop-management">4. Event Loop Management</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#future-callbacks-callbacks-await">5. Future Callbacks (Callbacks → <code class="docutils literal notranslate"><span class="pre">await</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#blocking-calls-in-async-code">6. Blocking Calls in Async Code</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#string-formatting-f-strings">7. String Formatting (<code class="docutils literal notranslate"><span class="pre">%</span></code> → f-strings)</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#migration-checklist">Migration Checklist</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#compatibility">Compatibility</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html#summary">Summary</a><ul>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#quick-reference-guide">Quick Reference Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l3"><a class="reference internal" href="key_concepts.html#further-reading">Further Reading</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html">Hardware Parallelism: Cores, Hyperthreading, and GPUs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hardware_parallelism.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="hardware_parallelism.html#id1">Physical Cores vs Logical Cores</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#physical-cores">Physical Cores</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#logical-cores">Logical Cores</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#check-on-your-system">Check on your system</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hardware_parallelism.html#id2">What is Hyperthreading?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#the-concept">The Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#how-it-works">How It Works</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#technical-implementation">Technical Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#performance-characteristics">Performance Characteristics</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#hyperthreading-limitations">Hyperthreading Limitations</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#checking-hyperthreading-status">Checking Hyperthreading Status</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#check-if-ht-is-enabled">Check if HT is enabled</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#or-check-cpu-info">Or check CPU info</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#id3">Logical cores</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#id4">Physical cores</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#if-logical-physical-ht-is-enabled">If logical &gt; physical, HT is enabled</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#platform-specific-physical-core-detection">Platform-specific physical core detection</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hardware_parallelism.html#id5">How Threading is Bounded by Physical Cores</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#the-fundamental-constraint">The Fundamental Constraint</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#why-more-threads-more-speed">Why More Threads ≠ More Speed</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#benchmark-computing-sum-of-squares">Benchmark: Computing sum of squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#results-on-4-core-cpu">Results on 4-core CPU:</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#worker-10-0s-baseline">1 worker:  10.0s  (baseline)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#workers-5-1s-1-96x-speedup">2 workers:  5.1s  (1.96x speedup) ✅</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#workers-2-6s-3-85x-speedup">4 workers:  2.6s  (3.85x speedup) ✅</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#workers-2-8s-3-57x-speedup-worse-than-4">8 workers:  2.8s  (3.57x speedup) ⚠️ (worse than 4!)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#workers-3-2s-3-13x-speedup-much-worse">16 workers: 3.2s  (3.13x speedup) ❌ (much worse!)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#best-practice">Best practice:</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#conservative-recommended-for-production">Conservative (recommended for production):</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#or-detect-actual-physical-cores">Or detect actual physical cores:</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#matrix-multiplication-cpu-intensive">Matrix multiplication (CPU-intensive)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#test-on-4-core-cpu">Test on 4-core CPU:</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#typical-output">Typical output:</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#workers-time-speedup-efficiency">Workers | Time  | Speedup | Efficiency</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#id10">——–|-------|———|————</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hardware_parallelism.html#id11">Why GPUs Excel at Parallel Computing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#cpu-vs-gpu-different-design-philosophies">CPU vs GPU: Different Design Philosophies</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#key-differences">Key Differences</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#simd-and-gpu-architecture">SIMD and GPU Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#why-gpus-excel-at-compute-intensive-tasks">Why GPUs Excel at Compute-Intensive Tasks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hardware_parallelism.html#massive-parallelism">1. Massive Parallelism</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#cpu-approach-4-cores">CPU approach (4 cores):</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#split-into-4-chunks-of-250-000-each">Split into 4 chunks of 250,000 each</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#each-core-processes-250-000-additions-sequentially">Each core processes 250,000 additions sequentially</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#gpu-approach-16-384-cores">GPU approach (16,384 cores):</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#split-into-16-384-chunks-of-61-each">Split into 16,384 chunks of ~61 each</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#each-core-processes-61-additions">Each core processes ~61 additions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hardware_parallelism.html#id12">CPU vs GPU Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#silicon-real-estate-comparison">Silicon Real Estate Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#performance-comparison">Performance Comparison</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#generate-random-matrices">Generate random matrices</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#cpu-numpy-with-optimized-blas">CPU (NumPy with optimized BLAS)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#gpu-using-cupy-cuda-arrays">GPU (using CuPy - CUDA arrays)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#typical-results">Typical results:</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#cpu-time-0-850s-intel-i9-8-cores">CPU time: 0.850s (Intel i9, 8 cores)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#gpu-time-0-012s-nvidia-rtx-4090">GPU time: 0.012s (NVIDIA RTX 4090)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#speedup-70-8x">Speedup: 70.8x</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hardware_parallelism.html#id13">When to Use What</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#decision-matrix">Decision Matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#practical-guidelines">Practical Guidelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hardware_parallelism.html#use-cpu-when">Use CPU When:</a></li>
<li class="toctree-l4"><a class="reference internal" href="hardware_parallelism.html#use-gpu-when">Use GPU When:</a></li>
<li class="toctree-l4"><a class="reference internal" href="hardware_parallelism.html#use-hyperthreading-when">Use Hyperthreading When:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="hardware_parallelism.html#id14">Practical Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#example-1-image-processing">Example 1: Image Processing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#task-apply-gaussian-blur-to-100-images-4k-resolution">Task: Apply Gaussian blur to 100 images (4K resolution)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#approach-1-sequential-cpu-1-core">Approach 1: Sequential (CPU, 1 core)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#time-300-seconds">Time: ~300 seconds</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#approach-2-cpu-multiprocessing-4-physical-cores">Approach 2: CPU Multiprocessing (4 physical cores)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#time-80-seconds-3-75x-speedup">Time: ~80 seconds (3.75x speedup)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#approach-3-gpu-cuda">Approach 3: GPU (CUDA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#time-4-seconds-75x-speedup">Time: ~4 seconds (75x speedup!)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#task-estimate-using-monte-carlo-1-billion-points">Task: Estimate π using Monte Carlo (1 billion points)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#sequential-cpu">Sequential CPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#cpu-multiprocessing-4-cores">CPU Multiprocessing (4 cores)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#gpu-cuda">GPU (CUDA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#task-train-a-neural-network-on-mnist-dataset">Task: Train a neural network on MNIST dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#define-simple-network">Define simple network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#cpu-training">CPU Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware_parallelism.html#gpu-training">GPU Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hardware_parallelism.html#summary">Summary</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#core-principles">Core Principles</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#quick-reference">Quick Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware_parallelism.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html">Threading Basics: start() and join()</a><ul>
<li class="toctree-l2"><a class="reference internal" href="threading_basics.html#what-is-start">What is start()?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="threading_basics.html#key-points-about-start">Key Points About start()</a></li>
<li class="toctree-l3"><a class="reference internal" href="threading_basics.html#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#create-thread-object-doesn-t-start-yet">Create thread object (doesn’t start yet)</a></li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#call-start-to-actually-begin-execution">Call start() to actually begin execution</a><ul>
<li class="toctree-l2"><a class="reference internal" href="threading_basics.html#what-is-join">What is join()?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="threading_basics.html#key-points-about-join">Key Points About join()</a></li>
<li class="toctree-l3"><a class="reference internal" href="threading_basics.html#id1">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="threading_basics.html#comparison-with-vs-without-join">Comparison: With vs Without join()</a><ul>
<li class="toctree-l3"><a class="reference internal" href="threading_basics.html#without-join-danger">WITHOUT join() - DANGER!</a></li>
<li class="toctree-l3"><a class="reference internal" href="threading_basics.html#with-join-correct">WITH join() - CORRECT!</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="threading_basics.html#thread-lifecycle-diagram">Thread Lifecycle Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="threading_basics.html#typical-pattern-for-multiple-threads">Typical Pattern for Multiple Threads</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#step-1-create-all-threads">Step 1: Create all threads</a></li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#step-2-wait-for-all-to-finish">Step 2: Wait for all to finish</a><ul>
<li class="toctree-l2"><a class="reference internal" href="threading_basics.html#common-mistakes">Common Mistakes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="threading_basics.html#mistake-1-calling-the-function-directly-instead-of-start">Mistake 1: Calling the function directly instead of start()</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#wrong-runs-worker-in-main-thread">❌ WRONG - runs worker in MAIN thread</a></li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#correct-runs-worker-in-new-thread">✅ CORRECT - runs worker in NEW thread</a></li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#wrong-main-exits-before-worker-finishes">❌ WRONG - main exits before worker finishes</a></li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#correct-wait-for-worker-to-finish">✅ CORRECT - wait for worker to finish</a></li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#not-safe-race-condition">❌ NOT SAFE - race condition</a></li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#safe-use-lock">✅ SAFE - use lock</a><ul>
<li class="toctree-l2"><a class="reference internal" href="threading_basics.html#practical-example-web-scraper">Practical Example: Web Scraper</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#urls-to-fetch">URLs to fetch</a></li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#create-and-start-threads">Create and start threads</a></li>
<li class="toctree-l1"><a class="reference internal" href="threading_basics.html#wait-for-all-to-complete">Wait for all to complete</a><ul>
<li class="toctree-l2"><a class="reference internal" href="threading_basics.html#summary-table">Summary Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="threading_basics.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="asyncio_event_loop.html">Asyncio Event Loop</a><ul>
<li class="toctree-l2"><a class="reference internal" href="asyncio_event_loop.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_event_loop.html#file-location">File Location</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_event_loop.html#key-concepts">Key Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_event_loop.html#id1">Asyncio Event Loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_event_loop.html#async-await-pattern">Async/Await Pattern</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_event_loop.html#code-breakdown">Code Breakdown</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_event_loop.html#task-functions">Task Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_event_loop.html#main-function">Main Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_event_loop.html#entry-point">Entry Point</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_event_loop.html#python-3-12-updates">Python 3.12 Updates</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_event_loop.html#changes-made">Changes Made</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_event_loop.html#execution-flow">Execution Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_event_loop.html#usage">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_event_loop.html#output-example">Output Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_event_loop.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="asyncio_coroutine.html">Asyncio Coroutine - Finite State Machine</a><ul>
<li class="toctree-l2"><a class="reference internal" href="asyncio_coroutine.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_coroutine.html#file-location">File Location</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_coroutine.html#key-concepts">Key Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_coroutine.html#finite-state-machine-fsm">Finite State Machine (FSM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_coroutine.html#coroutines">Coroutines</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_coroutine.html#state-transitions">State Transitions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_coroutine.html#code-breakdown">Code Breakdown</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_coroutine.html#state-machine-structure">State Machine Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_coroutine.html#start-state">Start State</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_coroutine.html#intermediate-states-state-1-2-3">Intermediate States (State 1, 2, 3)</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_coroutine.html#end-state">End State</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_coroutine.html#python-3-12-updates">Python 3.12 Updates</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_coroutine.html#changes-made">Changes Made</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_coroutine.html#execution-flow-example">Execution Flow Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_coroutine.html#usage">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_coroutine.html#output-example">Output Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_coroutine.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_coroutine.html#use-cases">Use Cases</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="asyncio_and_futures.html">Asyncio and Futures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#file-location">File Location</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#key-concepts">Key Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#command-line-arguments">Command-Line Arguments</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#async-task-results">Async Task Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#concurrent-computation">Concurrent Computation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#code-breakdown">Code Breakdown</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#first-coroutine-sum-of-n-integers">First Coroutine - Sum of N Integers</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#second-coroutine-factorial">Second Coroutine - Factorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#main-function">Main Function</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#python-3-12-updates">Python 3.12 Updates</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#changes-made">Changes Made</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#before-vs-after-comparison">Before vs After Comparison</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#old-pattern-deprecated">Old Pattern (Deprecated)</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#new-pattern-modern">New Pattern (Modern)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#execution-flow">Execution Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#usage">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#examples">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#example-1">Example 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_and_futures.html#example-2">Example 2</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#performance">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#modern-best-practices">Modern Best Practices</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#when-to-use-this-pattern">When to Use This Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_and_futures.html#capturing-results">Capturing Results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="asyncio_task_manipulation.html">Asyncio Task Manipulation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#file-location">File Location</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#key-concepts">Key Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_task_manipulation.html#asyncio-tasks">Asyncio Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_task_manipulation.html#concurrent-execution">Concurrent Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_task_manipulation.html#asyncio-gather">asyncio.gather()</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#code-breakdown">Code Breakdown</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_task_manipulation.html#factorial-computation">Factorial Computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_task_manipulation.html#fibonacci-computation">Fibonacci Computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_task_manipulation.html#binomial-coefficient-computation">Binomial Coefficient Computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="asyncio_task_manipulation.html#main-function">Main Function</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#python-3-12-updates">Python 3.12 Updates</a><ul>
<li class="toctree-l3"><a class="reference internal" href="asyncio_task_manipulation.html#changes-made">Changes Made</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#execution-flow">Execution Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#concurrency-vs-parallelism">Concurrency vs Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#usage">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#output-example">Output Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#performance">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l2"><a class="reference internal" href="asyncio_task_manipulation.html#when-to-use">When to Use</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="concurrent_futures_pooling.html">Concurrent Futures Pooling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="concurrent_futures_pooling.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="concurrent_futures_pooling.html#file-location">File Location</a></li>
<li class="toctree-l2"><a class="reference internal" href="concurrent_futures_pooling.html#key-concepts">Key Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="concurrent_futures_pooling.html#executor-pattern">Executor Pattern</a></li>
<li class="toctree-l3"><a class="reference internal" href="concurrent_futures_pooling.html#execution-models">Execution Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="concurrent_futures_pooling.html#code-breakdown">Code Breakdown</a><ul>
<li class="toctree-l3"><a class="reference internal" href="concurrent_futures_pooling.html#cpu-intensive-task">CPU-Intensive Task</a></li>
<li class="toctree-l3"><a class="reference internal" href="concurrent_futures_pooling.html#evaluation-function">Evaluation Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="concurrent_futures_pooling.html#sequential-execution">Sequential Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="concurrent_futures_pooling.html#thread-pool-execution">Thread Pool Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="concurrent_futures_pooling.html#process-pool-execution">Process Pool Execution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="concurrent_futures_pooling.html#performance-expectations">Performance Expectations</a></li>
<li class="toctree-l2"><a class="reference internal" href="concurrent_futures_pooling.html#python-3-12-updates">Python 3.12 Updates</a><ul>
<li class="toctree-l3"><a class="reference internal" href="concurrent_futures_pooling.html#changes-made">Changes Made</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="concurrent_futures_pooling.html#usage">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="concurrent_futures_pooling.html#output-example">Output Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="concurrent_futures_pooling.html#when-to-use-each-approach">When to Use Each Approach</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html">Queue Explained: Thread-Safe Data Structure &amp; Locking</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#what-is-a-queue">What is a Queue?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_explained.html#key-concept">Key Concept</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#how-queue-works-internally">How Queue Works Internally</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_explained.html#internal-structure">Internal Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="queue_explained.html#automatic-locking">Automatic Locking</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#queue-operations">Queue Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_explained.html#put-item"><code class="docutils literal notranslate"><span class="pre">put(item)</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#why-queue-is-best-practice">Why Queue is Best Practice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_explained.html#problem-with-manual-locks">Problem with Manual Locks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#problems">Problems:</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#easy-to-forget-lock-somewhere">1. Easy to forget lock somewhere</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#busy-waiting-wastes-cpu">2. Busy-waiting wastes CPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#no-synchronization-between-threads">3. No synchronization between threads</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#race-conditions-possible">4. Race conditions possible</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#benefits">Benefits:</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#synchronization-automatic">1. Synchronization automatic</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#no-busy-waiting">2. No busy-waiting</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#blocks-correctly-when-empty-full">3. Blocks correctly when empty/full</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#task-tracking-with-task-done">4. Task tracking with task*done()</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#queue-as-locking-mechanism">Queue as Locking Mechanism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_explained.html#how-queue-does-locking">How Queue Does Locking</a></li>
<li class="toctree-l3"><a class="reference internal" href="queue_explained.html#locking-benefits">Locking Benefits</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#the-code-explained-producer-consumer">The Code Explained: Producer-Consumer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#create-queue">Create queue</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#create-threads">Create threads</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#start-all">Start all</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#queue-vs-lock-vs-semaphore-vs-rlock">Queue vs Lock vs Semaphore vs RLock</a></li>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#queue-benefits-summary">Queue Benefits Summary</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_explained.html#thread-safe-data-structure">1. <strong>Thread-Safe Data Structure</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#without-queue-need-to-manage-locking">Without Queue - Need to manage locking</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#with-queue-automatic">With Queue - Automatic</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#without-queue-need-condition-variables">Without Queue - Need condition variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#with-queue-blocks-automatically">With Queue - Blocks automatically</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#bad-busy-wait-wastes-cpu">Bad - Busy-wait (wastes CPU)</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#good-queue-blocks-efficiently">Good - Queue blocks efficiently</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#process-items">Process items</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#multiple-producers">Multiple producers</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#multiple-consumers">Multiple consumers</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#all-safe-queue-handles-synchronization">All safe! Queue handles synchronization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#internal-queue-locking-mechanism">Internal Queue Locking Mechanism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_explained.html#step-by-step-what-happens-in-put">Step-by-Step: What Happens in <code class="docutils literal notranslate"><span class="pre">put()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#internally-in-queue">Internally in Queue:</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#acquire-mutex-lock">1. Acquire mutex (lock)</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#check-if-full">2. Check if full</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#notify-consumers">4. Notify consumers</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#release-mutex">5. Release mutex</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#id7">Internally in Queue:</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#id8">1. Acquire mutex (lock)</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#check-if-empty">2. Check if empty</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#notify-producers">4. Notify producers</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#id9">5. Release mutex</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#why-queue-is-safer-than-manual-locking">Why Queue is Safer Than Manual Locking</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_explained.html#mistake-1-forgetting-lock">Mistake 1: Forgetting Lock</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#wrong-no-lock-on-append">❌ WRONG - No lock on append</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#correct-queue-is-always-locked">✅ CORRECT - Queue is always locked</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#wrong-wastes-cpu">❌ WRONG - Wastes CPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#correct-queue-blocks-efficiently">✅ CORRECT - Queue blocks efficiently</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#wrong-check-and-pop-not-atomic">❌ WRONG - Check and pop not atomic</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#correct-queue-makes-check-and-pop-atomic">✅ CORRECT - Queue makes check and pop atomic</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#practical-example-work-queue">Practical Example: Work Queue</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#create-workers">Create workers</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#add-tasks">Add tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#wait-for-all-tasks-to-be-processed">Wait for all tasks to be processed</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_explained.html#stop-workers">Stop workers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_explained.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html">Queue Internal Mechanics: Condition Variables &amp; Events</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#the-answer">The Answer</a></li>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#queue-s-internal-structure">Queue’s Internal Structure</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#inside-the-queue-object">Inside the Queue object:</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#id1">┌─────────────────────────────────────────┐</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#queue-internal-state">│ Queue Internal State                    │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#id2">├─────────────────────────────────────────┤</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#mutex-lock">│ mutex: Lock()                           │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#protects-all-modifications">│   - Protects all modifications          │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#id3">│                                         │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#not-empty-condition">│ not*empty: Condition()                  │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#signals-when-items-added">│   - Signals when items added            │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#consumers-wait-on-this">│   - Consumers wait on this              │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#id4">│                                         │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#not-full-condition">│ not*full: Condition()                   │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#signals-when-items-removed">│   - Signals when items removed          │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#producers-wait-on-this">│   - Producers wait on this              │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#id5">│                                         │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#items">│ items: []                               │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#actual-items-without-conditions">│   - Actual items (without conditions)   │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#id6">│                                         │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#task-counter-0">│ task*counter: 0                         │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#tracks-unfinished-tasks">│   - Tracks unfinished tasks             │</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#id7">└─────────────────────────────────────────┘</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#when-you-put-an-item">When you put an item</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#inside-queue">Inside queue:</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#items-42-just-the-number-no-condition-attached">items = [42]  ← Just the number, no condition attached</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#not-empty-condition-wakes-up-consumers">not*empty condition wakes up consumers</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#not-full-condition-might-wake-up-producers">not*full condition might wake up producers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#how-conditions-work-in-queue">How Conditions Work in Queue</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#condition-variables-explained">Condition Variables Explained</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#put-what-actually-happens">put() - What Actually Happens</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#step-by-step-execution">Step-by-Step Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#timeline-put-with-condition-variable">Timeline: put() with Condition Variable</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#get-what-actually-happens">get() - What Actually Happens</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#id8">Step-by-Step Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#timeline-get-with-condition-variable">Timeline: get() with Condition Variable</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#visual-no-condition-on-items">Visual: No Condition On Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#complete-put-and-get-timeline">Complete put() and get() Timeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#scenario-queue-with-maxsize-2-multiple-producers-consumers">Scenario: Queue with maxsize=2, multiple producers/consumers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#key-insight-conditions-are-on-queue-not-items">Key Insight: Conditions Are On Queue, Not Items</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#what-people-might-think-wrong">What People Might Think (WRONG):</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#wrong-mental-model">❌ WRONG MENTAL MODEL</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#correct-mental-model">✓ CORRECT MENTAL MODEL</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#why-queue-uses-shared-conditions">Why Queue Uses Shared Conditions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#instead-of-per-item-events">Instead of Per-Item Events</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#this-would-be-inefficient-if-items-had-events">❌ This would be inefficient (if items had events)</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#this-is-efficient-what-queue-actually-does">✓ This is efficient (what Queue actually does)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#how-conditions-work-the-mechanism">How Conditions Work: The Mechanism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#not-empty-notify-what-it-does">not*empty.notify() - What It Does</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#when-put-is-called">When put() is called</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#inside-put">Inside put():</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#this-tells-the-condition-variable">This tells the condition variable:</a></li>
<li class="toctree-l1"><a class="reference internal" href="queue_internal_mechanics.html#someone-just-added-an-item">“Someone just added an item”</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#back-to-your-original-question">Back to Your Original Question</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#does-each-item-get-a-condition">“Does each item get a condition?”</a></li>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#the-flow">The Flow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#real-code-example">Real Code Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="queue_internal_mechanics.html#what-queue-put-actually-does">What Queue.put() Actually Does</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#summary">Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="queue_internal_mechanics.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html">task*done() and Queue Explained: Counter &amp; Condition Variables</a><ul>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#quick-answer">Quick Answer</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#the-problem-without-task-done">The Problem Without task*done()</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#without-task-done-can-t-track-completion">Without task*done() - Can’t Track Completion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#how-do-we-know-if-all-items-have-been-processed">How do we know if ALL items have been processed?</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#we-don-t-consumer-might-still-be-working">WE DON’T! Consumer might still be working!</a><ul>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#how-task-done-works">How task*done() Works</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#internal-counter-system">Internal Counter System</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#visual-timeline">Visual Timeline</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#what-task-done-actually-does">What task*done() Actually Does</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#code-simplified">Code (Simplified)</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#two-operations">Two Operations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#the-third-condition-variable-all-tasks-done">The Third Condition Variable: all*tasks*done</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#timeline-all-three-conditions">Timeline: All Three Conditions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#complete-picture-all-operations">Complete Picture: All Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#put">put()</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#get">get()</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#task-done">task*done()</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#join">join()</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#the-complete-flow-with-all-three-conditions">The Complete Flow with All Three Conditions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#scenario-1-producer-1-consumer">Scenario: 1 Producer, 1 Consumer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#detailed-breakdown-task-done-with-counter">Detailed Breakdown: task*done() with Counter</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#step-1-put-increment-counter">Step 1: put() - Increment Counter</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#step-2-get-item-removed-counter-unchanged">Step 2: get() - Item Removed, Counter Unchanged</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#step-3-task-done-decrement-counter">Step 3: task*done() - Decrement Counter</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#step-4-join-wait-then-return">Step 4: join() - Wait, Then Return</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#the-counter-lifecycle">The Counter Lifecycle</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#diagram-tracking-one-task">Diagram: Tracking One Task</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#diagram-multiple-tasks">Diagram: Multiple Tasks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#key-insight-two-data-flows">Key Insight: Two Data Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#why-both-counter-and-condition-variable">Why BOTH Counter AND Condition Variable?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#counter">Counter</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#tracks-how-many-items-haven-t-been-marked-done-yet">Tracks how many items haven’t been marked done yet</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#used-to-know-when-to-signal">Used to know WHEN to signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#checked-by-join">Checked by join()</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#efficiently-wakes-up-waiting-threads">Efficiently wakes up waiting threads</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#avoids-busy-waiting">Avoids busy-waiting</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#used-by-join-to-sleep-instead-of-spinning">Used by join() to sleep instead of spinning</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#wrong-wastes-cpu">WRONG - Wastes CPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#right-uses-condition-variable">RIGHT - Uses condition variable</a><ul>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#visual-counter-and-condition-together">Visual: Counter and Condition Together</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#complete-operation-table">Complete Operation Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#what-happens-without-task-done">What Happens WITHOUT task*done()</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#queue-join-without-task-done">Queue.join() Without task*done()</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#no-task-done-calls">NO task*done() calls!</a><ul>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#what-happens-with-task-done">What Happens WITH task*done()</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#queue-join-with-task-done">Queue.join() With task*done()</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#why-it-works">Why It Works</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#the-three-step-cycle">The Three-Step Cycle</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#step-1-put-item">Step 1: Put Item</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#step-2-get-and-process">Step 2: Get and Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#step-3-mark-done">Step 3: Mark Done</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#flow-diagram">Flow Diagram</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#real-example-work-queue-pattern">Real Example: Work Queue Pattern</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#without-task-done-problematic">Without task*done() - PROBLEMATIC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#add-tasks">Add tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#start-worker">Start worker</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#main-thread-wants-to-know-when-all-work-is-done">Main thread wants to know when all work is done</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#send-poison-pill-to-stop-worker">Send poison pill to stop worker</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#id1">Add tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#id2">Start worker</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#main-thread-waits-for-all-work-to-be-done">Main thread waits for all work to be done</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#id3">Send poison pill to stop worker</a><ul>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#why-is-this-useful">Why Is This Useful?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#use-case-1-verify-all-work-complete">Use Case 1: Verify All Work Complete</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#main-thread">Main thread</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#wait-for-workers-to-finish-all-tasks">Wait for workers to finish ALL tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#now-we-know-all-work-is-done">NOW we know all work is done</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#wait-for-completion">Wait for completion</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#main">Main</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#wait-until-all-batches-processed">Wait until all batches processed</a><ul>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#comparison-with-vs-without-task-done">Comparison: With vs Without task*done()</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#scenario-main-thread-needs-to-know-when-workers-finish">Scenario: Main thread needs to know when workers finish</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#the-flow-in-your-code-05-queue-py">The Flow in Your Code (05*queue.py)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#timeline">Timeline</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#the-missing-piece-in-the-code">The Missing Piece in the Code</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#better-code-pattern">Better Code Pattern</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#in-main">In main</a></li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#stop-consumers">Stop consumers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#summary-what-task-done-does">Summary: What task*done() Does</a><ul>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#why-we-need-task-done">Why We Need task*done()</a></li>
<li class="toctree-l3"><a class="reference internal" href="task_done_queue_explained.html#the-pattern">The Pattern</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="task_done_queue_explained.html#real-code-example">Real Code Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="task_done_queue_explained.html#now-wait-for-consumer-to-finish-processing-all-items">Now wait for consumer to finish processing ALL items</a></li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html">RLock (Reentrant Lock) Explained</a><ul>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#what-is-rlock">What is RLock?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlock_explained.html#regular-lock-vs-rlock">Regular Lock vs RLock</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#how-rlock-works-internally">How RLock Works Internally</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#the-code-explained">The Code Explained</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlock_explained.html#why-rlock-is-needed-here">Why RLock is Needed Here</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html#with-regular-lock-deadlock">With regular Lock - DEADLOCK!</a></li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html#with-rlock-no-deadlock">With RLock - NO DEADLOCK!</a><ul>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#when-to-use-rlock-vs-regular-lock">When to Use RLock vs Regular Lock</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlock_explained.html#use-regular-lock-when">Use Regular Lock When:</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlock_explained.html#use-rlock-when">Use RLock When:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#execution-flow-of-the-code">Execution Flow of the Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#reentrant-lock-counter-animation">Reentrant Lock Counter Animation</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#code-flow-with-comments">Code Flow with Comments</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#visual-comparison">Visual Comparison</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlock_explained.html#regular-lock-would-deadlock">Regular Lock - Would Deadlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlock_explained.html#rlock-no-deadlock">RLock - No Deadlock</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#real-world-example">Real-World Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html#without-rlock">Without RLock:</a></li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html#transfer-acquires-self-lock">transfer() acquires self.lock</a></li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html#withdraw-tries-to-acquire-self-lock-again">withdraw() tries to acquire self.lock again</a></li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html#deadlock">DEADLOCK!</a></li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html#with-rlock">With RLock:</a></li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html#transfer-acquires-self-lock-count-1">transfer() acquires self.lock (count=1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html#withdraw-acquires-self-lock-count-2-allowed">withdraw() acquires self.lock (count=2) - allowed!</a></li>
<li class="toctree-l1"><a class="reference internal" href="rlock_explained.html#no-deadlock">No deadlock!</a><ul>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#summary-table">Summary Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlock_explained.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html">Semaphore Explained</a><ul>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#what-is-a-semaphore">What is a Semaphore?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#key-concept">Key Concept</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#two-types-of-semaphores">Two Types of Semaphores</a><ul>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#counting-semaphore-counter-1">1. Counting Semaphore (Counter &gt; 1)</a></li>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#binary-semaphore-counter-0-or-1">2. Binary Semaphore (Counter = 0 or 1)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#the-code-explained-producer-consumer-pattern">The Code Explained: Producer-Consumer Pattern</a><ul>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#execution-timeline">Execution Timeline</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#semaphore-operations">Semaphore Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#acquire"><code class="docutils literal notranslate"><span class="pre">acquire()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#visual-representation">Visual Representation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#counting-semaphore-3-spots-available">Counting Semaphore (3 spots available)</a></li>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#binary-semaphore-producer-consumer">Binary Semaphore (Producer-Consumer)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#semaphore-vs-lock">Semaphore vs Lock</a></li>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#real-world-examples">Real-World Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#example-1-swimming-pool-with-limited-capacity">Example 1: Swimming Pool with Limited Capacity</a></li>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#example-2-producer-consumer-like-the-code">Example 2: Producer-Consumer (Like the Code)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#how-the-code-works-step-by-step">How the Code Works Step by Step</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#initial-state">Initial state</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#consumer-thread-starts">Consumer thread starts</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#producer-thread-starts-10-times-in-the-loop">Producer thread starts (10 times in the loop)</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#id1">Execution timeline:</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#time-0-consumer-starts-calls-acquire-blocks-counter-0">Time 0:   consumer() starts, calls acquire(), blocks (counter=0)</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#time-0-producer-starts-sleeps-for-3-seconds">Time 0:   producer() starts, sleeps for 3 seconds</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#time-3-producer-wakes-up-generates-item">Time 3:   producer() wakes up, generates item</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#time-3-producer-calls-release-counter-becomes-1">Time 3:   producer() calls release() - counter becomes 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#time-3-consumer-wakes-up-from-acquire-can-continue">Time 3:   consumer() wakes up from acquire(), can continue</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#time-3-consumer-prints-the-item">Time 3:   consumer() prints the item</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#time-3-both-threads-finish-join-completes">Time 3:   both threads finish (join completes)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#semaphore-states-and-transitions">Semaphore States and Transitions</a></li>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#counting-semaphore-states">Counting Semaphore States</a></li>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#common-use-cases">Common Use Cases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#limiting-concurrent-access">1. <strong>Limiting Concurrent Access</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#only-5-threads-can-access-database-at-once">Only 5 threads can access database at once</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#sender-signals-receiver">Sender signals receiver</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#wait-for-all-workers-to-finish">Wait for all workers to finish</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#main-waits-for-all">Main waits for all</a><ul>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#key-differences-from-lock">Key Differences from Lock</a><ul>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#lock-threading-lock">Lock (<code class="docutils literal notranslate"><span class="pre">threading.Lock</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#semaphore-counting">Semaphore (Counting)</a></li>
<li class="toctree-l3"><a class="reference internal" href="semaphore_explained.html#semaphore-binary-used-as-signal">Semaphore (Binary - Used as Signal)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#thread-a-waits-for-signal">Thread A waits for signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="semaphore_explained.html#thread-b-sends-signal">Thread B sends signal</a><ul>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#summary-table">Summary Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="semaphore_explained.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Why Different Approaches for CPU-bound vs I/O-bound Problems?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#table-of-contents">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id1">The Fundamental Problem: The GIL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#what-is-the-gil">What is the GIL?</a></li>
<li class="toctree-l3"><a class="reference internal" href="#why-does-python-have-a-gil">Why Does Python Have a GIL?</a></li>
<li class="toctree-l3"><a class="reference internal" href="#how-the-gil-works">How the GIL Works</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#conceptual-representation-of-gil-behavior">Conceptual representation of GIL behavior</a></li>
<li class="toctree-l1"><a class="reference internal" href="#cpu-bound-operation">CPU-bound operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="#thread-1-acquires-gil-executes-releases-after-100-bytecodes-repeat">Thread 1 acquires GIL → executes → releases after ~100 bytecodes → repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="#thread-2-waits-acquires-gil-executes-releases-repeat">Thread 2 waits → acquires GIL → executes → releases → repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="#result-threads-take-turns-no-parallel-execution">Result: Threads take TURNS, no parallel execution</a></li>
<li class="toctree-l1"><a class="reference internal" href="#i-o-bound-operation">I/O-bound operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="#thread-1-acquires-gil-starts-i-o-releases-gil-during-i-o-wait">Thread 1 acquires GIL → starts I/O → RELEASES GIL during I/O wait</a></li>
<li class="toctree-l1"><a class="reference internal" href="#thread-2-can-now-acquire-gil-and-execute-while-thread-1-waits">Thread 2 can now acquire GIL and execute while Thread 1 waits</a></li>
<li class="toctree-l1"><a class="reference internal" href="#result-threads-can-work-while-others-are-waiting-for-i-o">Result: Threads can work while others are waiting for I/O</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">How CPU and I/O Operations Differ</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cpu-bound-operations">CPU-bound Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#i-o-bound-operations">I/O-bound Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#real-world-analogy">Real-World Analogy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id3">Why Multiprocessing for CPU-bound</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-problem-with-threading-for-cpu-bound">The Problem with Threading for CPU-bound</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#cpu-intensive-task-with-threading">CPU-intensive task with threading</a></li>
<li class="toctree-l1"><a class="reference internal" href="#sequential">Sequential</a></li>
<li class="toctree-l1"><a class="reference internal" href="#threading-same-time-or-worse">Threading (SAME TIME OR WORSE!)</a></li>
<li class="toctree-l1"><a class="reference internal" href="#cpu-intensive-task-with-multiprocessing">CPU-intensive task with multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="#multiprocessing">Multiprocessing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id4">Why Threading for I/O-bound</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-problem-wasted-time">The Problem: Wasted Time</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#sequential-i-o-operations">Sequential I/O operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="#threaded-i-o-operations">Threaded I/O operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="#what-happens-under-the-hood">What happens under the hood:</a></li>
<li class="toctree-l1"><a class="reference internal" href="#real-example-downloading-10-web-pages">Real example: Downloading 10 web pages</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id5">Why Asyncio for I/O-bound</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-problem-with-threading-overhead">The Problem with Threading: Overhead</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asyncio-cooperative-multitasking">Asyncio: Cooperative Multitasking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#how-asyncio-works">How Asyncio Works</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#asyncio-example-10-000-concurrent-requests">Asyncio example: 10,000 concurrent requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="#threading-approach">Threading approach</a></li>
<li class="toctree-l1"><a class="reference internal" href="#problem-creating-1000-threads">Problem: Creating 1000 threads!</a></li>
<li class="toctree-l1"><a class="reference internal" href="#memory-8-gb-1000-8-mb-stack-per-thread">Memory: ~8 GB (1000 × 8 MB stack per thread)</a></li>
<li class="toctree-l1"><a class="reference internal" href="#os-overhead-managing-1000-threads">OS overhead: Managing 1000 threads</a></li>
<li class="toctree-l1"><a class="reference internal" href="#asyncio-approach">Asyncio approach</a></li>
<li class="toctree-l1"><a class="reference internal" href="#solution-single-thread-1000-lightweight-tasks">Solution: Single thread, 1000 lightweight tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="#memory-50-mb-total">Memory: ~50 MB total</a></li>
<li class="toctree-l1"><a class="reference internal" href="#os-overhead-none-all-managed-by-python">OS overhead: None (all managed by Python)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id10">Deep Dive: What Happens Under the Hood</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cpu-bound-with-threading-the-gil-dance">CPU-bound with Threading: The GIL Dance</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#example-two-threads-computing-sum">Example: Two threads computing sum</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id11">Performance Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#benchmark-cpu-bound-task-computing">Benchmark: CPU-bound Task (Computing π)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#benchmark-i-o-bound-task-web-requests">Benchmark: I/O-bound Task (Web Requests)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#benchmark-mixed-workload">Benchmark: Mixed Workload</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id14">Decision Tree</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#quick-reference-table">Quick Reference Table</a></li>
<li class="toctree-l3"><a class="reference internal" href="#code-templates">Code Templates</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#summary-the-core-principles">Summary: The Core Principles</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-gil-controls-everything">1. The GIL Controls Everything</a></li>
<li class="toctree-l3"><a class="reference internal" href="#resource-usage-matters">2. Resource Usage Matters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#trade-offs-are-real">3. Trade-offs are Real</a></li>
<li class="toctree-l3"><a class="reference internal" href="#know-your-workload">4. Know Your Workload</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#profile-your-code-first">Profile your code first!</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#final-thoughts">Final Thoughts</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Programming Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html">GPU Fundamentals</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#understanding-gpu-architecture">Understanding GPU Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#key-differences-cpu-vs-gpu">Key Differences: CPU vs GPU</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#gpu-hierarchy">GPU Hierarchy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#streaming-multiprocessors-sms">Streaming Multiprocessors (SMs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#thread-organization">Thread Organization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#spmd-programming-model">SPMD Programming Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#example-visualization">Example Visualization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#compute-capabilities">Compute Capabilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#key-concepts-summary">Key Concepts Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#next-steps">Next Steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html">GPU Memory Hierarchy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#the-performance-pyramid">The Performance Pyramid</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#global-memory-hbm-dram">Global Memory (HBM/DRAM)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#memory-coalescing">Memory Coalescing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#l2-cache">L2 Cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#l1-cache-shared-memory-sram">L1 Cache / Shared Memory (SRAM)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#example-matrix-multiplication">Example: Matrix Multiplication</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#registers">Registers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#memory-access-patterns">Memory Access Patterns</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#pattern-1-streaming-bandwidth-bound">Pattern 1: Streaming (Bandwidth-Bound)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#pattern-2-staged-computation-compute-bound">Pattern 2: Staged Computation (Compute-Bound)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#pattern-3-reduction-mixed">Pattern 3: Reduction (Mixed)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#optimizing-for-memory-hierarchy">Optimizing for Memory Hierarchy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#the-golden-rules">The Golden Rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#example-naive-vs-optimized-softmax">Example: Naive vs Optimized Softmax</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#measuring-memory-performance">Measuring Memory Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#key-metrics">Key Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#tools-for-profiling">Tools for Profiling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html">GPU Execution Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/execution-model.html#thread-execution">Thread Execution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#warps-and-simd-execution">Warps and SIMD Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#thread-divergence">Thread Divergence</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/execution-model.html#occupancy">Occupancy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#what-is-occupancy">What is Occupancy?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#factors-limiting-occupancy">Factors Limiting Occupancy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#example-calculation">Example Calculation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/execution-model.html#latency-hiding">Latency Hiding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#why-occupancy-matters">Why Occupancy Matters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#the-occupancy-sweet-spot">The Occupancy Sweet Spot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/execution-model.html#kernel-launch-configuration">Kernel Launch Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#grid-and-block-dimensions">Grid and Block Dimensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#choosing-block-size">Choosing Block Size</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/execution-model.html#synchronization">Synchronization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#within-a-block">Within a Block</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#between-blocks">Between Blocks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/execution-model.html#warp-level-operations">Warp-Level Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#warp-shuffles">Warp Shuffles</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#warp-level-reductions">Warp-Level Reductions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/execution-model.html#software-pipelining">Software Pipelining</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#overlap-compute-and-memory">Overlap Compute and Memory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/execution-model.html#persistent-kernels">Persistent Kernels</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#traditional-approach">Traditional Approach</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#persistent-approach">Persistent Approach</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/execution-model.html#performance-considerations">Performance Considerations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#key-factors">Key Factors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/execution-model.html#profiling-tools">Profiling Tools</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/execution-model.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html">Performance Optimization Strategies</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#the-optimization-process">The Optimization Process</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#step-1-profile-first">Step 1: Profile First</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#step-2-identify-bottleneck">Step 2: Identify Bottleneck</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#memory-optimization">Memory Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-1-kernel-fusion">Strategy 1: Kernel Fusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-2-tiling">Strategy 2: Tiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-3-vectorized-loads">Strategy 3: Vectorized Loads</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-4-memory-coalescing">Strategy 4: Memory Coalescing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#compute-optimization">Compute Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-1-use-tensor-cores">Strategy 1: Use Tensor Cores</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-2-increase-arithmetic-intensity">Strategy 2: Increase Arithmetic Intensity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-3-minimize-thread-divergence">Strategy 3: Minimize Thread Divergence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-4-optimize-loop-structure">Strategy 4: Optimize Loop Structure</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#occupancy-optimization">Occupancy Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-1-reduce-register-usage">Strategy 1: Reduce Register Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-2-tune-shared-memory">Strategy 2: Tune Shared Memory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-3-adjust-block-size">Strategy 3: Adjust Block Size</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#auto-tuning">Auto-Tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#why-auto-tune">Why Auto-Tune?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#triton-auto-tuning">Triton Auto-Tuning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#advanced-techniques">Advanced Techniques</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#warp-specialization">Warp Specialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#persistent-kernels">Persistent Kernels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#recomputation">Recomputation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#common-patterns">Common Patterns</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#pattern-reduction">Pattern: Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#pattern-element-wise">Pattern: Element-wise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#pattern-matrix-multiply">Pattern: Matrix Multiply</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#debugging-performance-issues">Debugging Performance Issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#issue-low-bandwidth">Issue: Low Bandwidth</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#issue-low-compute-utilization">Issue: Low Compute Utilization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#issue-lower-than-pytorch">Issue: Lower Than PyTorch</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#performance-checklist">Performance Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#before-you-optimize">Before You Optimize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#memory-optimizations">Memory Optimizations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#compute-optimizations">Compute Optimizations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#id1">Occupancy Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#advanced">Advanced</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#summary">Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#next-steps">Next Steps</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Tutorials (Beginner)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html">Vector Addition in Triton</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#what-you-ll-learn">What You’ll Learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#gpu-cuda-concepts">GPU/CUDA Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#spmd-single-program-multiple-data">SPMD (Single Program, Multiple Data)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#program-id-and-block-processing">Program ID and Block Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#grid-size">Grid Size</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#memory-hierarchy">Memory Hierarchy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#memory-coalescing">Memory Coalescing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#masking-for-boundary-conditions">Masking for Boundary Conditions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#how-the-kernel-works">How the Kernel Works</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#step-by-step-execution">Step-by-Step Execution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#performance-characteristics">Performance Characteristics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#bandwidth-bound-operation">Bandwidth-Bound Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#arithmetic-intensity">Arithmetic Intensity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#theoretical-performance">Theoretical Performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#triton-specific-features">Triton-Specific Features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#triton-jit-decorator"><code class="docutils literal notranslate"><span class="pre">&#64;triton.jit</span></code> Decorator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#constexpr-for-compile-time-constants"><code class="docutils literal notranslate"><span class="pre">constexpr</span></code> for Compile-Time Constants</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#launch-grid-syntax">Launch Grid Syntax</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#benchmarking-insights">Benchmarking Insights</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#expected-results">Expected Results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#common-patterns-you-ll-see">Common Patterns You’ll See</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#pointer-arithmetic">1. Pointer Arithmetic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#vectorized-operations">2. Vectorized Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#masked-memory-operations">3. Masked Memory Operations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#comparison-to-cuda">Comparison to CUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#next-steps">Next Steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html">Fused Softmax in Triton</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#what-you-ll-learn">What You’ll Learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#the-problem-with-naive-softmax">The Problem with Naive Softmax</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#standard-softmax-formula">Standard Softmax Formula</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#naive-pytorch-implementation">Naive PyTorch Implementation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#gpu-memory-hierarchy">GPU Memory Hierarchy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#dram-global-memory">DRAM (Global Memory)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#sram-shared-memory-l1-cache">SRAM (Shared Memory / L1 Cache)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#the-key-insight">The Key Insight</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#how-the-fused-kernel-works">How the Fused Kernel Works</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#block-level-processing">Block-Level Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#step-1-load-row-into-sram">Step 1: Load Row Into SRAM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#step-2-compute-max-reduction">Step 2: Compute Max (Reduction)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#step-3-exponentiation">Step 3: Exponentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#step-4-compute-sum-another-reduction">Step 4: Compute Sum (Another Reduction)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#step-5-normalize-and-write-back">Step 5: Normalize and Write Back</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#power-of-two-block-sizes">Power-of-Two Block Sizes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#why-must-block-size-be-power-of-2">Why Must BLOCK*SIZE Be Power of 2?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#occupancy-and-performance-tuning">Occupancy and Performance Tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#number-of-warps">Number of Warps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#number-of-pipeline-stages">Number of Pipeline Stages</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#computing-occupancy">Computing Occupancy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#persistent-kernels">Persistent Kernels</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#the-pattern">The Pattern</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#numerical-stability">Numerical Stability</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#why-subtract-max">Why Subtract Max?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#padding-with-inf">Padding with -inf</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#memory-bandwidth-analysis">Memory Bandwidth Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#theoretical-speedup">Theoretical Speedup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#actual-performance">Actual Performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#key-cuda-triton-concepts">Key CUDA/Triton Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#reduction-operations">Reduction Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#warp-shuffles">Warp Shuffles</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#block-vs-thread">Block vs Thread</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#common-pitfalls">Common Pitfalls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#row-too-large-for-sram">1. Row Too Large for SRAM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#numerical-precision">2. Numerical Precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#masking-errors">3. Masking Errors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#performance-tips">Performance Tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#comparison-to-other-approaches">Comparison to Other Approaches</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#jit-fusion-torch-jit-script">JIT Fusion (torch.jit.script)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#manual-cuda">Manual CUDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#cudnn-cublas">CuDNN/CuBLAS</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#extensions">Extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Tutorials (Intermediate)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html">Matrix Multiplication in Triton</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#what-you-ll-learn">What You’ll Learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#the-matrix-multiplication-problem">The Matrix Multiplication Problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#basic-algorithm">Basic Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#why-it-s-hard-to-optimize">Why It’s Hard to Optimize</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#gpu-matrix-multiplication-strategy">GPU Matrix Multiplication Strategy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#blocked-algorithm">Blocked Algorithm</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#pseudocode-for-our-kernel">Pseudocode for our kernel</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#pointer-arithmetic-in-2d">Pointer Arithmetic in 2D</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#understanding-strides">Understanding Strides</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#block-pointers">Block Pointers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#broadcasting-multiplication">Broadcasting multiplication:</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#l2-cache-optimization">L2 Cache Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#the-problem-with-row-major-ordering">The Problem with Row-Major Ordering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#grouped-ordering-swizzling">Grouped Ordering (Swizzling)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#auto-tuning">Auto-Tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#the-configuration-space">The Configuration Space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#triton-s-auto-tuner">Triton’s Auto-Tuner</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#id3">)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#good-configurations">Good Configurations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#the-kernel-implementation">The Kernel Implementation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#step-1-compute-program-ids">Step 1: Compute Program IDs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#step-2-initialize-pointers">Step 2: Initialize Pointers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#step-3-accumulation-loop">Step 3: Accumulation Loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#step-4-apply-activation-optional">Step 4: Apply Activation (Optional)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#step-5-store-result">Step 5: Store Result</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#tensor-cores">Tensor Cores</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#what-are-tensor-cores">What Are Tensor Cores?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#how-tensor-cores-work">How Tensor Cores Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#triton-and-tensor-cores">Triton and Tensor Cores</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#performance-analysis">Performance Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#arithmetic-intensity">Arithmetic Intensity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#roofline-model">Roofline Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#expected-performance">Expected Performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#advanced-optimizations">Advanced Optimizations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#software-pipelining">Software Pipelining</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#loop-unrolling">Loop Unrolling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#register-pressure">Register Pressure</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#common-pitfalls">Common Pitfalls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#non-contiguous-tensors">1. Non-Contiguous Tensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#wrong-stride-calculation">2. Wrong Stride Calculation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#boundary-conditions">3. Boundary Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#numerical-precision">4. Numerical Precision</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#benchmarking-tips">Benchmarking Tips</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#warm-up">1. Warm-up</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#measure-tflops">2. Measure TFLOPS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#compare-against-cublas-rocblas">3. Compare Against cuBLAS/rocBLAS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#test-different-sizes">4. Test Different Sizes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html">Low-Memory Dropout in Triton</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#what-you-ll-learn">What You’ll Learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#what-is-dropout">What is Dropout?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#purpose">Purpose</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#mathematical-definition">Mathematical Definition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#id1">}</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#scaling-factor">Scaling Factor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#naive-implementation-problems">Naive Implementation Problems</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#standard-pytorch-dropout">Standard PyTorch Dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#the-backward-pass-problem">The Backward Pass Problem</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#forward">Forward</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#backward-later">Backward (later)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#backward-pass-uses-different-mask-wrong-gradients">Backward pass uses different mask → wrong gradients!</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#seeded-dropout-solution">Seeded Dropout Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#key-insight">Key Insight</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#the-triton-implementation">The Triton Implementation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#parallel-random-number-generation">Parallel Random Number Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#the-challenge">The Challenge</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#the-solution-counter-based-prng">The Solution: Counter-Based PRNG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#the-philox-algorithm">The Philox Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#using-philox-in-triton">Using Philox in Triton</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#call-again-with-same-seed-and-offsets">Call again with same seed and offsets:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#different-seed">Different seed:</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#memory-and-performance-trade-offs">Memory and Performance Trade-offs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#memory-comparison">Memory Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#computational-cost">Computational Cost</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#when-to-use-seeded-dropout">When to Use Seeded Dropout</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#reproducibility-and-determinism">Reproducibility and Determinism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#ensuring-same-random-numbers">Ensuring Same Random Numbers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#forward-pass">Forward pass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#backward-pass-later">Backward pass (later)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#must-use-same-seed-to-get-same-mask">Must use SAME seed to get SAME mask</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#implementation-details">Implementation Details</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#the-tl-where-function">The <code class="docutils literal notranslate"><span class="pre">tl.where</span></code> Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#masking-for-boundary-conditions">Masking for Boundary Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#random-number-distribution">Random Number Distribution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#advanced-considerations">Advanced Considerations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#different-random-distributions">Different Random Distributions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#generate-normal-distribution">Generate normal distribution</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#performance-benchmarks">Performance Benchmarks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#expected-performance">Expected Performance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#bottleneck-analysis">Bottleneck Analysis</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#practical-usage">Practical Usage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#integration-with-pytorch">Integration with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#seed-generation-strategies">Seed Generation Strategies</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#ensure-different-seeds-on-different-gpus">Ensure different seeds on different GPUs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Tutorials (Advanced)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html">Layer Normalization in Triton</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#what-you-ll-learn">What You’ll Learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#what-is-layer-normalization">What is Layer Normalization?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#the-formula">The Formula</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#step-by-step-math">Step-by-Step Math</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#why-layer-normalization">Why Layer Normalization?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#batch-norm-vs-layer-norm">Batch Norm vs Layer Norm</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#the-forward-pass">The Forward Pass</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#kernel-structure">Kernel Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#computing-the-mean">Computing the Mean</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#computing-the-variance">Computing the Variance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#normalization-and-transformation">Normalization and Transformation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#the-backward-pass">The Backward Pass</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#gradient-mathematics">Gradient Mathematics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#gradient-for-biases">Gradient for Biases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#gradient-for-weights">Gradient for Weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#gradient-for-input-complex">Gradient for Input (Complex!)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#parallel-reduction-strategy">Parallel Reduction Strategy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#the-challenge">The Challenge</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#two-stage-reduction">Two-Stage Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#group-assignment">Group Assignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#using-locks">Using Locks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#in-kernel">In kernel:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#acquire-lock">Acquire lock</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#critical-section-update-dw-and-db">Critical section: Update DW and DB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#release-lock">Release lock</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#lock-acquired-we-set-it-to-1">Lock acquired (we set it to 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#do-work">Do work…</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#triton-implementation-details">Triton Implementation Details</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#memory-layout">Memory Layout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#stride-usage">Stride Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#why-use-float32-for-accumulation">Why Use float32 for Accumulation?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#performance-characteristics">Performance Characteristics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#computational-complexity">Computational Complexity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#memory-bandwidth">Memory Bandwidth</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#optimization-opportunities">Optimization Opportunities</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#common-pitfalls">Common Pitfalls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#numerical-stability">1. Numerical Stability</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#dimension-confusion">2. Dimension Confusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#gradient-accumulation-race-conditions">3. Gradient Accumulation Race Conditions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#use-locks-or-separate-buffers">Use locks or separate buffers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#advanced-concepts">Advanced Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#rmsnorm-simpler-variant">RMSNorm (Simpler Variant)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#groupnorm">GroupNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#fp8-and-mixed-precision">FP8 and Mixed Precision</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#comparison-to-pytorch">Comparison to PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#pytorch-implementation">PyTorch Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#triton-advantages">Triton Advantages</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#performance">Performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html">Fused Attention (Flash Attention) in Triton</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#what-you-ll-learn">What You’ll Learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#background-the-attention-mechanism">Background: The Attention Mechanism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#standard-attention-formula">Standard Attention Formula</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#step-by-step-computation">Step-by-Step Computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#the-memory-problem">The Memory Problem</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#flash-attention-the-key-insights">Flash Attention: The Key Insights</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#insight-1-we-don-t-need-to-store-s-and-p">Insight 1: We Don’t Need to Store S and P</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#insight-2-online-softmax">Insight 2: Online Softmax</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#pass-1-find-max">Pass 1: Find max</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#pass-2-compute-softmax">Pass 2: Compute softmax</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#the-online-softmax-algorithm">The Online Softmax Algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#standard-softmax">Standard Softmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#block-wise-computation">Block-wise Computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#updating-the-output">Updating the Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#triton-implementation-details">Triton Implementation Details</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#the-inner-loop">The Inner Loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#causal-masking">Causal Masking</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#stages-for-causal-attention">Stages for Causal Attention</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#memory-optimizations">Memory Optimizations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#tensor-descriptors">Tensor Descriptors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#warp-specialization">Warp Specialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#reduced-shared-memory">Reduced Shared Memory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#fp8-support">FP8 Support</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#backward-pass">Backward Pass</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#preprocess-step">Preprocess Step</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#computing-dk-and-dv">Computing dK and dV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#computing-dq">Computing dQ</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#why-recomputation">Why Recomputation?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#performance-characteristics">Performance Characteristics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#memory-complexity">Memory Complexity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#compute-complexity">Compute Complexity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#arithmetic-intensity">Arithmetic Intensity</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#auto-tuning-configurations">Auto-Tuning Configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#common-pitfalls">Common Pitfalls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#sram-overflow">1. SRAM Overflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#numerical-instability">2. Numerical Instability</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#wrong">Wrong</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#right">Right</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#wrong-for-causal-token-can-t-attend-to-itself">Wrong for causal (token can’t attend to itself!)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#id9">Right</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#must-update-both-m-i-and-l-i">Must update both m*i and l*i!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#and-correct-accumulator">And correct accumulator</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#extensions-and-variants">Extensions and Variants</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#multi-query-attention-mqa">Multi-Query Attention (MQA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#grouped-query-attention-gqa">Grouped Query Attention (GQA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#sliding-window-attention">Sliding Window Attention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#flash-attention-3">Flash Attention 3</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#comparison-to-standard-attention">Comparison to Standard Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html">Using External Functions (libdevice) in Triton</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#what-you-ll-learn">What You’ll Learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#what-is-libdevice">What is libdevice?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#nvidia-s-libdevice">NVIDIA’s libdevice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#amd-s-device-libraries">AMD’s Device Libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#what-functions-are-available">What Functions Are Available?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#why-use-external-functions">Why Use External Functions?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#triton-built-in-math">Triton Built-in Math</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#when-you-need-more">When You Need More</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#using-libdevice-in-triton">Using libdevice in Triton</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#the-simple-way-default-path">The Simple Way (Default Path)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#the-custom-path-way">The Custom Path Way</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#find-libdevice-in-triton-installation">Find libdevice in Triton installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#pass-to-kernel">Pass to kernel</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#how-it-works-under-the-hood">How It Works Under the Hood</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#compilation-process">Compilation Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#type-dispatch">Type Dispatch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#calling-convention">Calling Convention</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#available-libdevice-functions-in-triton">Available libdevice Functions in Triton</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#triton-s-libdevice-wrapper">Triton’s libdevice Wrapper</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#trigonometric">Trigonometric</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#hyperbolic">Hyperbolic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#exponential-logarithmic">Exponential/Logarithmic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#special-functions">Special functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#and-many-more">And many more!</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#example-arc-sine-asin">Example: Arc Sine (asin)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#the-math">The Math</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#why-use-libdevice">Why Use libdevice?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#full-example">Full Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#test">Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#should-match">Should match!</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#performance-considerations">Performance Considerations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#libdevice-performance">Libdevice Performance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#when-to-use-vs-triton-intrinsics">When to Use vs Triton Intrinsics</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#linking-multiple-libraries-amd-example">Linking Multiple Libraries (AMD Example)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#debugging-linking-issues">Debugging Linking Issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#common-errors">Common Errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#verifying-libraries">Verifying Libraries</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#nvidia">NVIDIA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#amd">AMD</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#advanced-usage">Advanced Usage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#calling-custom-external-functions">Calling Custom External Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#id5">}</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#mixing-multiple-external-libraries">Mixing Multiple External Libraries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#portability-considerations">Portability Considerations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#nvidia-vs-amd">NVIDIA vs AMD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#function-name-differences">Function Name Differences</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#comparison-to-cuda">Comparison to CUDA</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#in-cuda">In CUDA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#id6">}</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#in-triton">In Triton</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html">Tutorial 08: Grouped GEMM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#key-concepts">Key Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#static-on-device-scheduling">Static On-Device Scheduling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#group-problem-representation">Group Problem Representation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#code-walkthrough">Code Walkthrough</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#grouped-gemm-kernel-basic-version">1. Grouped GEMM Kernel (Basic Version)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#tma-tensor-memory-accelerator-version">2. TMA (Tensor Memory Accelerator) Version</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#host-function-setup">3. Host Function Setup</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#auto-tuning-configurations">Auto-tuning Configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#memory-layout-considerations">Memory Layout Considerations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#pointer-indirection">Pointer Indirection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#leading-dimension-stride">Leading Dimension (Stride)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#for-row-major-matrix-a-m-k">For row-major matrix A[M, K]:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#element-at-i-j-is-at-base-ptr-i-lda-j">Element at (i, j) is at: base*ptr + i * lda + j</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#performance-characteristics">Performance Characteristics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#when-grouped-gemm-wins">When Grouped GEMM Wins</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#when-to-use-separate-kernels">When to Use Separate Kernels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#benchmarking-results">Benchmarking Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#id1">)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#gpu-architecture-insights">GPU Architecture Insights</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#why-fixed-number-of-ctas">Why Fixed Number of CTAs?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#work-distribution">Work Distribution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#advanced-tma-descriptor-creation">Advanced: TMA Descriptor Creation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#load-a-block-starting-at-offs-am-offs-k">Load a block starting at (offs*am, offs*k)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#common-pitfalls">Common Pitfalls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#forgetting-contiguity">1. Forgetting Contiguity</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#bad-b-might-not-be-contiguous-after-transpose">Bad: B might not be contiguous after transpose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#good-ensure-contiguity">Good: Ensure contiguity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#wrong-assuming-contiguous">Wrong: Assuming contiguous</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#correct-use-actual-stride">Correct: Use actual stride</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#fp8-requires-compute-capability-9-0">FP8 requires compute capability &gt;= 9.0</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#practical-example">Practical Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#define-different-problem-sizes">Define different problem sizes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#create-random-matrices">Create random matrices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#compute-all-gemms-in-one-kernel-launch">Compute all GEMMs in one kernel launch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#verify-against-pytorch">Verify against PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html">Tutorial 09: Persistent Matmul</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#key-concepts">Key Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#persistent-kernel-pattern">Persistent Kernel Pattern</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#traditional-kernel-one-cta-per-tile">Traditional kernel: One CTA per tile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#persistent-kernel-num-sms-ctas-process-all-tiles">Persistent kernel: NUM*SMS CTAs process all tiles</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#code-walkthrough">Code Walkthrough</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#naive-matmul-baseline">1. Naive Matmul (Baseline)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#id1">)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#persistent-matmul">2. Persistent Matmul</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#id4">)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#tma-matmul">3. TMA Matmul</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#tma-persistent-with-epilogue-subtiling">4. TMA Persistent with Epilogue Subtiling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#proton-profiler-integration">Proton Profiler Integration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#start-profiling">Start profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#run-benchmarks">Run benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#finalize-and-show-results">Finalize and show results</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#device-side-vs-host-side-descriptors">Device-side vs Host-side Descriptors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#host-side-tensordescriptor">Host-side (TensorDescriptor)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#created-on-cpu-passed-to-gpu">Created on CPU, passed to GPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#warp-specialization-details">Warp Specialization Details</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#how-it-works">How It Works</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#requirements">Requirements</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#on-hopper-software-pipelining">On Hopper: Software pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#on-blackwell-hardware-warp-specialization">On Blackwell: Hardware warp specialization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#flattening-in-persistent-loops">Flattening in Persistent Loops</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#choose-based-on-gpu-generation">Choose based on GPU generation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#performance-comparison">Performance Comparison</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#expected-speedups-relative-to-naive">Expected speedups (relative to naive):</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#when-each-variant-wins">When Each Variant Wins</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#precision-support">Precision Support</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#fp16-float16">FP16 (Float16)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#fp8-float8">FP8 (Float8)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#auto-tuning-configuration">Auto-tuning Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#command-line-usage">Command-line Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#fp16-matmul">FP16 matmul</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#fp8-matmul-requires-hopper">FP8 matmul (requires Hopper+)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#profile-specific-k-dimension">Profile specific K dimension</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#common-pitfalls">Common Pitfalls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#wrong-b-matrix-layout-for-tma">1. Wrong B Matrix Layout for TMA</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#tma-expects-b-to-be-transposed">TMA expects B to be transposed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#bad-using-both-in-same-kernel">Bad: Using both in same kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#good-pick-one-approach">Good: Pick one approach</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html">Tutorial 10: Block Scaled Matrix Multiplication</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#key-concepts">Key Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#block-scaling-fundamentals">Block Scaling Fundamentals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#quantization-formats">Quantization Formats</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#memory-savings">Memory Savings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#scale-preshuffling-nvidia">Scale Preshuffling (NVIDIA)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#why-preshuffling">Why Preshuffling?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#original-linear-layout-m-k-vec-size">Original linear layout: [M, K // VEC*SIZE]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#each-row-has-k-vec-size-scales">Each row has K // VEC*SIZE scales</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#preshuffled-layout-m-128-k-vec-size-4-32-4-4">Preshuffled layout: [M // 128, K // VEC*SIZE // 4, 32, 4, 4]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#organized-for-128-element-blocks-along-m">Organized for 128-element blocks along M</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#load-in-5d-preshuffled-format">Load in 5D preshuffled format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#reshape-to-5d">Reshape to 5D</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#transpose-to-logical-2d-layout">Transpose to logical 2D layout</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#now-ready-for-tl-dot-scaled">Now ready for tl.dot*scaled</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#scale-preshuffling-amd-cdna4">Scale Preshuffling (AMD CDNA4)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#mfma-scale-organization">MFMA Scale Organization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#thread-level-access-pattern">Thread-level Access Pattern</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#code-walkthrough">Code Walkthrough</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#nvidia-kernel-tma-based">1. NVIDIA Kernel (TMA-based)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#amd-cdna4-kernel">2. AMD CDNA4 Kernel</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#initialization-and-setup">Initialization and Setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#nvidia-version">NVIDIA Version</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#amd-version">AMD Version</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#performance-characteristics">Performance Characteristics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#theoretical-speedup">Theoretical Speedup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#real-world-performance">Real-world Performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#numerical-considerations">Numerical Considerations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#quantization-error">Quantization Error</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#fp16-range-65504-3-decimal-digits">FP16 range: ±65504, ~3 decimal digits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#fp8-e4m3-range-448-2-decimal-digits">FP8 (E4M3) range: ±448, ~2 decimal digits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#fp4-e2m1-range-6-1-decimal-digit">FP4 (E2M1) range: ±6, ~1 decimal digit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#without-scaling">Without scaling:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#with-scaling">With scaling:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#example">Example:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#x-135-2-135-127-2-8-256">x = 135 → 2^(135-127) = 2^8 = 256</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#x-127-2-0-1">x = 127 → 2^0 = 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#x-119-2-8-0-00390625">x = 119 → 2^(-8) = 0.00390625</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#usage-examples">Usage Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#command-line-benchmarking">Command-line Benchmarking</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#nvidia-fp4">NVIDIA FP4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#nvidia-fp8">NVIDIA FP8</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#amd-mxfp4-automatic-detection">AMD MXFP4 (automatic detection)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#mixed-precision">Mixed precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#nvidia">NVIDIA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#amd-with-both-mfma-shapes">AMD with both MFMA shapes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#common-pitfalls">Common Pitfalls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#unsupported-hardware">1. Unsupported Hardware</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#format-mismatch">2. Format Mismatch</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#bad-using-amd-kernel-with-nvidia-formats">Bad: Using AMD kernel with NVIDIA formats</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#scales-must-match-data-dimensions">Scales must match data dimensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#after-packing-to-5d">After packing to 5D</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#summary">Summary</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton Compiler Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../triton-compiler/01-overview.html">Triton Compiler Architecture Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/01-overview.html#what-is-triton">What is Triton?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#key-features">Key Features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/01-overview.html#compilation-pipeline-overview">Compilation Pipeline Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/01-overview.html#architecture-components">Architecture Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/01-overview.html#compilation-stages-in-detail">Compilation Stages in Detail</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#stage-1-python-ast-parsing">Stage 1: Python AST Parsing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#stage-2-code-generation-ttir">Stage 2: Code Generation (TTIR)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#stage-3-triton-gpu-ir-ttgir">Stage 3: Triton GPU IR (TTGIR)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#stage-4-llvm-ir">Stage 4: LLVM IR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#stage-5-ptx-amdgcn">Stage 5: PTX / AMDGCN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#stage-6-binary-cubin-hsaco">Stage 6: Binary (CUBIN / HSACO)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/01-overview.html#key-design-decisions">Key Design Decisions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#block-based-programming-model">Block-based Programming Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#jit-compilation">JIT Compilation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#mlir-infrastructure">MLIR Infrastructure</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/01-overview.html#source-code-organization">Source Code Organization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#python-components">Python Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#c-components">C++ Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/01-overview.html#backend-components">Backend Components</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/01-overview.html#links-to-source-code">Links to Source Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/01-overview.html#next-steps">Next Steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html">The &#64;triton.jit Decorator</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#how-the-decorator-works">How the Decorator Works</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#implementation">Implementation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#the-jitcallable-base-class">The JITCallable Base Class</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#source-code-extraction">Source Code Extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#ast-parsing">AST Parsing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#cache-key-generation">Cache Key Generation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#dependencies-tracking">Dependencies Tracking</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#tracking-global-variables">Tracking Global Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#handling-nested-function-calls">Handling Nested Function Calls</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#the-jitfunction-class">The JITFunction Class</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#initialization">Initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#kernel-call-handling">Kernel Call Handling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#argument-specialization">Argument Specialization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#compilation-triggering">Compilation Triggering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#kernel-metadata">Kernel Metadata</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#launch-metadata">Launch Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#attributes-and-hints">Attributes and Hints</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#constexpr-parameters">Constexpr Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/02-jit-decorator.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html">Compilation Pipeline: AST to GPU Binary</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#code-generation-python-ast-triton-ir">Code Generation: Python AST → Triton IR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#codegenerator-class">CodeGenerator Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#ast-visitor-pattern">AST Visitor Pattern</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#triton-language-primitives">Triton Language Primitives</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#type-inference">Type Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#example-ttir-output">Example TTIR Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#mlir-lowering-ttir-ttgir-llir">MLIR Lowering: TTIR → TTGIR → LLIR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#compilation-orchestration">Compilation Orchestration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#ttir-ttgir-transformation">TTIR → TTGIR Transformation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#ttgir-llvm-ir">TTGIR → LLVM IR</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#backend-compilation">Backend Compilation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#llvm-ir-ptx">LLVM IR → PTX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#ptx-cubin">PTX → CUBIN</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#caching-strategy">Caching Strategy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#cache-key-components">Cache Key Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#cache-directory-structure">Cache Directory Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#cache-lookup">Cache Lookup</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#performance-timeline">Performance Timeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../triton-compiler/03-compilation-pipeline.html#summary">Summary</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Additional Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../learning-paths.html">Learning Paths</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#path-1-fast-track-essentials">Path 1: Fast Track (Essentials)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#path-2-deep-understanding-comprehensive">Path 2: Deep Understanding (Comprehensive)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#path-3-transformer-focus-for-llm-nlp">Path 3: Transformer Focus (For LLM/NLP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#path-4-computer-vision-focus">Path 4: Computer Vision Focus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#path-5-performance-engineering">Path 5: Performance Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#by-topic">By Topic</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../learning-paths.html#memory-optimization">Memory Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../learning-paths.html#compute-optimization">Compute Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../learning-paths.html#backward-pass-training">Backward Pass / Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../learning-paths.html#advanced-techniques">Advanced Techniques</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#learning-tips">Learning Tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#assessment-checkpoints">Assessment Checkpoints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../learning-paths.html#after-path-1-fast-track">After Path 1 (Fast Track)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../learning-paths.html#after-path-2-comprehensive">After Path 2 (Comprehensive)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../learning-paths.html#after-path-3-transformer">After Path 3 (Transformer)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#next-steps-after-completing-a-path">Next Steps After Completing a Path</a></li>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#resources-for-continued-learning">Resources for Continued Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../learning-paths.html#choose-your-path">Choose Your Path</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html">Troubleshooting Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#out-of-memory-errors">Out of Memory Errors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#cuda-out-of-memory">CUDA Out of Memory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#out-of-shared-memory">Out of Shared Memory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#correctness-issues">Correctness Issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#wrong-results">Wrong Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#nan-or-inf-values">NaN or Inf Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#performance-issues">Performance Issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#slower-than-pytorch">Slower Than PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#low-gpu-utilization">Low GPU Utilization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#compilation-issues">Compilation Issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#compilation-errors">Compilation Errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#slow-compilation">Slow Compilation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#platform-specific-issues">Platform-Specific Issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#nvidia-specific">NVIDIA-Specific</a></li>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#amd-specific">AMD-Specific</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#multi-gpu-issues">Multi-GPU Issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#wrong-gpu-selected">Wrong GPU Selected</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#debugging-techniques">Debugging Techniques</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#print-debugging">Print Debugging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#profiling">Profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#assertions">Assertions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#unit-testing">Unit Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#common-error-messages">Common Error Messages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#getting-help">Getting Help</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../troubleshooting.html#when-stuck">When Stuck</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#best-practices-for-avoiding-issues">Best Practices for Avoiding Issues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#prevention-checklist">Prevention Checklist</a></li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References and Resources</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../references.html#official-documentation">Official Documentation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../references.html#triton">Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#cuda">CUDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#rocm-amd">ROCm (AMD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#pytorch">PyTorch</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#research-papers">Research Papers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../references.html#flash-attention">Flash Attention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#normalization">Normalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#optimization-techniques">Optimization Techniques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#id1">Triton</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#books">Books</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../references.html#gpu-programming">GPU Programming</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#deep-learning">Deep Learning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#tools-and-profilers">Tools and Profilers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../references.html#nvidia-tools">NVIDIA Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#amd-tools">AMD Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#pytorch-profiler">PyTorch Profiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#benchmarking">Benchmarking</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#online-resources">Online Resources</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../references.html#tutorials-and-courses">Tutorials and Courses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#community">Community</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#blogs-and-articles">Blogs and Articles</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#example-repositories">Example Repositories</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../references.html#triton-examples">Triton Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#production-usage">Production Usage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#hardware-documentation">Hardware Documentation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../references.html#nvidia-gpus">NVIDIA GPUs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#amd-gpus">AMD GPUs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#performance-databases">Performance Databases</a></li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#keeping-up-to-date">Keeping Up to Date</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../references.html#subscribe-to">Subscribe To</a></li>
<li class="toctree-l3"><a class="reference internal" href="../references.html#conferences">Conferences</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#academic-courses">Academic Courses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#contributing">Contributing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#citation">Citation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../references.html#quick-reference">Quick Reference</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Triton GPU Programming Guide</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Why Different Approaches for CPU-bound vs I/O-bound Problems?</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/cpu-concurrency/patterns_problems_mapping.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="why-different-approaches-for-cpu-bound-vs-i-o-bound-problems">
<h1>Why Different Approaches for CPU-bound vs I/O-bound Problems?<a class="headerlink" href="#why-different-approaches-for-cpu-bound-vs-i-o-bound-problems" title="Link to this heading"></a></h1>
<p>A deep dive into the technical reasons behind choosing multiprocessing for CPU-bound tasks and threading/asyncio for I/O-bound tasks in Python.</p>
<section id="table-of-contents">
<h2>Table of Contents<a class="headerlink" href="#table-of-contents" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p><a class="reference external" href="#the-fundamental-problem-the-gil">The Fundamental Problem: The GIL</a></p></li>
<li><p><a class="reference external" href="#how-cpu-and-io-operations-differ">How CPU and I/O Operations Differ</a></p></li>
<li><p><a class="reference external" href="#why-multiprocessing-for-cpu-bound">Why Multiprocessing for CPU-bound</a></p></li>
<li><p><a class="reference external" href="#why-threading-for-io-bound">Why Threading for I/O-bound</a></p></li>
<li><p><a class="reference external" href="#why-asyncio-for-io-bound">Why Asyncio for I/O-bound</a></p></li>
<li><p><a class="reference external" href="#deep-dive-what-happens-under-the-hood">Deep Dive: What Happens Under the Hood</a></p></li>
<li><p><a class="reference external" href="#performance-analysis">Performance Analysis</a></p></li>
<li><p><a class="reference external" href="#decision-tree">Decision Tree</a></p></li>
</ol>
<p>—</p>
</section>
<section id="id1">
<h2>The Fundamental Problem: The GIL<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<section id="what-is-the-gil">
<h3>What is the GIL?<a class="headerlink" href="#what-is-the-gil" title="Link to this heading"></a></h3>
<p>The <strong>Global Interpreter Lock (GIL)</strong> is a mutex (mutual exclusion lock) in CPython that protects access to Python objects, preventing multiple threads from executing Python bytecode simultaneously.</p>
</section>
<section id="why-does-python-have-a-gil">
<h3>Why Does Python Have a GIL?<a class="headerlink" href="#why-does-python-have-a-gil" title="Link to this heading"></a></h3>
<p>Historical Context:
┌─────────────────────────────────────────────┐
│ Python was designed in the late 1980s       │
│ when single-core CPUs were the norm        │
│                                             │
│ Design Decision:                            │
│ • Simple memory management (ref counting)   │
│ • Easy C extension integration              │
│ • Thread-safe by default                    │
│ • Trade-off: One GIL = Simple design       │
└─────────────────────────────────────────────┘</p>
</section>
<section id="how-the-gil-works">
<h3>How the GIL Works<a class="headerlink" href="#how-the-gil-works" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="conceptual-representation-of-gil-behavior">
<h1>Conceptual representation of GIL behavior<a class="headerlink" href="#conceptual-representation-of-gil-behavior" title="Link to this heading"></a></h1>
<dl class="simple">
<dt>Thread 1: [Acquire GIL] → Execute Python Code → [Release GIL]</dt><dd><p>↓</p>
</dd>
</dl>
<p>Thread 2:                    [Waiting…]  → [Acquire GIL] → Execute</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">Key</span> <span class="n">Point</span><span class="o">**</span><span class="p">:</span> <span class="n">Only</span> <span class="n">ONE</span> <span class="n">thread</span> <span class="n">can</span> <span class="n">execute</span> <span class="n">Python</span> <span class="n">bytecode</span> <span class="n">at</span> <span class="n">a</span> <span class="n">time</span><span class="p">,</span> <span class="n">even</span> <span class="n">on</span> <span class="n">a</span> <span class="n">multi</span><span class="o">-</span><span class="n">core</span> <span class="n">CPU</span><span class="o">.</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
<section id="cpu-bound-operation">
<h1>CPU-bound operation<a class="headerlink" href="#cpu-bound-operation" title="Link to this heading"></a></h1>
<dl>
<dt>def cpu*intensive():</dt><dd><p>total = 0
for i in range(10*000*000):</p>
<blockquote>
<div><p>total += i</p>
</div></blockquote>
<p>return total</p>
</dd>
</dl>
</section>
<section id="thread-1-acquires-gil-executes-releases-after-100-bytecodes-repeat">
<h1>Thread 1 acquires GIL → executes → releases after ~100 bytecodes → repeat<a class="headerlink" href="#thread-1-acquires-gil-executes-releases-after-100-bytecodes-repeat" title="Link to this heading"></a></h1>
</section>
<section id="thread-2-waits-acquires-gil-executes-releases-repeat">
<h1>Thread 2 waits → acquires GIL → executes → releases → repeat<a class="headerlink" href="#thread-2-waits-acquires-gil-executes-releases-repeat" title="Link to this heading"></a></h1>
</section>
<section id="result-threads-take-turns-no-parallel-execution">
<h1>Result: Threads take TURNS, no parallel execution<a class="headerlink" href="#result-threads-take-turns-no-parallel-execution" title="Link to this heading"></a></h1>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">..</span> <span class="n">code</span><span class="o">-</span><span class="n">block</span><span class="p">::</span> <span class="n">python</span>
</pre></div>
</div>
</section>
<section id="i-o-bound-operation">
<h1>I/O-bound operation<a class="headerlink" href="#i-o-bound-operation" title="Link to this heading"></a></h1>
<dl class="simple">
<dt>def io*intensive():</dt><dd><p>response = requests.get(’<a class="reference external" href="https://api.example.com/data">https://api.example.com/data</a>’)
return response.json()</p>
</dd>
</dl>
</section>
<section id="thread-1-acquires-gil-starts-i-o-releases-gil-during-i-o-wait">
<h1>Thread 1 acquires GIL → starts I/O → RELEASES GIL during I/O wait<a class="headerlink" href="#thread-1-acquires-gil-starts-i-o-releases-gil-during-i-o-wait" title="Link to this heading"></a></h1>
</section>
<section id="thread-2-can-now-acquire-gil-and-execute-while-thread-1-waits">
<h1>Thread 2 can now acquire GIL and execute while Thread 1 waits<a class="headerlink" href="#thread-2-can-now-acquire-gil-and-execute-while-thread-1-waits" title="Link to this heading"></a></h1>
</section>
<section id="result-threads-can-work-while-others-are-waiting-for-i-o">
<h1>Result: Threads can work while others are waiting for I/O<a class="headerlink" href="#result-threads-can-work-while-others-are-waiting-for-i-o" title="Link to this heading"></a></h1>
<div class="line-block">
<div class="line">Operation Type | GIL Released During Operation? | Result |</div>
</div>
<p><a href="#id19"><span class="problematic" id="id20">|----------------|</span></a>——————————-<a href="#id21"><span class="problematic" id="id22">|--------|</span></a>
| CPU-bound (pure Python) | ❌ No | Threads execute sequentially |
| I/O-bound (network, disk) | ✅ Yes | Threads can work concurrently |
| C extensions (NumPy, etc.) | ✅ Often yes | Can achieve parallelism |</p>
<p>—</p>
<section id="id2">
<h2>How CPU and I/O Operations Differ<a class="headerlink" href="#id2" title="Link to this heading"></a></h2>
<section id="cpu-bound-operations">
<h3>CPU-bound Operations<a class="headerlink" href="#cpu-bound-operations" title="Link to this heading"></a></h3>
<p><strong>Definition</strong>: Operations where execution time is determined by CPU processing speed.</p>
<p><strong>Characteristics</strong>:</p>
<p>CPU Usage:  ████████████████████████ (100%)
I/O Wait:   (minimal or none)
Bottleneck: CPU cycles</p>
<p>Example Timeline:
0ms   ──► Processing ──► Processing ──► Processing ──► Done</p>
<blockquote>
<div><p>(CPU busy)      (CPU busy)      (CPU busy)</p>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">What</span> <span class="n">happens</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<ol class="arabic simple">
<li><p>CPU fetches instructions from memory</p></li>
<li><p>CPU executes mathematical/logical operations</p></li>
<li><p>CPU writes results to memory/registers</p></li>
<li><p>Repeat continuously</p></li>
</ol>
<p><strong>No waiting</strong> - CPU is constantly working.</p>
</section>
<section id="i-o-bound-operations">
<h3>I/O-bound Operations<a class="headerlink" href="#i-o-bound-operations" title="Link to this heading"></a></h3>
<p><strong>Definition</strong>: Operations where execution time is determined by waiting for input/output.</p>
<p><strong>Characteristics</strong>:</p>
<p>CPU Usage:  █▁▁▁▁▁▁▁█▁▁▁▁▁▁▁█ (sporadic, mostly idle)
I/O Wait:   ▁████████▁████████ (most of the time)
Bottleneck: Waiting for external resources</p>
<p>Example Timeline:
0ms   ──► Request ──► Waiting… ──► Waiting… ──► Response ──► Process</p>
<blockquote>
<div><dl class="simple">
<dt>(CPU)        (I/O device)   (I/O device)   (network)   (CPU)</dt><dd><p>100μs           50ms           50ms         100ms      1ms</p>
</dd>
</dl>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">What</span> <span class="n">happens</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<ol class="arabic simple">
<li><p>CPU initiates I/O request (network/disk)</p></li>
<li><p><strong>CPU sits idle waiting</strong> for response</p></li>
<li><p>I/O device/network does the work</p></li>
<li><p>Response arrives</p></li>
<li><p>CPU processes the response (brief)</p></li>
</ol>
<p><strong>Lots of waiting</strong> - CPU is idle most of the time.</p>
</section>
<section id="real-world-analogy">
<h3>Real-World Analogy<a class="headerlink" href="#real-world-analogy" title="Link to this heading"></a></h3>
<p><strong>CPU-bound</strong> (Computing factorial):</p>
<dl class="simple">
<dt>You: Calculate 1000! in your head</dt><dd><p>└─► You must think continuously
└─► Cannot do anything else while thinking
└─► Limited by your brain’s processing speed</p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">I</span><span class="o">/</span><span class="n">O</span><span class="o">-</span><span class="n">bound</span><span class="o">**</span> <span class="p">(</span><span class="n">Ordering</span> <span class="n">pizza</span><span class="p">):</span>
</pre></div>
</div>
<dl class="simple">
<dt>You: Call pizza place → Wait 30 min → Receive pizza</dt><dd><p>└─► Phone call: 1 minute (active)
└─► Waiting: 29 minutes (idle - can do other things!)
└─► Receive: 1 minute (active)
└─► Limited by pizza shop’s speed, not yours</p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---</span>
</pre></div>
</div>
</section>
</section>
<section id="id3">
<h2>Why Multiprocessing for CPU-bound<a class="headerlink" href="#id3" title="Link to this heading"></a></h2>
<section id="the-problem-with-threading-for-cpu-bound">
<h3>The Problem with Threading for CPU-bound<a class="headerlink" href="#the-problem-with-threading-for-cpu-bound" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="cpu-intensive-task-with-threading">
<h1>CPU-intensive task with threading<a class="headerlink" href="#cpu-intensive-task-with-threading" title="Link to this heading"></a></h1>
<p>import threading
import time</p>
<dl class="simple">
<dt>def cpu*work():</dt><dd><p>total = sum(i*i for i in range(10*000*000))
return total</p>
</dd>
</dl>
</section>
<section id="sequential">
<h1>Sequential<a class="headerlink" href="#sequential" title="Link to this heading"></a></h1>
<p>start = time.perf*counter()
cpu*work()
cpu*work()
print(f”Sequential: {time.perf*counter() - start:.2f}s”)
Output: Sequential: 2.50s
=========================</p>
</section>
<section id="threading-same-time-or-worse">
<h1>Threading (SAME TIME OR WORSE!)<a class="headerlink" href="#threading-same-time-or-worse" title="Link to this heading"></a></h1>
<p>start = time.perf*counter()
t1 = threading.Thread(target=cpu*work)
t2 = threading.Thread(target=cpu*work)
t1.start(); t2.start()
t1.join(); t2.join()
print(f”Threading: {time.perf*counter() - start:.2f}s”)
Output: Threading: 2.55s (no improvement!)
==========================================</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>**Why no speedup?**
</pre></div>
</div>
<p>With GIL (Threading):
Core 1: [Thread 1][Thread 2][Thread 1][Thread 2][Thread 1][Thread 2]
Core 2: [idle…………………………………………….]
Core 3: [idle…………………………………………….]
Core 4: [idle…………………………………………….]
Time:   ═══════════════════════════════════════════════════════►</p>
<p>Result: Only using 1 core, taking turns due to GIL</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
<section id="cpu-intensive-task-with-multiprocessing">
<h1>CPU-intensive task with multiprocessing<a class="headerlink" href="#cpu-intensive-task-with-multiprocessing" title="Link to this heading"></a></h1>
<p>from concurrent.futures import ProcessPoolExecutor
import time</p>
<dl class="simple">
<dt>def cpu*work():</dt><dd><p>return sum(i*i for i in range(10*000*000))</p>
</dd>
</dl>
</section>
<section id="multiprocessing">
<h1>Multiprocessing<a class="headerlink" href="#multiprocessing" title="Link to this heading"></a></h1>
<p>start = time.perf*counter()
with ProcessPoolExecutor(max*workers=2) as executor:</p>
<blockquote>
<div><p>futures = [executor.submit(cpu*work) for * in range(2)]
results = [f.result() for f in futures]</p>
</div></blockquote>
<p>print(f”Multiprocessing: {time.perf*counter() - start:.2f}s”)
Output: Multiprocessing: 1.30s (nearly 2x speedup!)
===================================================</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">Why</span> <span class="n">it</span> <span class="n">works</span><span class="p">:</span><span class="o">**</span>
</pre></div>
</div>
<p>Without GIL (Multiprocessing):
Process 1 on Core 1: [████████████████████████] Complete
Process 2 on Core 2: [████████████████████████] Complete
Process 3 on Core 3: [idle]
Process 4 on Core 4: [idle]
Time:                ═════════════════════════►</p>
<p>Result: Using 2 cores in TRUE parallel execution</p>
<p>Each process has:
- <strong>Its own Python interpreter</strong>
- <strong>Its own GIL</strong> (doesn’t interfere with other processes)
- <strong>Its own memory space</strong>
- <strong>Its own process ID</strong></p>
<p>┌──────────────────┐  ┌──────────────────┐  ┌──────────────────┐
│   Process 1      │  │   Process 2      │  │   Process 3      │
│                  │  │                  │  │                  │
│  ┌────────────┐  │  │  ┌────────────┐  │  │  ┌────────────┐  │
│  │ GIL #1     │  │  │  │ GIL #2     │  │  │  │ GIL #3     │  │
│  └────────────┘  │  │  └────────────┘  │  │  └────────────┘  │
│  ┌────────────┐  │  │  ┌────────────┐  │  │  ┌────────────┐  │
│  │ Interpreter│  │  │  │ Interpreter│  │  │  │ Interpreter│  │
│  └────────────┘  │  │  └────────────┘  │  │  └────────────┘  │
│  ┌────────────┐  │  │  ┌────────────┐  │  │  ┌────────────┐  │
│  │   Memory   │  │  │  │   Memory   │  │  │  │   Memory   │  │
│  └────────────┘  │  │  └────────────┘  │  │  └────────────┘  │
└──────────────────┘  └──────────────────┘  └──────────────────┘</p>
<blockquote>
<div><p>CPU Core 1           CPU Core 2           CPU Core 3</p>
</div></blockquote>
<p><strong>Advantages</strong>:
- ✅ True parallelism - uses multiple CPU cores
- ✅ No GIL interference between processes
- ✅ Process isolation (crash in one doesn’t affect others)
- ✅ Can achieve near-linear speedup for CPU-bound tasks</p>
<p><strong>Disadvantages</strong>:
- ❌ Higher memory usage (each process has full Python interpreter)
- ❌ Slower startup time (creating processes is expensive)
- ❌ Inter-process communication is complex and slow
- ❌ Cannot share memory directly (must pickle/unpickle data)</p>
<p>Memory cost per process: ~10-50 MB
Speedup for CPU-bound tasks: 2-8x (depending on cores)</p>
<p>Example:
Task: Process 1000 images (CPU-intensive)
├─ Sequential: 100 seconds
├─ Threading: 100 seconds (no improvement due to GIL)
└─ Multiprocessing (4 cores): 27 seconds</p>
<blockquote>
<div><p>└─ Memory cost: 150 MB vs 50 MB
└─ Worth it? YES! (3.7x speedup for 100MB extra)</p>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---</span>
</pre></div>
</div>
<section id="id4">
<h2>Why Threading for I/O-bound<a class="headerlink" href="#id4" title="Link to this heading"></a></h2>
<section id="the-problem-wasted-time">
<h3>The Problem: Wasted Time<a class="headerlink" href="#the-problem-wasted-time" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="sequential-i-o-operations">
<h1>Sequential I/O operations<a class="headerlink" href="#sequential-i-o-operations" title="Link to this heading"></a></h1>
<p>import requests
import time</p>
<p>urls = [’<a class="reference external" href="https://api1.com">https://api1.com</a>’, ‘<a class="reference external" href="https://api2.com">https://api2.com</a>’, ‘<a class="reference external" href="https://api3.com">https://api3.com</a>’]</p>
<p>start = time.perf*counter()
for url in urls:</p>
<blockquote>
<div><p>response = requests.get(url)  # Takes 2 seconds each
process(response)</p>
</div></blockquote>
<p>print(f”Sequential: {time.perf*counter() - start:.2f}s”)
Output: Sequential: 6.00s (2s + 2s + 2s)
========================================</p>
<p>Timeline:
0s    2s    4s    6s
├─────┼─────┼─────┤
│Wait1│Wait2│Wait3│  ← CPU is IDLE during all this time!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
<section id="threaded-i-o-operations">
<h1>Threaded I/O operations<a class="headerlink" href="#threaded-i-o-operations" title="Link to this heading"></a></h1>
<p>import threading
import requests
import time</p>
<dl class="simple">
<dt>def fetch(url):</dt><dd><p>response = requests.get(url)
process(response)</p>
</dd>
</dl>
<p>urls = [’<a class="reference external" href="https://api1.com">https://api1.com</a>’, ‘<a class="reference external" href="https://api2.com">https://api2.com</a>’, ‘<a class="reference external" href="https://api3.com">https://api3.com</a>’]</p>
<p>start = time.perf*counter()
threads = [threading.Thread(target=fetch, args=(url,)) for url in urls]
for t in threads: t.start()
for t in threads: t.join()
print(f”Threading: {time.perf*counter() - start:.2f}s”)
Output: Threading: 2.05s (all wait in parallel!)
================================================</p>
<p>Timeline:
0s    2s
├─────┤
│Wait1│  ← Thread 1
│Wait2│  ← Thread 2
│Wait3│  ← Thread 3 (all waiting simultaneously)</p>
<p><strong>The GIL is Released During I/O Operations!</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
<section id="what-happens-under-the-hood">
<h1>What happens under the hood:<a class="headerlink" href="#what-happens-under-the-hood" title="Link to this heading"></a></h1>
<dl class="simple">
<dt>Thread 1: [Acquire GIL] → Start network request → [Release GIL] → Wait…</dt><dd><p>↓</p>
</dd>
<dt>Thread 2:                    [Acquire GIL] → Start disk read → [Release GIL]</dt><dd><p>↓</p>
</dd>
</dl>
<p>Thread 3:                                      [Acquire GIL] → Start DB query</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>**Key Insight**: While Thread 1 waits for network I/O, Threads 2 and 3 can start their I/O operations. All three are waiting simultaneously!
</pre></div>
</div>
<p>When Python releases the GIL during I/O:</p>
<dl class="simple">
<dt>Python Thread          Operating System           I/O Device</dt><dd><p>│                        │                        │
│─── Read file ─────────→│                        │
│ [Release GIL]          │─── Send request ──────→│
│                        │                        │
│ (Thread sleeps)        │                     (Working)
│                        │                        │
│                        │←── Data ready ─────────│
│←── Data ready ─────────│                        │
│ [Acquire GIL]          │                        │
│─── Process data        │                        │</p>
</dd>
</dl>
<p>The OS handles I/O asynchronously while the thread waits, allowing other threads to work.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
<section id="real-example-downloading-10-web-pages">
<h1>Real example: Downloading 10 web pages<a class="headerlink" href="#real-example-downloading-10-web-pages" title="Link to this heading"></a></h1>
<p>Sequential (1 thread):
├─ Page 1: 0.5s
├─ Page 2: 0.5s
├─ …
└─ Page 10: 0.5s
Total: 5.0 seconds</p>
<p>Threading (10 threads):
├─ All pages: 0.5s (in parallel)
└─ Total: 0.5 seconds</p>
<p>Speedup: 10x! (near-perfect for I/O-bound)</p>
<p>Threading for I/O:
├─ Memory: 50 MB (one process, 10 threads)
├─ Startup: Instant (threads are lightweight)
├─ Communication: Shared memory (easy)
└─ Performance: 10x speedup</p>
<p>Multiprocessing for I/O:
├─ Memory: 500 MB (10 processes × 50 MB each)
├─ Startup: Slow (creating 10 processes)
├─ Communication: IPC (complex, slow)
└─ Performance: 10x speedup (same as threading!)</p>
<p>Verdict: Threading is MORE EFFICIENT for I/O</p>
<p><strong>Advantages</strong>:
- ✅ Lightweight (minimal memory overhead)
- ✅ Fast to create/destroy
- ✅ Easy data sharing (shared memory)
- ✅ Perfect for I/O-bound tasks</p>
<p><strong>Disadvantages</strong>:
- ❌ No speedup for CPU-bound tasks (GIL)
- ❌ Race conditions possible with shared state
- ❌ More complex debugging
- ❌ Limited by GIL for Python code execution</p>
<p>—</p>
<section id="id5">
<h2>Why Asyncio for I/O-bound<a class="headerlink" href="#id5" title="Link to this heading"></a></h2>
<section id="the-problem-with-threading-overhead">
<h3>The Problem with Threading: Overhead<a class="headerlink" href="#the-problem-with-threading-overhead" title="Link to this heading"></a></h3>
<p>Creating 10,000 threads:
├─ Memory: 10,000 threads × 8 MB stack = 80 GB! (impossible)
├─ Context switching: OS must switch between 10,000 threads
├─ Overhead: Significant CPU time spent on thread management
└─ Result: System becomes unresponsive</p>
<p>Creating 10,000 asyncio tasks:
├─ Memory: ~10-100 MB total (tasks are lightweight)
├─ Context switching: Controlled by Python (no OS involvement)
├─ Overhead: Minimal
└─ Result: Efficient and responsive</p>
</section>
<section id="asyncio-cooperative-multitasking">
<h3>Asyncio: Cooperative Multitasking<a class="headerlink" href="#asyncio-cooperative-multitasking" title="Link to this heading"></a></h3>
<p><strong>Threading</strong> (Preemptive - OS decides when to switch):</p>
<p>OS: “Thread 1, you’ve used enough CPU, I’m switching to Thread 2”
Thread 1: “But I’m not done!”
OS: “Too bad, Thread 2’s turn now”</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">Asyncio</span><span class="o">**</span> <span class="p">(</span><span class="n">Cooperative</span> <span class="o">-</span> <span class="n">code</span> <span class="n">decides</span> <span class="n">when</span> <span class="n">to</span> <span class="k">yield</span><span class="p">):</span>
</pre></div>
</div>
<p>Task 1: “I’m about to wait for network, let me yield control”
Event Loop: “Thanks! I’ll run Task 2 now”
Task 2: “I’m about to wait for disk, let me yield”
Event Loop: “Got it! I’ll check if Task 1’s network response arrived”</p>
</section>
<section id="how-asyncio-works">
<h3>How Asyncio Works<a class="headerlink" href="#how-asyncio-works" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="asyncio-example-10-000-concurrent-requests">
<h1>Asyncio example: 10,000 concurrent requests<a class="headerlink" href="#asyncio-example-10-000-concurrent-requests" title="Link to this heading"></a></h1>
<p>import asyncio
import aiohttp</p>
<dl>
<dt>async def fetch(session, url):</dt><dd><dl class="simple">
<dt>async with session.get(url) as response:</dt><dd><p>return await response.text()</p>
</dd>
</dl>
</dd>
<dt>async def main():</dt><dd><p>urls = [f’<a class="reference external" href="https://api.example.com/item">https://api.example.com/item</a>/{i}’ for i in range(10000)]
async with aiohttp.ClientSession() as session:</p>
<blockquote>
<div><p>tasks = [fetch(session, url) for url in urls]
results = await asyncio.gather(<a href="#id6"><span class="problematic" id="id7">*</span></a>tasks)</p>
</div></blockquote>
</dd>
</dl>
<p>asyncio.run(main())
Can handle 10,000 requests efficiently!
=======================================</p>
<p>Event Loop (Single Thread):
┌─────────────────────────────────────────────────────────┐
│                                                         │
│  Ready Queue: [Task 1, Task 5, Task 12, …]          │
│                                                         │
│  Waiting for I/O: {Task 2: socket 1,                   │
│                    Task 3: socket 2,                   │
│                    Task 4: socket 3, …}              │
│                                                         │
│  Flow:                                                  │
│  1. Get next ready task                                │
│  2. Run until it awaits something                      │
│  3. Check which I/O operations completed               │
│  4. Move completed tasks to ready queue                │
│  5. Repeat                                             │
│                                                         │
└─────────────────────────────────────────────────────────┘</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
<section id="threading-approach">
<h1>Threading approach<a class="headerlink" href="#threading-approach" title="Link to this heading"></a></h1>
<p>import threading
import requests</p>
<dl class="simple">
<dt>def fetch*url(url):</dt><dd><p>response = requests.get(url)
return response.text</p>
</dd>
</dl>
<p>urls = [f’<a class="reference external" href="https://api.example.com">https://api.example.com</a>/{i}’ for i in range(1000)]
threads = [threading.Thread(target=fetch*url, args=(url,)) for url in urls]</p>
</section>
<section id="problem-creating-1000-threads">
<h1>Problem: Creating 1000 threads!<a class="headerlink" href="#problem-creating-1000-threads" title="Link to this heading"></a></h1>
</section>
<section id="memory-8-gb-1000-8-mb-stack-per-thread">
<h1>Memory: ~8 GB (1000 × 8 MB stack per thread)<a class="headerlink" href="#memory-8-gb-1000-8-mb-stack-per-thread" title="Link to this heading"></a></h1>
</section>
<section id="os-overhead-managing-1000-threads">
<h1>OS overhead: Managing 1000 threads<a class="headerlink" href="#os-overhead-managing-1000-threads" title="Link to this heading"></a></h1>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">..</span> <span class="n">code</span><span class="o">-</span><span class="n">block</span><span class="p">::</span> <span class="n">python</span>
</pre></div>
</div>
</section>
<section id="asyncio-approach">
<h1>Asyncio approach<a class="headerlink" href="#asyncio-approach" title="Link to this heading"></a></h1>
<p>import asyncio
import aiohttp</p>
<dl>
<dt>async def fetch*url(session, url):</dt><dd><dl class="simple">
<dt>async with session.get(url) as response:</dt><dd><p>return await response.text()</p>
</dd>
</dl>
</dd>
<dt>async def main():</dt><dd><p>urls = [f’<a class="reference external" href="https://api.example.com">https://api.example.com</a>/{i}’ for i in range(1000)]
async with aiohttp.ClientSession() as session:</p>
<blockquote>
<div><p>tasks = [fetch*url(session, url) for url in urls]
results = await asyncio.gather(<a href="#id8"><span class="problematic" id="id9">*</span></a>tasks)</p>
</div></blockquote>
</dd>
</dl>
<p>asyncio.run(main())</p>
</section>
<section id="solution-single-thread-1000-lightweight-tasks">
<h1>Solution: Single thread, 1000 lightweight tasks<a class="headerlink" href="#solution-single-thread-1000-lightweight-tasks" title="Link to this heading"></a></h1>
</section>
<section id="memory-50-mb-total">
<h1>Memory: ~50 MB total<a class="headerlink" href="#memory-50-mb-total" title="Link to this heading"></a></h1>
</section>
<section id="os-overhead-none-all-managed-by-python">
<h1>OS overhead: None (all managed by Python)<a class="headerlink" href="#os-overhead-none-all-managed-by-python" title="Link to this heading"></a></h1>
<div class="line-block">
<div class="line">Metric | Threading (1000 ops) | Asyncio (1000 ops) |</div>
</div>
<p><a href="#id23"><span class="problematic" id="id24">|--------|</span></a>———————<a href="#id25"><span class="problematic" id="id26">|-------------------|</span></a>
| Memory Usage | ~8 GB | ~50 MB |
| Context Switch | OS-level (slow) | Python-level (fast) |
| Scalability | ~1000s | ~100,000s |
| Startup Time | Slow (create threads) | Fast (create tasks) |
| CPU Overhead | High (OS scheduling) | Low (event loop) |</p>
<p><strong>Perfect for</strong>:</p>
<p>✅ Web servers (handle many simultaneous connections)
✅ Web scraping (thousands of HTTP requests)
✅ Database queries (many concurrent queries)
✅ Microservices (coordinating many API calls)
✅ Chat applications (many idle connections)
✅ IoT systems (many devices sending data)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">Not</span> <span class="n">ideal</span> <span class="k">for</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<p>❌ CPU-intensive tasks (use multiprocessing)
❌ Blocking libraries (must use async-compatible libraries)
❌ Simple scripts with few I/O operations (threading is simpler)</p>
<p><strong>Advantages</strong>:
- ✅ Extremely lightweight (handle 100,000+ concurrent operations)
- ✅ Low memory overhead
- ✅ Fast context switching (Python-level)
- ✅ Single-threaded (no race conditions)
- ✅ Explicit concurrency (clear control flow with <code class="docutils literal notranslate"><span class="pre">await</span></code>)</p>
<p><strong>Disadvantages</strong>:
- ❌ Requires async-compatible libraries (can’t use standard <code class="docutils literal notranslate"><span class="pre">requests</span></code>, etc.)
- ❌ Learning curve (async/await paradigm)
- ❌ Viral nature (once you go async, everything must be async)
- ❌ No speedup for CPU-bound tasks
- ❌ One blocking operation blocks everything</p>
<p>—</p>
<section id="id10">
<h2>Deep Dive: What Happens Under the Hood<a class="headerlink" href="#id10" title="Link to this heading"></a></h2>
<section id="cpu-bound-with-threading-the-gil-dance">
<h3>CPU-bound with Threading: The GIL Dance<a class="headerlink" href="#cpu-bound-with-threading-the-gil-dance" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="example-two-threads-computing-sum">
<h1>Example: Two threads computing sum<a class="headerlink" href="#example-two-threads-computing-sum" title="Link to this heading"></a></h1>
<p>import threading</p>
<dl>
<dt>def compute*sum(n):</dt><dd><p>total = 0
for i in range(n):</p>
<blockquote>
<div><p>total += i</p>
</div></blockquote>
<p>return total</p>
</dd>
</dl>
<p>t1 = threading.Thread(target=compute*sum, args=(10*000*000,))
t2 = threading.Thread(target=compute*sum, args=(10*000*000,))</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">What</span> <span class="n">actually</span> <span class="n">happens</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<p>Time →
0ms    Thread 1: [Acquire GIL]
1ms              : Execute: total = 0
2ms              : Execute: total += 1
3ms              : Execute: total += 2
…
100ms            : [Release GIL] (every ~100 bytecodes or 5ms)
100ms  Thread 2:                 [Acquire GIL]
101ms            :                 Execute: total = 0
102ms            :                 Execute: total += 1
…
200ms            :                 [Release GIL]
200ms  Thread 1: [Acquire GIL]
…
(continues alternating)</p>
<p>Result: Threads take turns executing Python bytecode
No parallelism for CPU work!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>from concurrent.futures import ProcessPoolExecutor</p>
<dl>
<dt>def compute*sum(n):</dt><dd><p>total = 0
for i in range(n):</p>
<blockquote>
<div><p>total += i</p>
</div></blockquote>
<p>return total</p>
</dd>
<dt>with ProcessPoolExecutor(max*workers=2) as executor:</dt><dd><p>future1 = executor.submit(compute*sum, 10*000*000)
future2 = executor.submit(compute*sum, 10*000*000)</p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">What</span> <span class="n">actually</span> <span class="n">happens</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<p>Time →
0ms    Process 1 (Core 1): [Start] Create interpreter, load code
10ms                       : Execute: total = 0
11ms                       : Execute: total += 1
12ms                       : Execute: total += 2
…
1000ms                     : [Done] Return result via pipe</p>
<p>0ms    Process 2 (Core 2): [Start] Create interpreter, load code
10ms                       : Execute: total = 0
11ms                       : Execute: total += 1
12ms                       : Execute: total += 2
…
1000ms                     : [Done] Return result via pipe</p>
<p>Result: Both processes execute SIMULTANEOUSLY on different cores
True parallelism!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>import threading
import requests</p>
<dl class="simple">
<dt>def fetch*url(url):</dt><dd><p>response = requests.get(url)  # I/O operation
return response.text</p>
</dd>
</dl>
<p>t1 = threading.Thread(target=fetch*url, args=(’<a class="reference external" href="https://api1.com">https://api1.com</a>’,))
t2 = threading.Thread(target=fetch*url, args=(’<a class="reference external" href="https://api2.com">https://api2.com</a>’,))</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">What</span> <span class="n">actually</span> <span class="n">happens</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<p>Time →
0ms    Thread 1: [Acquire GIL]
1ms             : Prepare HTTP request
2ms             : [Release GIL] ← Call to C library (requests)
2ms             : [OS: Send network packet]
3ms             : [OS: Waiting for response…]</p>
<p>2ms    Thread 2:                [Acquire GIL] ← Can run while T1 waits!
3ms             :                Prepare HTTP request
4ms             :                [Release GIL] ← Call to C library
4ms             :                [OS: Send network packet]
5ms             :                [OS: Waiting for response…]</p>
<p>200ms           : [OS: T1’s response arrives]
200ms  Thread 1: [Acquire GIL]
201ms           : Process response
202ms           : [Done]</p>
<p>210ms           : [OS: T2’s response arrives]
210ms  Thread 2: [Acquire GIL]
211ms           : Process response
212ms           : [Done]</p>
<p>Result: Both threads waited concurrently (overlapped I/O)
Total time: ~210ms instead of 400ms sequential</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>import asyncio
import aiohttp</p>
<dl class="simple">
<dt>async def fetch*url(session, url):</dt><dd><dl class="simple">
<dt>async with session.get(url) as response:</dt><dd><p>return await response.text()</p>
</dd>
</dl>
</dd>
<dt>async def main():</dt><dd><dl class="simple">
<dt>async with aiohttp.ClientSession() as session:</dt><dd><p>task1 = asyncio.create*task(fetch*url(session, ‘<a class="reference external" href="https://api1.com">https://api1.com</a>’))
task2 = asyncio.create*task(fetch*url(session, ‘<a class="reference external" href="https://api2.com">https://api2.com</a>’))
results = await asyncio.gather(task1, task2)</p>
</dd>
</dl>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">What</span> <span class="n">actually</span> <span class="n">happens</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<p>Time → (Single Thread)
0ms    Event Loop: Create task1
1ms              : Create task2
2ms              : Run task1 until await
3ms    Task 1   : Send HTTP request
4ms              : await response.get() ← Yields control
4ms    Event Loop: task1 waiting for I/O, switch to task2
5ms    Task 2   : Send HTTP request
6ms              : await response.get() ← Yields control
6ms    Event Loop: Both tasks waiting, check I/O status
…
200ms  Event Loop: task1’s I/O completed
200ms  Task 1   : Process response
201ms            : Return result
201ms  Event Loop: task1 done, check task2
210ms  Event Loop: task2’s I/O completed
210ms  Task 2   : Process response
211ms            : Return result
212ms  Event Loop: Both tasks done, gather returns</p>
<p>Result: Single thread efficiently managing multiple I/O operations
No thread overhead, same concurrency benefit</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---</span>
</pre></div>
</div>
<section id="id11">
<h2>Performance Analysis<a class="headerlink" href="#id11" title="Link to this heading"></a></h2>
<section id="benchmark-cpu-bound-task-computing">
<h3>Benchmark: CPU-bound Task (Computing π)<a class="headerlink" href="#benchmark-cpu-bound-task-computing" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<dl>
<dt>def compute*pi(iterations):</dt><dd><p>“””CPU-intensive: Monte Carlo π approximation”””
inside = 0
for * in range(iterations):</p>
<blockquote>
<div><p>x, y = random.random(), random.random()
if x*x + y*y &lt;= 1:</p>
<blockquote>
<div><p>inside += 1</p>
</div></blockquote>
</div></blockquote>
<p>return 4 * inside / iterations</p>
</dd>
</dl>
<p>ITERATIONS = 10*000*000
TASKS = 4</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">Results</span> <span class="n">on</span> <span class="mi">4</span><span class="o">-</span><span class="n">core</span> <span class="n">CPU</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<div class="line-block">
<div class="line">Approach | Time | Speedup | Memory |</div>
</div>
<p><a href="#id27"><span class="problematic" id="id28">|----------|</span></a>——<a href="#id29"><span class="problematic" id="id30">|---------|</span></a>———|
| Sequential | 10.0s | 1.0x | 50 MB |
| Threading (4 threads) | 10.2s | 0.98x ❌ | 55 MB |
| Asyncio (4 tasks) | 10.1s | 0.99x ❌ | 52 MB |
| Multiprocessing (4 proc) | 2.7s | 3.7x ✅ | 200 MB |</p>
<p><strong>Analysis</strong>:
- Threading/Asyncio: No improvement (GIL limitation)
- Multiprocessing: Near-linear speedup (3.7x on 4 cores)
- Memory trade-off is worth it for 3.7x speedup</p>
</section>
<section id="benchmark-i-o-bound-task-web-requests">
<h3>Benchmark: I/O-bound Task (Web Requests)<a class="headerlink" href="#benchmark-i-o-bound-task-web-requests" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<dl>
<dt>async def fetch*page(session, url):</dt><dd><p>“””I/O-intensive: Download web page”””
async with session.get(url) as response:</p>
<blockquote>
<div><p>return await response.text()</p>
</div></blockquote>
</dd>
</dl>
<p>URLS = 100 (each takes ~0.5s to fetch)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">Results</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<div class="line-block">
<div class="line">Approach | Time | Speedup | Memory | Max Concurrent |</div>
</div>
<p><a href="#id31"><span class="problematic" id="id32">|----------|</span></a>——<a href="#id33"><span class="problematic" id="id34">|---------|</span></a>———<a href="#id35"><span class="problematic" id="id36">|----------------|</span></a>
| Sequential | 50.0s | 1.0x | 50 MB | 1 |
| Threading (10 threads) | 5.2s | 9.6x ✅ | 130 MB | 10 |
| Threading (100 threads) | 1.8s | 27.8x ✅ | 850 MB | 100 |
| Asyncio (100 tasks) | 1.5s | 33.3x ✅ | 65 MB | 100 |
| Multiprocessing (4 proc) | 13.0s | 3.8x ❌ | 200 MB | 4 |</p>
<p><strong>Analysis</strong>:
- Threading: Good speedup, but memory grows with threads
- Asyncio: Best speedup with lowest memory
- Multiprocessing: Poor choice (high overhead, limited concurrency)</p>
</section>
<section id="benchmark-mixed-workload">
<h3>Benchmark: Mixed Workload<a class="headerlink" href="#benchmark-mixed-workload" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<dl>
<dt>async def process*data(session, url):</dt><dd><p>“””Fetch data (I/O) then process (CPU)”””
# I/O: Fetch data (2 seconds)
async with session.get(url) as response:</p>
<blockquote>
<div><p>data = await response.json()</p>
</div></blockquote>
<p># CPU: Heavy processing (1 second)
result = complex*computation(data)
return result</p>
</dd>
</dl>
<p>TASKS = 10</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">Results</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<div class="line-block">
<div class="line">Approach | Time | Analysis |</div>
</div>
<p><a href="#id37"><span class="problematic" id="id38">|----------|</span></a>——<a href="#id39"><span class="problematic" id="id40">|----------|</span></a>
| Sequential | 30.0s | (2s I/O + 1s CPU) × 10 |
| Threading | 15.5s | I/O concurrent, CPU sequential |
| Asyncio | 15.2s | I/O concurrent, CPU sequential |
| Asyncio + ProcessPool | 5.8s | I/O concurrent, CPU parallel ✅ |</p>
<p><strong>Best approach for mixed workload</strong>:
.. code-block:: python</p>
<p>import asyncio
from concurrent.futures import ProcessPoolExecutor</p>
<dl>
<dt>async def process*data(session, url, executor):</dt><dd><p># I/O: Use asyncio
async with session.get(url) as response:</p>
<blockquote>
<div><p>data = await response.json()</p>
</div></blockquote>
<p># CPU: Offload to process pool
loop = asyncio.get*event*loop()
result = await loop.run*in*executor(executor, complex*computation, data)
return result</p>
</dd>
<dt>async def main():</dt><dd><dl class="simple">
<dt>with ProcessPoolExecutor(max*workers=4) as executor:</dt><dd><dl class="simple">
<dt>async with aiohttp.ClientSession() as session:</dt><dd><p>tasks = [process*data(session, url, executor) for url in urls]
results = await asyncio.gather(<a href="#id12"><span class="problematic" id="id13">*</span></a>tasks)</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---</span>
</pre></div>
</div>
</section>
</section>
<section id="id14">
<h2>Decision Tree<a class="headerlink" href="#id14" title="Link to this heading"></a></h2>
<p>Use this decision tree to choose the right approach:</p>
<p>Start: What type of operation?
│
├─ CPU-bound (math, data processing, compression)
│  │
│  ├─ How many tasks?
│  │  ├─ Single task → Sequential (simplest)
│  │  └─ Multiple tasks → Multiprocessing
│  │
│  └─ How many CPU cores available?
│     ├─ 1 core → Sequential (multiprocessing won’t help)
│     └─ 2+ cores → Multiprocessing (use max*workers = CPU cores)
│
└─ I/O-bound (network, disk, database)</p>
<blockquote>
<div><p>│
├─ How many concurrent operations?
│  │
│  ├─ Few (&lt; 50)
│  │  ├─ Using blocking libraries? → Threading
│  │  └─ Can use async libraries? → Asyncio (preferred)
│  │
│  ├─ Many (50-1000)
│  │  └─ Asyncio (threading becomes expensive)
│  │
│  └─ Very many (&gt; 1000)
│     └─ Asyncio (threading impossible)
│
└─ Do you need simplicity or scalability?</p>
<blockquote>
<div><p>├─ Simplicity → Threading (easier to understand)
└─ Scalability → Asyncio (better performance)</p>
</div></blockquote>
</div></blockquote>
<section id="quick-reference-table">
<h3>Quick Reference Table<a class="headerlink" href="#quick-reference-table" title="Link to this heading"></a></h3>
<div class="line-block">
<div class="line">Scenario | Solution | Reason |</div>
</div>
<p><a href="#id41"><span class="problematic" id="id42">|----------|</span></a>———-<a href="#id43"><span class="problematic" id="id44">|--------|</span></a>
| Image processing (1000 images) | Multiprocessing | CPU-bound, benefits from parallel cores |
| Web scraping (100 pages) | Asyncio | I/O-bound, many concurrent connections |
| REST API server | Asyncio | I/O-bound, handle many simultaneous requests |
| Video encoding | Multiprocessing | CPU-intensive, utilize all cores |
| Database queries (10 concurrent) | Threading | I/O-bound, simple implementation |
| Database queries (1000 concurrent) | Asyncio | I/O-bound, need high concurrency |
| File downloads (5 files) | Threading | I/O-bound, blocking library OK |
| WebSocket server (10000 clients) | Asyncio | I/O-bound, need extreme scalability |
| Scientific computation | Multiprocessing | CPU-intensive calculations |
| Real-time chat (1000 users) | Asyncio | I/O-bound, many idle connections |</p>
</section>
<section id="code-templates">
<h3>Code Templates<a class="headerlink" href="#code-templates" title="Link to this heading"></a></h3>
<p><strong>CPU-bound Template</strong>:
.. code-block:: python</p>
<p>from concurrent.futures import ProcessPoolExecutor
import os</p>
<dl>
<dt>def cpu*intensive*task(data):</dt><dd><p># Your CPU-heavy computation here
result = complex*calculation(data)
return result</p>
</dd>
<dt>def main():</dt><dd><p>data*items = […]  # Your data</p>
<p># Use number of CPU cores
max*workers = os.cpu*count()</p>
<dl class="simple">
<dt>with ProcessPoolExecutor(max*workers=max*workers) as executor:</dt><dd><p>results = executor.map(cpu*intensive*task, data*items)</p>
</dd>
</dl>
<p>return list(results)</p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">I</span><span class="o">/</span><span class="n">O</span><span class="o">-</span><span class="n">bound</span> <span class="n">Template</span> <span class="p">(</span><span class="n">Few</span> <span class="n">operations</span><span class="p">,</span> <span class="n">blocking</span> <span class="n">library</span><span class="p">)</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>from concurrent.futures import ThreadPoolExecutor
import requests</p>
<dl>
<dt>def io*intensive*task(url):</dt><dd><p>response = requests.get(url)
return process(response)</p>
</dd>
<dt>def main():</dt><dd><p>urls = […]  # Your URLs</p>
<dl class="simple">
<dt>with ThreadPoolExecutor(max*workers=10) as executor:</dt><dd><p>results = executor.map(io*intensive*task, urls)</p>
</dd>
</dl>
<p>return list(results)</p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">I</span><span class="o">/</span><span class="n">O</span><span class="o">-</span><span class="n">bound</span> <span class="n">Template</span> <span class="p">(</span><span class="n">Many</span> <span class="n">operations</span><span class="p">,</span> <span class="k">async</span> <span class="n">library</span><span class="p">)</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>import asyncio
import aiohttp</p>
<dl>
<dt>async def io*intensive*task(session, url):</dt><dd><dl class="simple">
<dt>async with session.get(url) as response:</dt><dd><p>data = await response.text()
return process(data)</p>
</dd>
</dl>
</dd>
<dt>async def main():</dt><dd><p>urls = […]  # Your URLs</p>
<dl class="simple">
<dt>async with aiohttp.ClientSession() as session:</dt><dd><p>tasks = [io*intensive*task(session, url) for url in urls]
results = await asyncio.gather(<a href="#id15"><span class="problematic" id="id16">*</span></a>tasks)</p>
</dd>
</dl>
<p>return results</p>
</dd>
<dt>if _*name** == ‘<strong>main</strong>’:</dt><dd><p>asyncio.run(main())</p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">**</span><span class="n">Mixed</span> <span class="n">Workload</span> <span class="n">Template</span><span class="o">**</span><span class="p">:</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>import asyncio
import aiohttp
from concurrent.futures import ProcessPoolExecutor</p>
<dl>
<dt>def cpu*intensive(data):</dt><dd><p># CPU-heavy work here
return complex*calculation(data)</p>
</dd>
<dt>async def mixed*task(session, url, executor):</dt><dd><p># I/O part (async)
async with session.get(url) as response:</p>
<blockquote>
<div><p>data = await response.json()</p>
</div></blockquote>
<p># CPU part (process pool)
loop = asyncio.get*event*loop()
result = await loop.run*in*executor(executor, cpu*intensive, data)</p>
<p>return result</p>
</dd>
<dt>async def main():</dt><dd><p>urls = […]</p>
<dl class="simple">
<dt>with ProcessPoolExecutor(max*workers=4) as executor:</dt><dd><dl class="simple">
<dt>async with aiohttp.ClientSession() as session:</dt><dd><p>tasks = [mixed*task(session, url, executor) for url in urls]
results = await asyncio.gather(<a href="#id17"><span class="problematic" id="id18">*</span></a>tasks)</p>
</dd>
</dl>
</dd>
</dl>
<p>return results</p>
</dd>
<dt>if <strong>name</strong> == ‘<strong>main</strong>’:</dt><dd><p>asyncio.run(main())</p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---</span>
</pre></div>
</div>
</section>
</section>
<section id="summary-the-core-principles">
<h2>Summary: The Core Principles<a class="headerlink" href="#summary-the-core-principles" title="Link to this heading"></a></h2>
<section id="the-gil-controls-everything">
<h3>1. The GIL Controls Everything<a class="headerlink" href="#the-gil-controls-everything" title="Link to this heading"></a></h3>
<p>Python’s GIL:
├─ Allows only ONE thread to execute Python bytecode at a time
├─ Released during I/O operations (C library calls)
└─ Not present in separate processes (each has own GIL)</p>
<p>Therefore:
├─ CPU-bound + Threading = No parallelism (GIL bottleneck)
├─ I/O-bound + Threading = Concurrency (GIL released during I/O)
└─ CPU-bound + Multiprocessing = Parallelism (separate GILs)</p>
</section>
<section id="resource-usage-matters">
<h3>2. Resource Usage Matters<a class="headerlink" href="#resource-usage-matters" title="Link to this heading"></a></h3>
<p>Operation Type  │  Resource Bottleneck  │  Solution  │  Why?
────────────────┼──────────────────────┼────────────┼──────────────────
CPU-bound       │  CPU cycles          │  Multi-    │  Bypass GIL,</p>
<blockquote>
<div><p>│  (computation)       │  processing│  use all cores</p>
</div></blockquote>
<p>────────────────┼──────────────────────┼────────────┼──────────────────
I/O-bound       │  Waiting for I/O     │  Asyncio/  │  GIL released,
(few ops)       │  (network, disk)     │  Threading │  work during wait
────────────────┼──────────────────────┼────────────┼──────────────────
I/O-bound       │  Waiting for I/O     │  Asyncio   │  Lightweight,
(many ops)      │  + scalability       │            │  handles 1000s</p>
</section>
<section id="trade-offs-are-real">
<h3>3. Trade-offs are Real<a class="headerlink" href="#trade-offs-are-real" title="Link to this heading"></a></h3>
<p><strong>Multiprocessing</strong>:
- Pros: True parallelism, bypasses GIL
- Cons: Memory overhead, slow startup, complex IPC
- <strong>Use when</strong>: CPU-bound work benefits &gt; memory cost</p>
<p><strong>Threading</strong>:
- Pros: Lightweight, easy data sharing, fast startup
- Cons: No speedup for CPU work, race conditions possible
- <strong>Use when</strong>: I/O-bound with moderate concurrency</p>
<p><strong>Asyncio</strong>:
- Pros: Extremely lightweight, handles 100,000+ operations
- Cons: Requires async libraries, learning curve
- <strong>Use when</strong>: I/O-bound with high concurrency</p>
</section>
<section id="know-your-workload">
<h3>4. Know Your Workload<a class="headerlink" href="#know-your-workload" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="profile-your-code-first">
<h1>Profile your code first!<a class="headerlink" href="#profile-your-code-first" title="Link to this heading"></a></h1>
<p>import time</p>
<dl>
<dt>def profile*task(task*func):</dt><dd><p># CPU time (actual processing)
cpu*start = time.process*time()
# Wall time (including waiting)
wall*start = time.perf*counter()</p>
<p>result = task*func()</p>
<p>cpu*time = time.process*time() - cpu*start
wall*time = time.perf*counter() - wall*start</p>
<dl class="simple">
<dt>if cpu*time / wall*time &gt; 0.8:</dt><dd><p>print(“CPU-bound → Use multiprocessing”)</p>
</dd>
<dt>else:</dt><dd><p>print(“I/O-bound → Use asyncio/threading”)</p>
</dd>
</dl>
<p>return result</p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---</span>
</pre></div>
</div>
<section id="final-thoughts">
<h2>Final Thoughts<a class="headerlink" href="#final-thoughts" title="Link to this heading"></a></h2>
<p>The choice between multiprocessing, threading, and asyncio isn’t about which is “better” - it’s about matching the tool to the task:</p>
<ul class="simple">
<li><p><strong>Multiprocessing</strong>: Powerful but heavy. Use when you need true parallel CPU computation.</p></li>
<li><p><strong>Threading</strong>: Simple and effective for I/O. Use when blocking libraries are needed.</p></li>
<li><p><strong>Asyncio</strong>: Lightweight and scalable for I/O. Use when you need to handle many concurrent operations.</p></li>
</ul>
<p>Understanding the GIL and how Python interacts with the OS is key to making the right choice. Always profile your code, measure the results, and choose based on your specific requirements.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="semaphore_explained.html" class="btn btn-neutral float-left" title="Semaphore Explained" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../gpu-concepts/gpu-fundamentals.html" class="btn btn-neutral float-right" title="GPU Fundamentals" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Fast Concurrent Programs.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>