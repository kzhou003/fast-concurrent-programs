

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>CUDA Out of Memory &mdash; Triton GPU Programming Guide 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=f2a433a1"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Triton" href="references.html" />
    <link rel="prev" title="By Topic" href="learning-paths.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Triton GPU Programming Guide
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">CPU Concurrency</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html">Concurrency</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#parallelism">Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#visual-comparison">Visual Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#threading-concurrent-futures-threadpoolexecutor">Threading (concurrent.futures.ThreadPoolExecutor)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#multiprocessing-concurrent-futures-processpoolexecutor">Multiprocessing (concurrent.futures.ProcessPoolExecutor)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#when-to-use-what">When to Use What</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#what-is-the-gil">What is the GIL?</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#key-points">Key Points:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#impact-on-performance">Impact on Performance:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#observing-the-gil-from-script-06">Observing the GIL (from script 06):</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#event-loop">Event Loop</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#how-it-works-from-script-07">How It Works (from script 07):</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#event-loop-lifecycle">Event Loop Lifecycle:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#modern-vs-old-patterns">Modern vs Old Patterns:</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/key_concepts.html#id1">Coroutines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#what-are-coroutines">What are Coroutines?</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#defining-coroutines">Defining Coroutines:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#key-features">Key Features:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#example-from-script-08">Example from Script 08:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#execution-flow">Execution Flow:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#important-rules">Important Rules:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#tasks">Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#task-characteristics">Task Characteristics:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#example-from-script-09">Example from Script 09:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#futures">Futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#waiting-for-multiple-tasks">Waiting for Multiple Tasks:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#cpu-bound-operations">CPU-bound Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#i-o-bound-operations">I/O-bound Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#comparison-table">Comparison Table:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#hybrid-workloads">Hybrid Workloads:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#time-measurement-time-clock-time-perf-counter">1. Time Measurement (<code class="docutils literal notranslate"><span class="pre">time.clock()</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">time.perf_counter()</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#coroutine-syntax-asyncio-coroutine-async-def">2. Coroutine Syntax (<code class="docutils literal notranslate"><span class="pre">&#64;asyncio.coroutine</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">async</span> <span class="pre">def</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#task-creation-asyncio-task-asyncio-create-task">3. Task Creation (<code class="docutils literal notranslate"><span class="pre">asyncio.Task()</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">asyncio.create_task()</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#event-loop-management">4. Event Loop Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#future-callbacks-callbacks-await">5. Future Callbacks (Callbacks -&gt; <code class="docutils literal notranslate"><span class="pre">await</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#blocking-calls-in-async-code">6. Blocking Calls in Async Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#string-formatting-f-strings">7. String Formatting (<code class="docutils literal notranslate"><span class="pre">%</span></code> -&gt; f-strings)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#migration-checklist">Migration Checklist</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#compatibility">Compatibility</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/key_concepts.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#quick-reference-guide">Quick Reference Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/key_concepts.html#further-reading">Further Reading</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html">Physical Cores</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#logical-cores">Logical Cores</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#the-concept">The Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#how-it-works">How It Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#technical-implementation">Technical Implementation</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#performance-characteristics">Performance Characteristics</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#hyperthreading-limitations">Hyperthreading Limitations</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#checking-hyperthreading-status">Checking Hyperthreading Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#the-fundamental-constraint">The Fundamental Constraint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#why-more-threads-more-speed">Why More Threads != More Speed</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#optimal-worker-count">Optimal Worker Count</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#real-world-example">Real-World Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#cpu-vs-gpu-different-design-philosophies">CPU vs GPU: Different Design Philosophies</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#key-differences">Key Differences</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#simd-and-gpu-architecture">SIMD and GPU Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#why-gpus-excel-at-compute-intensive-tasks">Why GPUs Excel at Compute-Intensive Tasks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#massive-parallelism">1. Massive Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#perfect-for-data-parallel-problems">2. Perfect for Data-Parallel Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#high-memory-bandwidth">3. High Memory Bandwidth</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#what-gpus-are-good-at">What GPUs Are Good At</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#silicon-real-estate-comparison">Silicon Real Estate Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#performance-comparison">Performance Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#detailed-benchmark-results">Detailed Benchmark Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#decision-matrix">Decision Matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#practical-guidelines">Practical Guidelines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#use-cpu-when">Use CPU When:</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#use-gpu-when">Use GPU When:</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#use-hyperthreading-when">Use Hyperthreading When:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#example-1-image-processing">Example 1: Image Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#example-2-monte-carlo-simulation">Example 2: Monte Carlo Simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#example-3-neural-network-training">Example 3: Neural Network Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#core-principles">Core Principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#quick-reference">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/hardware_parallelism.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/threading_basics.html">Key Points About start()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/threading_basics.html#example">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/threading_basics.html#key-points-about-join">Key Points About join()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/threading_basics.html#id1">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/threading_basics.html#without-join-danger">WITHOUT join() - DANGER!</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/threading_basics.html#with-join-correct">WITH join() - CORRECT!</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/threading_basics.html#mistake-1-calling-the-function-directly-instead-of-start">Mistake 1: Calling the function directly instead of start()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/threading_basics.html#mistake-2-forgetting-join">Mistake 2: Forgetting join()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/threading_basics.html#mistake-3-thinking-threads-share-data-automatically">Mistake 3: Thinking threads share data automatically</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/asyncio_event_loop.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_event_loop.html#asyncio-event-loop">Asyncio Event Loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_event_loop.html#async-await-pattern">Async/Await Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_event_loop.html#task-functions">Task Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_event_loop.html#main-function">Main Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_event_loop.html#entry-point">Entry Point</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_event_loop.html#changes-made">Changes Made</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/asyncio_event_loop.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html#finite-state-machine-fsm">Finite State Machine (FSM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html#coroutines">Coroutines</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html#state-transitions">State Transitions</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html#state-machine-structure">State Machine Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html#start-state">Start State</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html#intermediate-states-state-1-2-3">Intermediate States (State 1, 2, 3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html#end-state">End State</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html#changes-made">Changes Made</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/asyncio_coroutine.html#use-cases">Use Cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#command-line-arguments">Command-Line Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#async-task-results">Async Task Results</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#concurrent-computation">Concurrent Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#first-coroutine-sum-of-n-integers">First Coroutine - Sum of N Integers</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#second-coroutine-factorial">Second Coroutine - Factorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#main-function">Main Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#changes-made">Changes Made</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#old-pattern-deprecated">Old Pattern (Deprecated)</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#new-pattern-modern">New Pattern (Modern)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#examples">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#example-1">Example 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_and_futures.html#example-2">Example 2</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/asyncio_task_manipulation.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_task_manipulation.html#asyncio-tasks">Asyncio Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_task_manipulation.html#concurrent-execution">Concurrent Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_task_manipulation.html#asyncio-gather">asyncio.gather()</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_task_manipulation.html#factorial-computation">Factorial Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_task_manipulation.html#fibonacci-computation">Fibonacci Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_task_manipulation.html#binomial-coefficient-computation">Binomial Coefficient Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_task_manipulation.html#main-function">Main Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/asyncio_task_manipulation.html#changes-made">Changes Made</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/asyncio_task_manipulation.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/concurrent_futures_pooling.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/concurrent_futures_pooling.html#executor-pattern">Executor Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/concurrent_futures_pooling.html#execution-models">Execution Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/concurrent_futures_pooling.html#cpu-intensive-task">CPU-Intensive Task</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/concurrent_futures_pooling.html#evaluation-function">Evaluation Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/concurrent_futures_pooling.html#sequential-execution">Sequential Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/concurrent_futures_pooling.html#thread-pool-execution">Thread Pool Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/concurrent_futures_pooling.html#process-pool-execution">Process Pool Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/concurrent_futures_pooling.html#changes-made">Changes Made</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/concurrent_futures_pooling.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#internal-structure">Internal Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#automatic-locking">Automatic Locking</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#put-item"><code class="docutils literal notranslate"><span class="pre">put(item)</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#problem-with-manual-locks">Problem with Manual Locks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_explained.html#problems">Problems:</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_explained.html#benefits">Benefits:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#how-queue-does-locking">How Queue Does Locking</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#locking-benefits">Locking Benefits</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_explained.html#start-all">Start all</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#execution-flow">Execution Flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#thread-safe-data-structure">1. <strong>Thread-Safe Data Structure</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#blocks-correctly">2. <strong>Blocks Correctly</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#no-busy-waiting">3. <strong>No Busy-Waiting</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#task-tracking">4. <strong>Task Tracking</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#safe-for-multiple-producers-consumers">5. <strong>Safe for Multiple Producers/Consumers</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#step-by-step-what-happens-in-put">Step-by-Step: What Happens in <code class="docutils literal notranslate"><span class="pre">put()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#step-by-step-what-happens-in-get">Step-by-Step: What Happens in <code class="docutils literal notranslate"><span class="pre">get()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#mistake-1-forgetting-lock">Mistake 1: Forgetting Lock</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#mistake-2-busy-waiting">Mistake 2: Busy-Waiting</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_explained.html#mistake-3-race-condition">Mistake 3: Race Condition</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_explained.html#add-tasks">Add tasks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html">The Answer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#the-items-don-t-have-conditions">The Items Don’t Have Conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#condition-variables-explained">Condition Variables Explained</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#step-by-step-execution">Step-by-Step Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#timeline-put-with-condition-variable">Timeline: put() with Condition Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#id1">Step-by-Step Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#timeline-get-with-condition-variable">Timeline: get() with Condition Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#scenario-queue-with-maxsize-2-multiple-producers-consumers">Scenario: Queue with maxsize=2, multiple producers/consumers</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#what-people-might-think-wrong">What People Might Think (WRONG):</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#the-actual-truth">The Actual Truth:</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#instead-of-per-item-events">Instead of Per-Item Events</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#not-empty-notify-what-it-does">not_empty.notify() - What It Does</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#diagram-condition-variable-notification">Diagram: Condition Variable Notification</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#does-each-item-get-a-condition">“Does each item get a condition?”</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#the-flow">The Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#what-queue-put-actually-does">What Queue.put() Actually Does</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/queue_internal_mechanics.html#summary">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html">Without task_done() - Can’t Track Completion</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#with-task-done-can-track-completion">With task_done() - Can Track Completion</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#internal-counter-system">Internal Counter System</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#visual-timeline">Visual Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#code-simplified">Code (Simplified)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#two-operations">Two Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#timeline-all-three-conditions">Timeline: All Three Conditions</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#put">put()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#get">get()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#task-done">task_done()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#join">join()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#scenario-1-producer-1-consumer">Scenario: 1 Producer, 1 Consumer</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#step-1-put-increment-counter">Step 1: put() - Increment Counter</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#step-2-get-item-removed-counter-unchanged">Step 2: get() - Item Removed, Counter Unchanged</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#step-3-task-done-decrement-counter">Step 3: task_done() - Decrement Counter</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#step-4-join-wait-then-return">Step 4: join() - Wait, Then Return</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#diagram-tracking-one-task">Diagram: Tracking One Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#diagram-multiple-tasks">Diagram: Multiple Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#counter">Counter</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#condition-variable">Condition Variable</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#together">Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#without-all-tasks-done-condition">Without all_tasks*done Condition</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#queue-join-without-task-done">Queue.join() Without task_done()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#why-it-blocks-forever">Why It Blocks Forever</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#queue-join-with-task-done">Queue.join() With task_done()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#why-it-works">Why It Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#step-1-put-item">Step 1: Put Item</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#step-2-get-and-process">Step 2: Get and Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#step-3-mark-done">Step 3: Mark Done</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#flow-diagram">Flow Diagram</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#without-task-done-problematic">Without task_done() - PROBLEMATIC</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#add-tasks">Add tasks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#with-task-done-correct">With task_done() - CORRECT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#id17">Add tasks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#use-case-1-verify-all-work-complete">Use Case 1: Verify All Work Complete</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#use-case-2-track-progress">Use Case 2: Track Progress</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#use-case-3-batch-processing">Use Case 3: Batch Processing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#main">Main</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#scenario-main-thread-needs-to-know-when-workers-finish">Scenario: Main thread needs to know when workers finish</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#timeline">Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#better-code-pattern">Better Code Pattern</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#in-main">In main</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#why-we-need-task-done">Why We Need task_done()</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/task_done_queue_explained.html#the-pattern">The Pattern</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/rlock_explained.html">Regular Lock vs RLock</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/rlock_explained.html#why-rlock-is-needed-here">Why RLock is Needed Here</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/rlock_explained.html#use-regular-lock-when">Use Regular Lock When:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/rlock_explained.html#use-rlock-when">Use RLock When:</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/rlock_explained.html#regular-lock-would-deadlock">Regular Lock - Would Deadlock</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/rlock_explained.html#rlock-no-deadlock">RLock - No Deadlock</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#counting-semaphore-counter-1">1. Counting Semaphore (Counter &gt; 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#binary-semaphore-counter-0-or-1">2. Binary Semaphore (Counter = 0 or 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#execution-timeline">Execution Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#acquire"><code class="docutils literal notranslate"><span class="pre">acquire()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#counting-semaphore-3-spots-available">Counting Semaphore (3 spots available)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#binary-semaphore-producer-consumer">Binary Semaphore (Producer-Consumer)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#example-1-swimming-pool-with-limited-capacity">Example 1: Swimming Pool with Limited Capacity</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#example-2-producer-consumer-like-the-code">Example 2: Producer-Consumer (Like the Code)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#limiting-concurrent-access">1. <strong>Limiting Concurrent Access</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#producer-consumer-communication">2. <strong>Producer-Consumer Communication</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#synchronizing-multiple-threads">3. <strong>Synchronizing Multiple Threads</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#lock-threading-lock">Lock (<code class="docutils literal notranslate"><span class="pre">threading.Lock</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#semaphore-counting">Semaphore (Counting)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/semaphore_explained.html#semaphore-binary-used-as-signal">Semaphore (Binary - Used as Signal)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html">What is the GIL?</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#why-does-python-have-a-gil">Why Does Python Have a GIL?</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#how-the-gil-works">How the GIL Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#gil-behavior-with-different-operations">GIL Behavior with Different Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#the-critical-difference">The Critical Difference</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#cpu-bound-operations">CPU-bound Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#i-o-bound-operations">I/O-bound Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#real-world-analogy">Real-World Analogy</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#the-problem-with-threading-for-cpu-bound">The Problem with Threading for CPU-bound</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#sequential">Sequential</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#the-solution-multiprocessing">The Solution: Multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#how-multiprocessing-bypasses-the-gil">How Multiprocessing Bypasses the GIL</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#trade-offs-of-multiprocessing">Trade-offs of Multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#when-the-trade-off-is-worth-it">When the Trade-off is Worth It</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#the-problem-wasted-time">The Problem: Wasted Time</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#the-solution-threading">The Solution: Threading</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#why-threading-works-for-i-o">Why Threading Works for I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#how-the-os-helps">How the OS Helps</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#performance-comparison">Performance Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#why-not-multiprocessing-for-i-o">Why Not Multiprocessing for I/O?</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#threading-trade-offs">Threading Trade-offs</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#the-problem-with-threading-overhead">The Problem with Threading: Overhead</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#asyncio-cooperative-multitasking">Asyncio: Cooperative Multitasking</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#how-asyncio-works">How Asyncio Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#event-loop-visualization">Event Loop Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#asyncio-vs-threading-detailed-comparison">Asyncio vs Threading: Detailed Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#performance-characteristics">Performance Characteristics</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#when-asyncio-shines">When Asyncio Shines</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#asyncio-trade-offs">Asyncio Trade-offs</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#cpu-bound-with-threading-the-gil-dance">CPU-bound with Threading: The GIL Dance</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#cpu-bound-with-multiprocessing-true-parallel">CPU-bound with Multiprocessing: True Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#i-o-bound-with-threading-gil-released">I/O-bound with Threading: GIL Released</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#i-o-bound-with-asyncio-event-loop-magic">I/O-bound with Asyncio: Event Loop Magic</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#benchmark-cpu-bound-task-computing-pi">Benchmark: CPU-bound Task (Computing pi)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#benchmark-i-o-bound-task-web-requests">Benchmark: I/O-bound Task (Web Requests)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#benchmark-mixed-workload">Benchmark: Mixed Workload</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#quick-reference-table">Quick Reference Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#code-templates">Code Templates</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#the-gil-controls-everything">1. The GIL Controls Everything</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#resource-usage-matters">2. Resource Usage Matters</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#trade-offs-are-real">3. Trade-offs are Real</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu-concurrency/patterns_problems_mapping.html#know-your-workload">4. Know Your Workload</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/gpu-fundamentals.html">Key Differences: CPU vs GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/gpu-fundamentals.html#streaming-multiprocessors-sms">Streaming Multiprocessors (SMs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/gpu-fundamentals.html#thread-organization">Thread Organization</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/gpu-fundamentals.html#example-visualization">Example Visualization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/gpu-fundamentals.html#next-steps">Next Steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#the-performance-pyramid">The Performance Pyramid</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#memory-coalescing">Memory Coalescing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#l2-cache">L2 Cache</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#example-matrix-multiplication">Example: Matrix Multiplication</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#registers">Registers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#pattern-1-streaming-bandwidth-bound">Pattern 1: Streaming (Bandwidth-Bound)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#pattern-2-staged-computation-compute-bound">Pattern 2: Staged Computation (Compute-Bound)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#pattern-3-reduction-mixed">Pattern 3: Reduction (Mixed)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#the-golden-rules">The Golden Rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#example-naive-vs-optimized-softmax">Example: Naive vs Optimized Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#key-metrics">Key Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#tools-for-profiling">Tools for Profiling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/memory-hierarchy.html#summary">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html">Warps and SIMD Execution</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#thread-divergence">Thread Divergence</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/execution-model.html#occupancy">Occupancy</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#what-is-occupancy">What is Occupancy?</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#factors-limiting-occupancy">Factors Limiting Occupancy</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#example-calculation">Example Calculation</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#why-occupancy-matters">Why Occupancy Matters</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#the-occupancy-sweet-spot">The Occupancy Sweet Spot</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#grid-and-block-dimensions">Grid and Block Dimensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#choosing-block-size">Choosing Block Size</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#within-a-block">Within a Block</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#between-blocks">Between Blocks</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#warp-shuffles">Warp Shuffles</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#warp-level-reductions">Warp-Level Reductions</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#overlap-compute-and-memory">Overlap Compute and Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#traditional-approach">Traditional Approach</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#persistent-approach">Persistent Approach</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#key-factors">Key Factors</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/execution-model.html#profiling-tools">Profiling Tools</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/execution-model.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html">Step 1: Profile First</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#step-2-identify-bottleneck">Step 2: Identify Bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-1-kernel-fusion">Strategy 1: Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-2-tiling">Strategy 2: Tiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-3-vectorized-loads">Strategy 3: Vectorized Loads</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-4-memory-coalescing">Strategy 4: Memory Coalescing</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-1-use-tensor-cores">Strategy 1: Use Tensor Cores</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-2-increase-arithmetic-intensity">Strategy 2: Increase Arithmetic Intensity</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-3-minimize-thread-divergence">Strategy 3: Minimize Thread Divergence</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-4-optimize-loop-structure">Strategy 4: Optimize Loop Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-1-reduce-register-usage">Strategy 1: Reduce Register Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-2-tune-shared-memory">Strategy 2: Tune Shared Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#strategy-3-adjust-block-size">Strategy 3: Adjust Block Size</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#why-auto-tune">Why Auto-Tune?</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#triton-auto-tuning">Triton Auto-Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#warp-specialization">Warp Specialization</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#persistent-kernels">Persistent Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#recomputation">Recomputation</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#pattern-reduction">Pattern: Reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#pattern-element-wise">Pattern: Element-wise</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#pattern-matrix-multiply">Pattern: Matrix Multiply</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#issue-low-bandwidth">Issue: Low Bandwidth</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#issue-low-compute-utilization">Issue: Low Compute Utilization</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#issue-lower-than-pytorch">Issue: Lower Than PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#before-you-optimize">Before You Optimize</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#memory-optimizations">Memory Optimizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#compute-optimizations">Compute Optimizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#occupancy-optimization">Occupancy Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/performance-optimization.html#advanced">Advanced</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/performance-optimization.html#summary">Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/performance-optimization.html#next-steps">Next Steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-concepts/triton-concepts.html">Triton Concepts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#introduction-to-triton">Introduction to Triton</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#vector-addition-example">Vector Addition Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#the-kernel-launch-mechanism">The Kernel Launch Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#the-grid-syntax-sugar-python-s-getitem">The <cite>[grid]</cite> Syntax Sugar: Python’s <cite>__getitem__</cite></a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#how-it-works">How It Works</a><ul>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#implementation-details">Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#the-complete-flow">The Complete Flow</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#grid-calculation-triton-cdiv">Grid Calculation: <cite>triton.cdiv()</cite></a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#purpose">Purpose</a><ul>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#example-with-vector-addition">Example with Vector Addition</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#why-ceiling-division">Why Ceiling Division?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#program-indexing-and-data-partitioning">Program Indexing and Data Partitioning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#the-spmd-model">The SPMD Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#program-id-assignment">Program ID Assignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#index-calculation">Index Calculation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#data-access-pattern">Data Access Pattern</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#memory-load-and-store">Memory Load and Store</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#how-tl-program-id-works">How <cite>tl.program_id()</cite> Works</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#implementation-stack">Implementation Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#flow-diagram">Flow Diagram</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#kernel-execution-and-asynchronous-behavior">Kernel Execution and Asynchronous Behavior</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#is-kernel-launch-synchronous-or-asynchronous">Is Kernel Launch Synchronous or Asynchronous?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#manual-synchronization">Manual Synchronization</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#implicit-synchronization">Implicit Synchronization</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#why-asynchronous-by-default">Why Asynchronous by Default?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#advanced-topics">Advanced Topics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#multi-dimensional-grids">Multi-Dimensional Grids</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#constexpr-parameters">Constexpr Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#kernel-caching">Kernel Caching</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#performance-considerations">Performance Considerations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#grid-size-selection">Grid Size Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#masking-overhead">Masking Overhead</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#memory-coalescing">Memory Coalescing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#kernel-compilation-warmup-and-gpu-initialization">Kernel Compilation, Warmup, and GPU Initialization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#is-hip-detect-amd-gpu-backend">is_hip() - Detect AMD GPU Backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#is-cdna-detect-amd-cdna-architecture">is_cdna() - Detect AMD CDNA Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#warmup-pre-compile-kernel-without-execution">warmup() - Pre-compile Kernel Without Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#init-handles-initialize-gpu-binary-handles">_init_handles() - Initialize GPU Binary Handles</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#complete-workflow-example-fused-softmax">Complete Workflow Example: Fused Softmax</a><ul>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#data-flow-diagram">Data Flow Diagram</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#summary-table">Summary Table</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#compiler-optimization-hints-tl-assume">Compiler Optimization Hints: <cite>tl.assume()</cite></a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#what-is-tl-assume">What is tl.assume()?</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#why-assumptions-help-optimization">Why Assumptions Help Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#matrix-multiplication-example">Matrix Multiplication Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#when-to-use-tl-assume">When to Use <cite>tl.assume()</cite></a><ul>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#dangerous-example-don-t-do-this">Dangerous Example: DON’T DO THIS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#related-functions-tl-static-assert">Related Functions: <cite>tl.static_assert()</cite></a><ul>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#performance-impact-in-matrix-multiplication">Performance Impact in Matrix Multiplication</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#how-compiler-uses-assumptions">How Compiler Uses Assumptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-concepts/triton-concepts.html#summary-tl-assume-guidelines">Summary: <cite>tl.assume()</cite> Guidelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="gpu-concepts/triton-concepts.html#comparison-with-other-optimization-techniques">Comparison with Other Optimization Techniques</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#summary">Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-concepts/triton-concepts.html#references">References</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/01-vector-add.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#spmd-single-program-multiple-data">SPMD (Single Program, Multiple Data)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#program-id-and-block-processing">Program ID and Block Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#grid-size">Grid Size</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#memory-hierarchy">Memory Hierarchy</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#memory-coalescing">Memory Coalescing</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#masking-for-boundary-conditions">Masking for Boundary Conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#step-by-step-execution">Step-by-Step Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#bandwidth-bound-operation">Bandwidth-Bound Operation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#arithmetic-intensity">Arithmetic Intensity</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#theoretical-performance">Theoretical Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#triton-jit-decorator"><code class="docutils literal notranslate"><span class="pre">&#64;triton.jit</span></code> Decorator</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#constexpr-for-compile-time-constants"><code class="docutils literal notranslate"><span class="pre">constexpr</span></code> for Compile-Time Constants</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#launch-grid-syntax">Launch Grid Syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#expected-results">Expected Results</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#pointer-arithmetic">1. Pointer Arithmetic</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#vectorized-operations">2. Vectorized Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#masked-memory-operations">3. Masked Memory Operations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/01-vector-add.html#next-steps">Next Steps</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#standard-softmax-formula">Standard Softmax Formula</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#naive-pytorch-implementation">Naive PyTorch Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#dram-global-memory">DRAM (Global Memory)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#sram-shared-memory-l1-cache">SRAM (Shared Memory / L1 Cache)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#the-key-insight">The Key Insight</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#block-level-processing">Block-Level Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#step-1-load-row-into-sram">Step 1: Load Row Into SRAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#step-2-compute-max-reduction">Step 2: Compute Max (Reduction)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#step-3-exponentiation">Step 3: Exponentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#step-4-compute-sum-another-reduction">Step 4: Compute Sum (Another Reduction)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#step-5-normalize-and-write-back">Step 5: Normalize and Write Back</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#why-must-block-size-be-power-of-2">Why Must BLOCK_SIZE Be Power of 2?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#number-of-warps">Number of Warps</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#number-of-pipeline-stages">Number of Pipeline Stages</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#computing-occupancy">Computing Occupancy</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#the-pattern">The Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#why-subtract-max">Why Subtract Max?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#padding-with-inf">Padding with -inf</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#theoretical-speedup">Theoretical Speedup</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#actual-performance">Actual Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#reduction-operations">Reduction Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#warp-shuffles">Warp Shuffles</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#block-vs-thread">Block vs Thread</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#row-too-large-for-sram">1. Row Too Large for SRAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#numerical-precision">2. Numerical Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#masking-errors">3. Masking Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#jit-fusion-torch-jit-script">JIT Fusion (torch.jit.script)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#manual-cuda">Manual CUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#cudnn-cublas">CuDNN/CuBLAS</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/02-fused-softmax.html#extensions">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html">Matrix Multiplication</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#basic-algorithm">Basic Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#why-it-s-hard-to-optimize">Why It’s Hard to Optimize</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#blocked-algorithm">Blocked Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#why-tiling-works">Why Tiling Works</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#understanding-strides">Understanding Strides</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#block-pointers">Block Pointers</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#advancing-pointers">Advancing Pointers</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#the-problem-with-row-major-ordering">The Problem with Row-Major Ordering</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#grouped-ordering-swizzling">Grouped Ordering (Swizzling)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#the-configuration-space">The Configuration Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#triton-s-auto-tuner">Triton’s Auto-Tuner</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#id3">)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#good-configurations">Good Configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#step-1-compute-program-ids">Step 1: Compute Program IDs</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#step-2-initialize-pointers">Step 2: Initialize Pointers</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#step-3-accumulation-loop">Step 3: Accumulation Loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#step-4-apply-activation-optional">Step 4: Apply Activation (Optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#step-5-store-result">Step 5: Store Result</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#what-are-tensor-cores">What Are Tensor Cores?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#how-tensor-cores-work">How Tensor Cores Work</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#triton-and-tensor-cores">Triton and Tensor Cores</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#arithmetic-intensity">Arithmetic Intensity</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#roofline-model">Roofline Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#expected-performance">Expected Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#software-pipelining">Software Pipelining</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#loop-unrolling">Loop Unrolling</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#register-pressure">Register Pressure</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#non-contiguous-tensors">1. Non-Contiguous Tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#wrong-stride-calculation">2. Wrong Stride Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#boundary-conditions">3. Boundary Conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#numerical-precision">4. Numerical Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#warm-up">1. Warm-up</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#measure-tflops">2. Measure TFLOPS</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#compare-against-cublas-rocblas">3. Compare Against cuBLAS/rocBLAS</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/03-matrix-multiplication.html#test-different-sizes">4. Test Different Sizes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html">Low Memory Dropout</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#purpose">Purpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#mathematical-definition">Mathematical Definition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#id1">}</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#scaling-factor">Scaling Factor</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#standard-pytorch-dropout">Standard PyTorch Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#the-backward-pass-problem">The Backward Pass Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#additional-complexity">Additional Complexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#key-insight">Key Insight</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#the-triton-implementation">The Triton Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#the-challenge">The Challenge</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#the-solution-counter-based-prng">The Solution: Counter-Based PRNG</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#the-philox-algorithm">The Philox Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#using-philox-in-triton">Using Philox in Triton</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#memory-comparison">Memory Comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#computational-cost">Computational Cost</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#when-to-use-seeded-dropout">When to Use Seeded Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#ensuring-same-random-numbers">Ensuring Same Random Numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#seed-management">Seed Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#testing-reproducibility">Testing Reproducibility</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#the-tl-where-function">The <code class="docutils literal notranslate"><span class="pre">tl.where</span></code> Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#masking-for-boundary-conditions">Masking for Boundary Conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#random-number-distribution">Random Number Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#different-random-distributions">Different Random Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#quality-of-randomness">Quality of Randomness</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#thread-safety-and-race-conditions">Thread Safety and Race Conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#expected-performance">Expected Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#bottleneck-analysis">Bottleneck Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#integration-with-pytorch">Integration with PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/04-low-memory-dropout.html#seed-generation-strategies">Seed Generation Strategies</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html">Layer Norm</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#the-formula">The Formula</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#step-by-step-math">Step-by-Step Math</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#why-layer-normalization">Why Layer Normalization?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#batch-norm-vs-layer-norm">Batch Norm vs Layer Norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#kernel-structure">Kernel Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#computing-the-mean">Computing the Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#computing-the-variance">Computing the Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#normalization-and-transformation">Normalization and Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#gradient-mathematics">Gradient Mathematics</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#gradient-for-biases">Gradient for Biases</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#gradient-for-weights">Gradient for Weights</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#gradient-for-input-complex">Gradient for Input (Complex!)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#the-challenge">The Challenge</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#two-stage-reduction">Two-Stage Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#group-assignment">Group Assignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#using-locks">Using Locks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#in-kernel">In kernel:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#stage-2-final-reduction">Stage 2: Final Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#memory-layout">Memory Layout</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#stride-usage">Stride Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#why-use-float32-for-accumulation">Why Use float32 for Accumulation?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#computational-complexity">Computational Complexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#memory-bandwidth">Memory Bandwidth</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#optimization-opportunities">Optimization Opportunities</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#numerical-stability">1. Numerical Stability</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#dimension-confusion">2. Dimension Confusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#gradient-accumulation-race-conditions">3. Gradient Accumulation Race Conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#forgetting-to-sum-weight-gradients">4. Forgetting to Sum Weight Gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#rmsnorm-simpler-variant">RMSNorm (Simpler Variant)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#groupnorm">GroupNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#fp8-and-mixed-precision">FP8 and Mixed Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#pytorch-implementation">PyTorch Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#triton-advantages">Triton Advantages</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/05-layer-norm.html#performance">Performance</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html">Fused Attention</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#standard-attention-formula">Standard Attention Formula</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#step-by-step-computation">Step-by-Step Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#the-memory-problem">The Memory Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#insight-1-we-don-t-need-to-store-s-and-p">Insight 1: We Don’t Need to Store S and P</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#insight-2-online-softmax">Insight 2: Online Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#insight-3-tiling">Insight 3: Tiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#standard-softmax">Standard Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#block-wise-computation">Block-wise Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#updating-the-output">Updating the Output</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#the-inner-loop">The Inner Loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#causal-masking">Causal Masking</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#stages-for-causal-attention">Stages for Causal Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#tensor-descriptors">Tensor Descriptors</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#warp-specialization">Warp Specialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#reduced-shared-memory">Reduced Shared Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#fp8-support">FP8 Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#preprocess-step">Preprocess Step</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#computing-dk-and-dv">Computing dK and dV</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#computing-dq">Computing dQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#why-recomputation">Why Recomputation?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#memory-complexity">Memory Complexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#compute-complexity">Compute Complexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#arithmetic-intensity">Arithmetic Intensity</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#id9">]</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#sram-overflow">1. SRAM Overflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#numerical-instability">2. Numerical Instability</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#causal-mask-errors">3. Causal Mask Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#forgetting-to-update-statistics">4. Forgetting to Update Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#multi-query-attention-mqa">Multi-Query Attention (MQA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#grouped-query-attention-gqa">Grouped Query Attention (GQA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#sliding-window-attention">Sliding Window Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/06-fused-attention.html#flash-attention-3">Flash Attention 3</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html">Extern Functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#nvidia-s-libdevice">NVIDIA’s libdevice</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#amd-s-device-libraries">AMD’s Device Libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#what-functions-are-available">What Functions Are Available?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#triton-built-in-math">Triton Built-in Math</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#when-you-need-more">When You Need More</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#the-simple-way-default-path">The Simple Way (Default Path)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#the-custom-path-way">The Custom Path Way</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#compilation-process">Compilation Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#type-dispatch">Type Dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#calling-convention">Calling Convention</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#triton-s-libdevice-wrapper">Triton’s libdevice Wrapper</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#hyperbolic">Hyperbolic</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#the-math">The Math</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#why-use-libdevice">Why Use libdevice?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#full-example">Full Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#test">Test</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#libdevice-performance">Libdevice Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#when-to-use-vs-triton-intrinsics">When to Use vs Triton Intrinsics</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#common-errors">Common Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#verifying-libraries">Verifying Libraries</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#nvidia">NVIDIA</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#amd">AMD</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#calling-custom-external-functions">Calling Custom External Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#mixing-multiple-external-libraries">Mixing Multiple External Libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#nvidia-vs-amd">NVIDIA vs AMD</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#function-name-differences">Function Name Differences</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#in-cuda">In CUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/07-extern-functions.html#in-triton">In Triton</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#static-on-device-scheduling">Static On-Device Scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#group-problem-representation">Group Problem Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#grouped-gemm-kernel-basic-version">1. Grouped GEMM Kernel (Basic Version)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#tma-tensor-memory-accelerator-version">2. TMA (Tensor Memory Accelerator) Version</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#host-function-setup">3. Host Function Setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#id1">)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#pointer-indirection">Pointer Indirection</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#leading-dimension-stride">Leading Dimension (Stride)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#when-grouped-gemm-wins">When Grouped GEMM Wins</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#when-to-use-separate-kernels">When to Use Separate Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#benchmarking-results">Benchmarking Results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#id2">)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#why-fixed-number-of-ctas">Why Fixed Number of CTAs?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#work-distribution">Work Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#forgetting-contiguity">1. Forgetting Contiguity</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#incorrect-leading-dimensions">2. Incorrect Leading Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#mixed-precision-issues">3. Mixed Precision Issues</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/08-grouped-gemm.html#summary">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#persistent-kernel-pattern">Persistent Kernel Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#warp-specialization">Warp Specialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#naive-matmul-baseline">1. Naive Matmul (Baseline)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#id1">)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#persistent-matmul">2. Persistent Matmul</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#id4">)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#tma-matmul">3. TMA Matmul</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#tma-persistent-with-epilogue-subtiling">4. TMA Persistent with Epilogue Subtiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#viewing-profile-data">Viewing Profile Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#host-side-tensordescriptor">Host-side (TensorDescriptor)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#device-side-tl-make-tensor-descriptor">Device-side (tl.make_tensor*descriptor)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#how-it-works">How It Works</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#expected-speedups-relative-to-naive">Expected speedups (relative to naive):</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#when-each-variant-wins">When Each Variant Wins</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#fp16-float16">FP16 (Float16)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#fp8-float8">FP8 (Float8)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#wrong-b-matrix-layout-for-tma">1. Wrong B Matrix Layout for TMA</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#mixing-host-and-device-descriptors">2. Mixing Host and Device Descriptors</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#forgetting-fp8-support-check">3. Forgetting FP8 Support Check</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/09-persistent-matmul.html#summary">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#block-scaling-fundamentals">Block Scaling Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#quantization-formats">Quantization Formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#memory-savings">Memory Savings</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#why-preshuffling">Why Preshuffling?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#d-preshuffled-layout">5D Preshuffled Layout</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#reshaping-and-transposing">Reshaping and Transposing</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#mfma-scale-organization">MFMA Scale Organization</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#thread-level-access-pattern">Thread-level Access Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#nvidia-kernel-tma-based">1. NVIDIA Kernel (TMA-based)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#amd-cdna4-kernel">2. AMD CDNA4 Kernel</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#nvidia-version">NVIDIA Version</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#amd-version">AMD Version</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#theoretical-speedup">Theoretical Speedup</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#real-world-performance">Real-world Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#quantization-error">Quantization Error</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#e8m0-scale-format-amd">E8M0 Scale Format (AMD)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#example">Example:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#command-line-benchmarking">Command-line Benchmarking</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#nvidia-fp4">NVIDIA FP4</a></li>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#nvidia-fp8">NVIDIA FP8</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#validation">Validation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#nvidia">NVIDIA</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#unsupported-hardware">1. Unsupported Hardware</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#format-mismatch">2. Format Mismatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#wrong-scale-shape">3. Wrong Scale Shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#missing-tma-allocator">4. Missing TMA Allocator</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu-tutorials/10-block-scaled-matmul.html#summary">Summary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton Compiler</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html">Key Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#stage-1-python-ast-parsing">Stage 1: Python AST Parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#stage-2-code-generation-ttir">Stage 2: Code Generation (TTIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#stage-3-triton-gpu-ir-ttgir">Stage 3: Triton GPU IR (TTGIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#stage-4-llvm-ir">Stage 4: LLVM IR</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#stage-5-ptx-amdgcn">Stage 5: PTX / AMDGCN</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#stage-6-binary-cubin-hsaco">Stage 6: Binary (CUBIN / HSACO)</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#block-based-programming-model">Block-based Programming Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#jit-compilation">JIT Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#mlir-infrastructure">MLIR Infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#python-components">Python Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#c-components">C++ Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/01-overview.html#backend-components">Backend Components</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/01-overview.html#next-steps">Next Steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/02-jit-decorator.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#implementation">Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#source-code-extraction">Source Code Extraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#ast-parsing">AST Parsing</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#cache-key-generation">Cache Key Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#tracking-global-variables">Tracking Global Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#handling-nested-function-calls">Handling Nested Function Calls</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#initialization">Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#kernel-call-handling">Kernel Call Handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#argument-specialization">Argument Specialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#launch-metadata">Launch Metadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#attributes-and-hints">Attributes and Hints</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/02-jit-decorator.html#summary">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html">CodeGenerator Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#ast-visitor-pattern">AST Visitor Pattern</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#triton-language-primitives">Triton Language Primitives</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#type-inference">Type Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#example-ttir-output">Example TTIR Output</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#compilation-orchestration">Compilation Orchestration</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#ttir-ttgir-transformation">TTIR -&gt; TTGIR Transformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#ttgir-llvm-ir">TTGIR -&gt; LLVM IR</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#llvm-ir-ptx">LLVM IR -&gt; PTX</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#ptx-cubin">PTX -&gt; CUBIN</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#cache-key-components">Cache Key Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#cache-directory-structure">Cache Directory Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#cache-lookup">Cache Lookup</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/03-compilation-pipeline.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html">The NVCC Compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#nvcc-compilation-stages">NVCC Compilation Stages</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#ptx-assembly-output">PTX Assembly Output</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#the-llvm-path">The LLVM Path</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#llvm-ir-stage">LLVM IR Stage</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#ptx-generated-by-triton">PTX Generated by Triton</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#same-tools-same-artifacts">Same Tools, Same Artifacts</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#source-language">Source Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#compiler-stack">Compiler Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#compilation-time">Compilation Time</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#optimization-levels">Optimization Levels</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#can-triton-and-cuda-c-work-together">Can Triton and CUDA C++ Work Together?</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#advantages-of-llvm-backend">Advantages of LLVM Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#why-not-use-nvcc">Why Not Use NVCC?</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#trade-offs">Trade-offs</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#file-types">File Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#example-directory-structures">Example Directory Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#ptx-inspection">PTX Inspection</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#cubin-inspection">CUBIN Inspection</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#compilation-paths-compared">Compilation Paths Compared</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/04-cuda-comparison.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html">Traditional Compiler Limitations</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#example-matrix-multiplication">Example: Matrix Multiplication</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#mlir-philosophy">MLIR Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#dialects">1. Dialects</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#common-dialects">Common Dialects</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#triton-s-custom-dialects">Triton’s Custom Dialects</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#operations">2. Operations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#operation-anatomy">Operation Anatomy</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#ssa-form-static-single-assignment">SSA Form (Static Single Assignment)</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#operation-examples">Operation Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#regions-and-blocks">3. Regions and Blocks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#regions">Regions</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#blocks">Blocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#example-with-regions-and-blocks">Example with Regions and Blocks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#types">4. Types</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#built-in-types">Built-in Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#triton-custom-types">Triton Custom Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#type-conversion">Type Conversion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#attributes">5. Attributes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#common-attribute-types">Common Attribute Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#triton-layout-attributes">Triton Layout Attributes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#passes">6. Passes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#pass-types">Pass Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#example-pass-pipeline">Example Pass Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#triton-specific-passes">Triton-Specific Passes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#why-triton-uses-mlir">Why Triton Uses MLIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#triton-s-mlir-dialects">Triton’s MLIR Dialects</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#triton-dialect-tt">Triton Dialect (tt)</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#tritongpu-dialect-ttg">TritonGPU Dialect (ttg)</a></li>
<li class="toctree-l2"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#tritonnvidiagpu-dialect-ttng">TritonNvidiaGPU Dialect (ttng)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#python-source">Python Source</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#stage-1-triton-ir-ttir">Stage 1: Triton IR (TTIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#stage-2-tritongpu-ir-ttgir">Stage 2: TritonGPU IR (TTGIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#stage-3-llvm-dialect">Stage 3: LLVM Dialect</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#stage-4-llvm-ir-actual">Stage 4: LLVM IR (Actual)</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#command-line-tools">Command-Line Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#tablegen-for-defining-operations">TableGen for Defining Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#debugging-mlir">Debugging MLIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#official-documentation">Official Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#tutorials">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#triton-specific">Triton-Specific</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#key-concepts-recap">Key Concepts Recap</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#why-mlir-matters-for-triton">Why MLIR Matters for Triton</a></li>
<li class="toctree-l1"><a class="reference internal" href="triton-compiler/05-mlir-concepts.html#the-big-picture">The Big Picture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="learning-paths.html">Learning Paths</a><ul>
<li class="toctree-l2"><a class="reference internal" href="learning-paths.html#memory-optimization">Memory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning-paths.html#compute-optimization">Compute Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning-paths.html#backward-pass-training">Backward Pass / Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning-paths.html#advanced-techniques">Advanced Techniques</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning-paths.html#after-path-1-fast-track">After Path 1 (Fast Track)</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning-paths.html#after-path-2-comprehensive">After Path 2 (Comprehensive)</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning-paths.html#after-path-3-transformer">After Path 3 (Transformer)</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">CUDA Out of Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="#out-of-shared-memory">Out of Shared Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="#wrong-results">Wrong Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="#nan-or-inf-values">NaN or Inf Values</a></li>
<li class="toctree-l1"><a class="reference internal" href="#slower-than-pytorch">Slower Than PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="#low-gpu-utilization">Low GPU Utilization</a></li>
<li class="toctree-l1"><a class="reference internal" href="#compilation-errors">Compilation Errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="#slow-compilation">Slow Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="#nvidia-specific">NVIDIA-Specific</a></li>
<li class="toctree-l1"><a class="reference internal" href="#amd-specific">AMD-Specific</a></li>
<li class="toctree-l1"><a class="reference internal" href="#wrong-gpu-selected">Wrong GPU Selected</a></li>
<li class="toctree-l1"><a class="reference internal" href="#print-debugging">Print Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="#profiling">Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="#assertions">Assertions</a></li>
<li class="toctree-l1"><a class="reference internal" href="#unit-testing">Unit Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="#when-stuck">When Stuck</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references.html">Triton</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#cuda">CUDA</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#rocm-amd">ROCm (AMD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#pytorch">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#flash-attention">Flash Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#normalization">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#optimization-techniques">Optimization Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#id1">Triton</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references.html#books">Books</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references.html#gpu-programming">GPU Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#deep-learning">Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#nvidia-tools">NVIDIA Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#amd-tools">AMD Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#pytorch-profiler">PyTorch Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#benchmarking">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#tutorials-and-courses">Tutorials and Courses</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#community">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#blogs-and-articles">Blogs and Articles</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#triton-examples">Triton Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#production-usage">Production Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#nvidia-gpus">NVIDIA GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#amd-gpus">AMD GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#subscribe-to">Subscribe To</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html#conferences">Conferences</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references.html#citation">Citation</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Triton GPU Programming Guide</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">CUDA Out of Memory</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/troubleshooting.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p>Troubleshooting Guide</p>
<p>Common issues and their solutions when working with Triton and GPU programming.</p>
<p>Out of Memory Errors</p>
<section id="cuda-out-of-memory">
<h1>CUDA Out of Memory<a class="headerlink" href="#cuda-out-of-memory" title="Link to this heading"></a></h1>
<p><strong>Error Message</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">CUDA</span> <span class="n">out</span> <span class="n">of</span> <span class="n">memory</span><span class="o">.</span> <span class="n">Tried</span> <span class="n">to</span> <span class="n">allocate</span> <span class="n">X</span> <span class="n">MB</span>
</pre></div>
</div>
<p><strong>Causes</strong>:</p>
<ol class="arabic simple">
<li><p>Batch size too large</p></li>
<li><p>Sequence length too long</p></li>
<li><p>Too many intermediate tensors</p></li>
<li><p>Memory leak</p></li>
</ol>
<p><strong>Solutions</strong>:</p>
<p><strong>Reduce batch size</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Before</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># After</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>  <span class="c1"># or 16</span>
</pre></div>
</div>
<p><strong>Use gradient checkpointing</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Recompute activations instead of storing</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.checkpoint</span><span class="w"> </span><span class="kn">import</span> <span class="n">checkpoint</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">(</span><span class="n">my_function</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Clear cache</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Check for memory leaks</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Detach tensors when not needed</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># Convert to Python number</span>
<span class="k">del</span> <span class="n">loss</span>  <span class="c1"># Free memory</span>
</pre></div>
</div>
</section>
<section id="out-of-shared-memory">
<h1>Out of Shared Memory<a class="headerlink" href="#out-of-shared-memory" title="Link to this heading"></a></h1>
<p><strong>Error Message</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">triton</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">OutOfResources</span><span class="p">:</span> <span class="n">out</span> <span class="n">of</span> <span class="n">resource</span><span class="p">:</span> <span class="n">shared</span> <span class="n">memory</span><span class="p">,</span>
<span class="n">Required</span><span class="p">:</span> <span class="mi">109568</span><span class="p">,</span> <span class="n">Hardware</span> <span class="n">limit</span><span class="p">:</span> <span class="mi">101376</span>
</pre></div>
</div>
<p><strong>Causes</strong>:</p>
<ul class="simple">
<li><p>Block sizes too large</p></li>
<li><p>Too many pipeline stages (<code class="docutils literal notranslate"><span class="pre">num_stages</span></code>)</p></li>
</ul>
<p><strong>Solutions</strong>:</p>
<p><strong>Reduce block sizes</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Before</span>
<span class="nd">@triton</span><span class="o">.</span><span class="n">Config</span><span class="p">({</span><span class="s1">&#39;BLOCK_M&#39;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span> <span class="s1">&#39;BLOCK_N&#39;</span><span class="p">:</span> <span class="mi">256</span><span class="p">},</span> <span class="o">...</span><span class="p">)</span>

<span class="c1"># After</span>
<span class="nd">@triton</span><span class="o">.</span><span class="n">Config</span><span class="p">({</span><span class="s1">&#39;BLOCK_M&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;BLOCK_N&#39;</span><span class="p">:</span> <span class="mi">128</span><span class="p">},</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Reduce num_stages</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Before</span>
<span class="n">num_stages</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># After</span>
<span class="n">num_stages</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># or 2</span>
</pre></div>
</div>
<p><strong>Adjust auto-tune configs</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">triton</span><span class="o">.</span><span class="n">Config</span><span class="p">({</span><span class="o">...</span><span class="p">},</span> <span class="n">num_stages</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_warps</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>  <span class="c1"># Less SRAM</span>
    <span class="c1"># Remove configs with large blocks</span>
<span class="p">]</span>
</pre></div>
</div>
<p>Correctness Issues</p>
</section>
<section id="wrong-results">
<h1>Wrong Results<a class="headerlink" href="#wrong-results" title="Link to this heading"></a></h1>
<p><strong>Symptoms</strong>: Output doesn’t match PyTorch or expected values</p>
<p><strong>Debug Steps</strong>:</p>
<ol class="arabic">
<li><p><strong>Check masking</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mask</span> <span class="o">=</span> <span class="n">offsets</span> <span class="o">&lt;</span> <span class="n">n_elements</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">x_ptr</span> <span class="o">+</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>  <span class="c1"># Don&#39;t forget mask!</span>
</pre></div>
</div>
</li>
<li><p><strong>Verify pointer arithmetic</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check strides are correct</span>
<span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>

<span class="c1"># Print debug info</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Stride: </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">stride</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Use float32 for accumulation</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bad: FP16 accumulation loses precision</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>

<span class="c1"># Good: FP32 accumulation</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>  <span class="c1"># Cast at end</span>
</pre></div>
</div>
</li>
<li><p><strong>Check numerical stability</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Softmax: always subtract max</span>
<span class="n">x_max</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x_normalized</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x_max</span>  <span class="c1"># Prevents overflow</span>
</pre></div>
</div>
</li>
<li><p><strong>Verify boundary conditions</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Test with non-power-of-2 sizes</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1001</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>  <span class="c1"># Not 1024!</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="nan-or-inf-values">
<h1>NaN or Inf Values<a class="headerlink" href="#nan-or-inf-values" title="Link to this heading"></a></h1>
<p><strong>Common causes</strong>:</p>
<ol class="arabic">
<li><p><strong>Division by zero</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Add epsilon</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Overflow in exp</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Subtract max before exp</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">tl</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Log of negative/zero</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Clamp before log</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">))</span>
</pre></div>
</div>
</li>
<li><p><strong>Uninitialized memory</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Always initialize</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># Not: acc = tl.empty(...)</span>
</pre></div>
</div>
</li>
</ol>
<p>Performance Issues</p>
</section>
<section id="slower-than-pytorch">
<h1>Slower Than PyTorch<a class="headerlink" href="#slower-than-pytorch" title="Link to this heading"></a></h1>
<p><strong>Diagnosis</strong>:</p>
<ol class="arabic">
<li><p><strong>Profile both</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">benchmark</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span><span class="n">stmt</span><span class="o">=</span><span class="s1">&#39;torch.matmul(a, b)&#39;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="n">a</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="n">b</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>

<span class="c1"># Triton</span>
<span class="n">ms</span> <span class="o">=</span> <span class="n">triton</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">do_bench</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">triton_matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
</li>
<li><p><strong>Check if PyTorch uses vendor libs</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch often uses cuBLAS, cuDNN</span>
<span class="c1"># These are extremely optimized</span>
<span class="c1"># Matching them is success!</span>
</pre></div>
</div>
</li>
</ol>
<p><strong>Common reasons</strong>:</p>
<ol class="arabic">
<li><p><strong>Not using Tensor Cores</strong></p>
<ul class="simple">
<li><p>Ensure FP16/BF16 inputs</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">tl.dot()</span></code> for matmul</p></li>
<li><p>Check block sizes are multiples of 16</p></li>
</ul>
</li>
<li><p><strong>Suboptimal configuration</strong></p>
<ul class="simple">
<li><p>Need auto-tuning</p></li>
<li><p>Try different block sizes</p></li>
<li><p>Adjust num_warps and num_stages</p></li>
</ul>
</li>
<li><p><strong>Non-contiguous tensors</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check contiguity</span>
<span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>

<span class="c1"># Make contiguous if needed</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
</pre></div>
</div>
</li>
<li><p><strong>Missing optimizations</strong></p>
<ul class="simple">
<li><p>No kernel fusion</p></li>
<li><p>Not using SRAM effectively</p></li>
<li><p>Poor memory access patterns</p></li>
</ul>
</li>
</ol>
</section>
<section id="low-gpu-utilization">
<h1>Low GPU Utilization<a class="headerlink" href="#low-gpu-utilization" title="Link to this heading"></a></h1>
<p><strong>Check with</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span> <span class="o">-</span><span class="n">l</span> <span class="mi">1</span>  <span class="c1"># Monitor GPU utilization</span>
</pre></div>
</div>
<p><strong>If low (&lt;50%)</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Increase batch size</strong>: More parallel work</p></li>
<li><p><strong>Check occupancy</strong>: May be too low</p></li>
<li><p><strong>Pipeline CPU-GPU</strong>: Overlap data transfer and compute</p></li>
<li><p><strong>Profile</strong>: Use <code class="docutils literal notranslate"><span class="pre">nsys</span></code> to find bottlenecks</p></li>
</ol>
<p><strong>If high (&gt;90%) but slow</strong>:</p>
<ul class="simple">
<li><p>Memory-bound: Optimize memory access</p></li>
<li><p>Compute-bound: Use Tensor Cores, increase arithmetic intensity</p></li>
</ul>
<p>Compilation Issues</p>
</section>
<section id="compilation-errors">
<h1>Compilation Errors<a class="headerlink" href="#compilation-errors" title="Link to this heading"></a></h1>
<p><strong>Error</strong>: <code class="docutils literal notranslate"><span class="pre">TypeError:</span> <span class="pre">unsupported</span> <span class="pre">operand</span> <span class="pre">type(s)</span></code></p>
<p><strong>Cause</strong>: Type mismatch in Triton</p>
<p><strong>Solution</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Explicit casting</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
</pre></div>
</div>
<p><strong>Error</strong>: <code class="docutils literal notranslate"><span class="pre">constexpr</span></code> parameter not constant</p>
<p><strong>Solution</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Must be compile-time constant</span>
<span class="n">BLOCK_SIZE</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># Not a variable!</span>
</pre></div>
</div>
</section>
<section id="slow-compilation">
<h1>Slow Compilation<a class="headerlink" href="#slow-compilation" title="Link to this heading"></a></h1>
<p><strong>First compilation is slow</strong> (minutes):</p>
<ul class="simple">
<li><p>Normal! Triton JIT-compiles and auto-tunes</p></li>
<li><p>Subsequent runs use cached version</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">TRITON_CACHE_DIR</span></code> to persist cache</p></li>
</ul>
<p><strong>Every run is slow</strong>:</p>
<ul>
<li><p>Check if cache is working:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="nb">print</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;TRITON_CACHE_DIR&#39;</span><span class="p">))</span>
</pre></div>
</div>
</li>
<li><p>Set cache directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">TRITON_CACHE_DIR</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">cache</span>
</pre></div>
</div>
</li>
</ul>
<p>Platform-Specific Issues</p>
</section>
<section id="nvidia-specific">
<h1>NVIDIA-Specific<a class="headerlink" href="#nvidia-specific" title="Link to this heading"></a></h1>
<p><strong>Compute capability too low</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">Triton</span> <span class="n">requires</span> <span class="n">compute</span> <span class="n">capability</span> <span class="o">&gt;=</span> <span class="mf">7.0</span>
</pre></div>
</div>
<p><strong>Solution</strong>: Upgrade GPU (Volta or newer required)</p>
<p><strong>Driver version mismatch</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CUDA</span> <span class="n">driver</span> <span class="n">version</span> <span class="ow">is</span> <span class="n">insufficient</span> <span class="k">for</span> <span class="n">CUDA</span> <span class="n">runtime</span> <span class="n">version</span>
</pre></div>
</div>
<p><strong>Solution</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check versions</span>
<span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span>  <span class="c1"># Driver version</span>
<span class="n">python</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;import torch; print(torch.version.cuda)&quot;</span>  <span class="c1"># CUDA version</span>

<span class="c1"># Update driver if needed</span>
</pre></div>
</div>
</section>
<section id="amd-specific">
<h1>AMD-Specific<a class="headerlink" href="#amd-specific" title="Link to this heading"></a></h1>
<p><strong>ROCm not found</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ne">ModuleNotFoundError</span><span class="p">:</span> <span class="n">No</span> <span class="n">module</span> <span class="n">named</span> <span class="s1">&#39;triton.backends.amd&#39;</span>
</pre></div>
</div>
<p><strong>Solution</strong>: Install ROCm-enabled Triton:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">triton</span> <span class="o">--</span><span class="n">index</span><span class="o">-</span><span class="n">url</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">download</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">whl</span><span class="o">/</span><span class="n">rocm5</span><span class="mf">.6</span>
</pre></div>
</div>
<p><strong>Kernel launch failures</strong>:</p>
<ul class="simple">
<li><p>Check <code class="docutils literal notranslate"><span class="pre">HSA_OVERRIDE_GFX_VERSION</span></code> for older GPUs</p></li>
<li><p>Verify ROCm version matches GPU architecture</p></li>
</ul>
<p>Multi-GPU Issues</p>
</section>
<section id="wrong-gpu-selected">
<h1>Wrong GPU Selected<a class="headerlink" href="#wrong-gpu-selected" title="Link to this heading"></a></h1>
<p><strong>Specify GPU</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set before any CUDA operations</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>  <span class="c1"># Use GPU 0</span>

<span class="c1"># Or in Python</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>In kernel</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;cuda:</span><span class="si">{</span><span class="n">gpu_id</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
</pre></div>
</div>
<p>Debugging Techniques</p>
</section>
<section id="print-debugging">
<h1>Print Debugging<a class="headerlink" href="#print-debugging" title="Link to this heading"></a></h1>
<p><strong>In kernel</strong> (limited):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@triton</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kernel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">pid</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Only print from first program</span>
    <span class="k">if</span> <span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">device_print</span><span class="p">(</span><span class="s2">&quot;pid:&quot;</span><span class="p">,</span> <span class="n">pid</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Outside kernel</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print shapes, dtypes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, dtype: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">, device: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Check values</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Min: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">, Max: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">, Mean: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Look for NaN/Inf</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Has NaN: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Has Inf: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="profiling">
<h1>Profiling<a class="headerlink" href="#profiling" title="Link to this heading"></a></h1>
<p><strong>NVIDIA</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Timeline profiling</span>
<span class="n">nsys</span> <span class="n">profile</span> <span class="o">-</span><span class="n">o</span> <span class="n">output</span> <span class="n">python</span> <span class="n">script</span><span class="o">.</span><span class="n">py</span>

<span class="c1"># Detailed metrics</span>
<span class="n">ncu</span> <span class="o">--</span><span class="nb">set</span> <span class="n">full</span> <span class="o">-</span><span class="n">o</span> <span class="n">output</span> <span class="n">python</span> <span class="n">script</span><span class="o">.</span><span class="n">py</span>

<span class="c1"># Specific metrics</span>
<span class="n">ncu</span> <span class="o">--</span><span class="n">metrics</span> <span class="n">dram__throughput</span><span class="o">.</span><span class="n">avg</span><span class="o">.</span><span class="n">pct_of_peak_sustained_elapsed</span> <span class="n">python</span> <span class="n">script</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p><strong>AMD</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rocprof</span> <span class="o">--</span><span class="n">stats</span> <span class="n">python</span> <span class="n">script</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section id="assertions">
<h1>Assertions<a class="headerlink" href="#assertions" title="Link to this heading"></a></h1>
<p><strong>Add runtime checks</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@triton</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kernel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="c1"># Check bounds</span>
    <span class="n">tl</span><span class="o">.</span><span class="n">static_assert</span><span class="p">(</span><span class="n">BLOCK_M</span> <span class="o">&lt;=</span> <span class="mi">256</span><span class="p">,</span> <span class="s2">&quot;BLOCK_M too large&quot;</span><span class="p">)</span>

    <span class="c1"># Runtime assertion</span>
    <span class="n">tl</span><span class="o">.</span><span class="n">device_assert</span><span class="p">(</span><span class="n">offset</span> <span class="o">&lt;</span> <span class="n">n_elements</span><span class="p">,</span> <span class="s2">&quot;Out of bounds&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="unit-testing">
<h1>Unit Testing<a class="headerlink" href="#unit-testing" title="Link to this heading"></a></h1>
<p><strong>Test correctness</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">test_my_kernel</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

    <span class="c1"># Triton result</span>
    <span class="n">y_triton</span> <span class="o">=</span> <span class="n">my_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Reference (PyTorch)</span>
    <span class="n">y_torch</span> <span class="o">=</span> <span class="n">reference_implementation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Check</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">y_triton</span><span class="p">,</span> <span class="n">y_torch</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</pre></div>
</div>
<p>Common Error Messages</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Error</p></th>
<th class="head"><p>Solution</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">CUDA</span> <span class="pre">out</span> <span class="pre">of</span> <span class="pre">memory</span></code></p></td>
<td><p>Reduce batch size, use gradient checkpointing</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">out</span> <span class="pre">of</span> <span class="pre">resource:</span> <span class="pre">shared</span> <span class="pre">memory</span></code></p></td>
<td><p>Reduce BLOCK_SIZE, num_stages</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">out</span> <span class="pre">of</span> <span class="pre">resource:</span> <span class="pre">registers</span></code></p></td>
<td><p>Reduce local variables, smaller blocks</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">constexpr</span> <span class="pre">parameter</span> <span class="pre">must</span> <span class="pre">be</span> <span class="pre">compile-time</span> <span class="pre">constant</span></code></p></td>
<td><p>Use <code class="docutils literal notranslate"><span class="pre">tl.constexpr</span></code> type annotation</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Tensor</span> <span class="pre">must</span> <span class="pre">be</span> <span class="pre">contiguous</span></code></p></td>
<td><p>Call <code class="docutils literal notranslate"><span class="pre">.contiguous()</span></code> on input</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Type</span> <span class="pre">mismatch</span></code></p></td>
<td><p>Explicit <code class="docutils literal notranslate"><span class="pre">to()</span></code> casting</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">AttributeError:</span> <span class="pre">'Tensor'</span> <span class="pre">object</span> <span class="pre">has</span> <span class="pre">no</span> <span class="pre">attribute</span> <span class="pre">'stride'</span></code></p></td>
<td><p>Pass tensor, not pointer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">unspecified</span> <span class="pre">launch</span> <span class="pre">failure</span></code></p></td>
<td><p>Out of bounds access, check masking</p></td>
</tr>
</tbody>
</table>
<p>Getting Help</p>
</section>
<section id="when-stuck">
<h1>When Stuck<a class="headerlink" href="#when-stuck" title="Link to this heading"></a></h1>
<ol class="arabic">
<li><p><strong>Search existing issues</strong>: <a class="reference external" href="https://github.com/openai/triton/issues">Triton GitHub Issues</a></p></li>
<li><p><strong>Minimal reproducible example</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">triton</span>

<span class="nd">@triton</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">broken_kernel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="c1"># Simplified version that shows the issue</span>
    <span class="o">...</span>
</pre></div>
</div>
</li>
<li><p><strong>Provide details</strong>:</p>
<ul class="simple">
<li><p>Error message (full stack trace)</p></li>
<li><p>Triton version: <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">triton;</span> <span class="pre">print(triton.__version__)</span></code></p></li>
<li><p>PyTorch version: <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">torch;</span> <span class="pre">print(torch.__version__)</span></code></p></li>
<li><p>GPU model: <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></p></li>
<li><p>Minimal code to reproduce</p></li>
</ul>
</li>
<li><p><strong>Ask in right place</strong>:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/openai/triton/discussions">Triton Discussions</a> - General questions</p></li>
<li><p><a class="reference external" href="https://github.com/openai/triton/issues">Triton Issues</a> - Bugs</p></li>
<li><p><a class="reference external" href="https://discuss.pytorch.org/">PyTorch Forums</a> - PyTorch integration</p></li>
</ul>
</li>
</ol>
<p>Best Practices for Avoiding Issues</p>
<ol class="arabic simple">
<li><p><strong>Start simple</strong>: Get basic version working before optimizing</p></li>
<li><p><strong>Test incrementally</strong>: Add features one at a time</p></li>
<li><p><strong>Verify correctness</strong>: Always compare with PyTorch</p></li>
<li><p><strong>Profile early</strong>: Understand bottlenecks before optimizing</p></li>
<li><p><strong>Use auto-tuning</strong>: Don’t guess optimal configurations</p></li>
<li><p><strong>Check edge cases</strong>: Non-power-of-2 sizes, empty tensors</p></li>
<li><p><strong>Handle boundaries</strong>: Always use masking for safety</p></li>
<li><p><strong>Maintain precision</strong>: Use float32 for accumulation</p></li>
</ol>
<p>Prevention Checklist</p>
<p>Before deploying:</p>
<p>[ ] Tested with various input sizes
[ ] Compared output with PyTorch
[ ] Profiled performance
[ ] Checked for NaN/Inf
[ ] Verified memory usage is reasonable
[ ] Tested edge cases (size=1, size=prime number, etc.)
[ ] Added assertions for debug builds
[ ] Documented any limitations</p>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h2>
<p>Most issues fall into three categories:</p>
<ol class="arabic simple">
<li><p><strong>Memory</strong>: OOM, shared memory limits -&gt; Reduce sizes</p></li>
<li><p><strong>Correctness</strong>: Wrong results, NaN -&gt; Check masking, precision, stability</p></li>
<li><p><strong>Performance</strong>: Slow -&gt; Profile, auto-tune, optimize memory access</p></li>
</ol>
<p>When in doubt:</p>
<ul class="simple">
<li><p>Profile to find the real bottleneck</p></li>
<li><p>Compare with PyTorch to verify correctness</p></li>
<li><p>Start simple and add complexity incrementally</p></li>
</ul>
<p>Still stuck? See <a class="reference internal" href="references.html"><span class="doc">Triton</span></a> for more resources.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="learning-paths.html" class="btn btn-neutral float-left" title="By Topic" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="references.html" class="btn btn-neutral float-right" title="Triton" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Fast Concurrent Programs.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>