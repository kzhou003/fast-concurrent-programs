

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Traditional Compiler Limitations &mdash; Fast Concurrent Programming Guide 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=1aac1d93" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/sidebar-fix.js?v=6c2f6f50"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="By Topic" href="../learning-paths.html" />
    <link rel="prev" title="The NVCC Compiler" href="04-cuda-comparison.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Fast Concurrent Programming Guide
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">CPU Concurrency</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html">Concurrency</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#parallelism">Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#visual-comparison">Visual Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#threading-concurrent-futures-threadpoolexecutor">Threading (concurrent.futures.ThreadPoolExecutor)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#multiprocessing-concurrent-futures-processpoolexecutor">Multiprocessing (concurrent.futures.ProcessPoolExecutor)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#when-to-use-what">When to Use What</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#what-is-the-gil">What is the GIL?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#key-points">Key Points:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#impact-on-performance">Impact on Performance:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#observing-the-gil-from-script-06">Observing the GIL (from script 06):</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#event-loop">Event Loop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#how-it-works-from-script-07">How It Works (from script 07):</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#event-loop-lifecycle">Event Loop Lifecycle:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#modern-vs-old-patterns">Modern vs Old Patterns:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#what-are-coroutines">What are Coroutines?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#defining-coroutines">Defining Coroutines:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#key-features">Key Features:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#example-from-script-08">Example from Script 08:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#execution-flow">Execution Flow:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#important-rules">Important Rules:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#tasks">Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#task-characteristics">Task Characteristics:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#example-from-script-09">Example from Script 09:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#futures">Futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#waiting-for-multiple-tasks">Waiting for Multiple Tasks:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#cpu-bound-operations">CPU-bound Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#i-o-bound-operations">I/O-bound Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#comparison-table">Comparison Table:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#hybrid-workloads">Hybrid Workloads:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#time-measurement-time-clock-time-perf-counter">1. Time Measurement (<code class="docutils literal notranslate"><span class="pre">time.clock()</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">time.perf_counter()</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#coroutine-syntax-asyncio-coroutine-async-def">2. Coroutine Syntax (<code class="docutils literal notranslate"><span class="pre">&#64;asyncio.coroutine</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">async</span> <span class="pre">def</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#task-creation-asyncio-task-asyncio-create-task">3. Task Creation (<code class="docutils literal notranslate"><span class="pre">asyncio.Task()</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">asyncio.create_task()</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#event-loop-management">4. Event Loop Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#future-callbacks-callbacks-await">5. Future Callbacks (Callbacks -&gt; <code class="docutils literal notranslate"><span class="pre">await</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#blocking-calls-in-async-code">6. Blocking Calls in Async Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#string-formatting-f-strings">7. String Formatting (<code class="docutils literal notranslate"><span class="pre">%</span></code> -&gt; f-strings)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#migration-checklist">Migration Checklist</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#compatibility">Compatibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#quick-reference-guide">Quick Reference Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/key_concepts.html#further-reading">Further Reading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html">Physical Cores</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#logical-cores">Logical Cores</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#the-concept">The Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#how-it-works">How It Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#technical-implementation">Technical Implementation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#performance-characteristics">Performance Characteristics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#hyperthreading-limitations">Hyperthreading Limitations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#checking-hyperthreading-status">Checking Hyperthreading Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#the-fundamental-constraint">The Fundamental Constraint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#why-more-threads-more-speed">Why More Threads != More Speed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#optimal-worker-count">Optimal Worker Count</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#real-world-example">Real-World Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#cpu-vs-gpu-different-design-philosophies">CPU vs GPU: Different Design Philosophies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#key-differences">Key Differences</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#simd-and-gpu-architecture">SIMD and GPU Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#why-gpus-excel-at-compute-intensive-tasks">Why GPUs Excel at Compute-Intensive Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#what-gpus-are-good-at">What GPUs Are Good At</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#silicon-real-estate-comparison">Silicon Real Estate Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#performance-comparison">Performance Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#detailed-benchmark-results">Detailed Benchmark Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#decision-matrix">Decision Matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#practical-guidelines">Practical Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#example-1-image-processing">Example 1: Image Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#example-2-monte-carlo-simulation">Example 2: Monte Carlo Simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#example-3-neural-network-training">Example 3: Neural Network Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#core-principles">Core Principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#quick-reference">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/hardware_parallelism.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/threading_basics.html">Key Points About start()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/threading_basics.html#example">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/threading_basics.html#key-points-about-join">Key Points About join()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/threading_basics.html#id1">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/threading_basics.html#without-join-danger">WITHOUT join() - DANGER!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/threading_basics.html#with-join-correct">WITH join() - CORRECT!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/threading_basics.html#mistake-1-calling-the-function-directly-instead-of-start">Mistake 1: Calling the function directly instead of start()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/threading_basics.html#mistake-2-forgetting-join">Mistake 2: Forgetting join()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/threading_basics.html#mistake-3-thinking-threads-share-data-automatically">Mistake 3: Thinking threads share data automatically</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/asyncio_event_loop.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/asyncio_event_loop.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/asyncio_coroutine.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/asyncio_coroutine.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/asyncio_coroutine.html#use-cases">Use Cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/asyncio_and_futures.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/asyncio_and_futures.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/asyncio_and_futures.html#examples">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/asyncio_task_manipulation.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/asyncio_task_manipulation.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/concurrent_futures_pooling.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/concurrent_futures_pooling.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#internal-structure">Internal Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#automatic-locking">Automatic Locking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#put-item"><code class="docutils literal notranslate"><span class="pre">put(item)</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#problem-with-manual-locks">Problem with Manual Locks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#how-queue-does-locking">How Queue Does Locking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#locking-benefits">Locking Benefits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#execution-flow">Execution Flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#thread-safe-data-structure">1. <strong>Thread-Safe Data Structure</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#blocks-correctly">2. <strong>Blocks Correctly</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#no-busy-waiting">3. <strong>No Busy-Waiting</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#task-tracking">4. <strong>Task Tracking</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#safe-for-multiple-producers-consumers">5. <strong>Safe for Multiple Producers/Consumers</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#step-by-step-what-happens-in-put">Step-by-Step: What Happens in <code class="docutils literal notranslate"><span class="pre">put()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#step-by-step-what-happens-in-get">Step-by-Step: What Happens in <code class="docutils literal notranslate"><span class="pre">get()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#mistake-1-forgetting-lock">Mistake 1: Forgetting Lock</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#mistake-2-busy-waiting">Mistake 2: Busy-Waiting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_explained.html#mistake-3-race-condition">Mistake 3: Race Condition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_internal_mechanics.html">The Answer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/queue_internal_mechanics.html#summary">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html">Without task_done() - Canâ€™t Track Completion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#with-task-done-can-track-completion">With task_done() - Can Track Completion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#internal-counter-system">Internal Counter System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#visual-timeline">Visual Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#code-simplified">Code (Simplified)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#two-operations">Two Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#timeline-all-three-conditions">Timeline: All Three Conditions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#put">put()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#get">get()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#task-done">task_done()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#join">join()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#scenario-1-producer-1-consumer">Scenario: 1 Producer, 1 Consumer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#step-1-put-increment-counter">Step 1: put() - Increment Counter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#step-2-get-item-removed-counter-unchanged">Step 2: get() - Item Removed, Counter Unchanged</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#step-3-task-done-decrement-counter">Step 3: task_done() - Decrement Counter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#step-4-join-wait-then-return">Step 4: join() - Wait, Then Return</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#diagram-tracking-one-task">Diagram: Tracking One Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#diagram-multiple-tasks">Diagram: Multiple Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#counter">Counter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#condition-variable">Condition Variable</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#together">Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#without-all-tasks-done-condition">Without all_tasks*done Condition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#queue-join-without-task-done">Queue.join() Without task_done()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#why-it-blocks-forever">Why It Blocks Forever</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#queue-join-with-task-done">Queue.join() With task_done()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#why-it-works">Why It Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#step-1-put-item">Step 1: Put Item</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#step-2-get-and-process">Step 2: Get and Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#step-3-mark-done">Step 3: Mark Done</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#flow-diagram">Flow Diagram</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#without-task-done-problematic">Without task_done() - PROBLEMATIC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#with-task-done-correct">With task_done() - CORRECT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#use-case-1-verify-all-work-complete">Use Case 1: Verify All Work Complete</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#use-case-2-track-progress">Use Case 2: Track Progress</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#use-case-3-batch-processing">Use Case 3: Batch Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#scenario-main-thread-needs-to-know-when-workers-finish">Scenario: Main thread needs to know when workers finish</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#timeline">Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#better-code-pattern">Better Code Pattern</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#why-we-need-task-done">Why We Need task_done()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/task_done_queue_explained.html#the-pattern">The Pattern</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/rlock_explained.html">Regular Lock vs RLock</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/rlock_explained.html#why-rlock-is-needed-here">Why RLock is Needed Here</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/rlock_explained.html#use-regular-lock-when">Use Regular Lock When:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/rlock_explained.html#use-rlock-when">Use RLock When:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/rlock_explained.html#regular-lock-would-deadlock">Regular Lock - Would Deadlock</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/rlock_explained.html#rlock-no-deadlock">RLock - No Deadlock</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#counting-semaphore-counter-1">1. Counting Semaphore (Counter &gt; 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#binary-semaphore-counter-0-or-1">2. Binary Semaphore (Counter = 0 or 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#execution-timeline">Execution Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#acquire"><code class="docutils literal notranslate"><span class="pre">acquire()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#counting-semaphore-3-spots-available">Counting Semaphore (3 spots available)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#binary-semaphore-producer-consumer">Binary Semaphore (Producer-Consumer)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#example-1-swimming-pool-with-limited-capacity">Example 1: Swimming Pool with Limited Capacity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#example-2-producer-consumer-like-the-code">Example 2: Producer-Consumer (Like the Code)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#limiting-concurrent-access">1. <strong>Limiting Concurrent Access</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#producer-consumer-communication">2. <strong>Producer-Consumer Communication</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#synchronizing-multiple-threads">3. <strong>Synchronizing Multiple Threads</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#lock-threading-lock">Lock (<code class="docutils literal notranslate"><span class="pre">threading.Lock</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#semaphore-counting">Semaphore (Counting)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/semaphore_explained.html#semaphore-binary-used-as-signal">Semaphore (Binary - Used as Signal)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html">What is the GIL?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#why-does-python-have-a-gil">Why Does Python Have a GIL?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#how-the-gil-works">How the GIL Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#gil-behavior-with-different-operations">GIL Behavior with Different Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#the-critical-difference">The Critical Difference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#cpu-bound-operations">CPU-bound Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#i-o-bound-operations">I/O-bound Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#real-world-analogy">Real-World Analogy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#the-problem-with-threading-for-cpu-bound">The Problem with Threading for CPU-bound</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#the-solution-multiprocessing">The Solution: Multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#how-multiprocessing-bypasses-the-gil">How Multiprocessing Bypasses the GIL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#trade-offs-of-multiprocessing">Trade-offs of Multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#when-the-trade-off-is-worth-it">When the Trade-off is Worth It</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#the-problem-wasted-time">The Problem: Wasted Time</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#the-solution-threading">The Solution: Threading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#why-threading-works-for-i-o">Why Threading Works for I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#how-the-os-helps">How the OS Helps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#performance-comparison">Performance Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#why-not-multiprocessing-for-i-o">Why Not Multiprocessing for I/O?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#threading-trade-offs">Threading Trade-offs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#the-problem-with-threading-overhead">The Problem with Threading: Overhead</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#asyncio-cooperative-multitasking">Asyncio: Cooperative Multitasking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#how-asyncio-works">How Asyncio Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#event-loop-visualization">Event Loop Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#asyncio-vs-threading-detailed-comparison">Asyncio vs Threading: Detailed Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#performance-characteristics">Performance Characteristics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#when-asyncio-shines">When Asyncio Shines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#asyncio-trade-offs">Asyncio Trade-offs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#cpu-bound-with-threading-the-gil-dance">CPU-bound with Threading: The GIL Dance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#cpu-bound-with-multiprocessing-true-parallel">CPU-bound with Multiprocessing: True Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#i-o-bound-with-threading-gil-released">I/O-bound with Threading: GIL Released</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#i-o-bound-with-asyncio-event-loop-magic">I/O-bound with Asyncio: Event Loop Magic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#benchmark-cpu-bound-task-computing-pi">Benchmark: CPU-bound Task (Computing pi)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#benchmark-i-o-bound-task-web-requests">Benchmark: I/O-bound Task (Web Requests)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#benchmark-mixed-workload">Benchmark: Mixed Workload</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#quick-reference-table">Quick Reference Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#code-templates">Code Templates</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#the-gil-controls-everything">1. The GIL Controls Everything</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#resource-usage-matters">2. Resource Usage Matters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#trade-offs-are-real">3. Trade-offs are Real</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpu-concurrency/patterns_problems_mapping.html#know-your-workload">4. Know Your Workload</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html">Key Differences: CPU vs GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#streaming-multiprocessors-sms">Streaming Multiprocessors (SMs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#thread-organization">Thread Organization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/gpu-fundamentals.html#example-visualization">Example Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#l2-cache">L2 Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#registers">Registers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/memory-hierarchy.html#summary">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html">Warps and SIMD Execution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#thread-divergence">Thread Divergence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#what-is-occupancy">What is Occupancy?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#factors-limiting-occupancy">Factors Limiting Occupancy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#example-calculation">Example Calculation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#why-occupancy-matters">Why Occupancy Matters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#the-occupancy-sweet-spot">The Occupancy Sweet Spot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#grid-and-block-dimensions">Grid and Block Dimensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#choosing-block-size">Choosing Block Size</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#within-a-block">Within a Block</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#between-blocks">Between Blocks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#warp-shuffles">Warp Shuffles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#warp-level-reductions">Warp-Level Reductions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#overlap-compute-and-memory">Overlap Compute and Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#traditional-approach">Traditional Approach</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#persistent-approach">Persistent Approach</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#key-factors">Key Factors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/execution-model.html#profiling-tools">Profiling Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html">Step 1: Profile First</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#step-2-identify-bottleneck">Step 2: Identify Bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-1-kernel-fusion">Strategy 1: Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-2-tiling">Strategy 2: Tiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-3-vectorized-loads">Strategy 3: Vectorized Loads</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-4-memory-coalescing">Strategy 4: Memory Coalescing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-1-use-tensor-cores">Strategy 1: Use Tensor Cores</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-2-increase-arithmetic-intensity">Strategy 2: Increase Arithmetic Intensity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-3-minimize-thread-divergence">Strategy 3: Minimize Thread Divergence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-4-optimize-loop-structure">Strategy 4: Optimize Loop Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-1-reduce-register-usage">Strategy 1: Reduce Register Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-2-tune-shared-memory">Strategy 2: Tune Shared Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#strategy-3-adjust-block-size">Strategy 3: Adjust Block Size</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#why-auto-tune">Why Auto-Tune?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#triton-auto-tuning">Triton Auto-Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#warp-specialization">Warp Specialization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#persistent-kernels">Persistent Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#recomputation">Recomputation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#pattern-reduction">Pattern: Reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#pattern-element-wise">Pattern: Element-wise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#pattern-matrix-multiply">Pattern: Matrix Multiply</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#issue-low-bandwidth">Issue: Low Bandwidth</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#issue-low-compute-utilization">Issue: Low Compute Utilization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#issue-lower-than-pytorch">Issue: Lower Than PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#before-you-optimize">Before You Optimize</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#memory-optimizations">Memory Optimizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#compute-optimizations">Compute Optimizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#occupancy-optimization">Occupancy Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/performance-optimization.html#advanced">Advanced</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-concepts/triton-concepts.html">Triton Concepts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/01-vector-add.html#next-steps">Next Steps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/02-fused-softmax.html#extensions">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/03-matrix-multiplication.html">Matrix Multiplication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/04-low-memory-dropout.html">Low Memory Dropout</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/05-layer-norm.html">Layer Norm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/06-fused-attention.html">Fused Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/07-extern-functions.html">Extern Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/08-grouped-gemm.html#summary">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/09-persistent-matmul.html#summary">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-tutorials/10-block-scaled-matmul.html#summary">Summary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton Compiler</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="01-overview.html">Key Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#stage-1-python-ast-parsing">Stage 1: Python AST Parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#stage-2-code-generation-ttir">Stage 2: Code Generation (TTIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#stage-3-triton-gpu-ir-ttgir">Stage 3: Triton GPU IR (TTGIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#stage-4-llvm-ir">Stage 4: LLVM IR</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#stage-5-ptx-amdgcn">Stage 5: PTX / AMDGCN</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#stage-6-binary-cubin-hsaco">Stage 6: Binary (CUBIN / HSACO)</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#block-based-programming-model">Block-based Programming Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#jit-compilation">JIT Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#mlir-infrastructure">MLIR Infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#python-components">Python Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#c-components">C++ Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-overview.html#backend-components">Backend Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="02-jit-decorator.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="02-jit-decorator.html#summary">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html">CodeGenerator Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#ast-visitor-pattern">AST Visitor Pattern</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#triton-language-primitives">Triton Language Primitives</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#type-inference">Type Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#example-ttir-output">Example TTIR Output</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#compilation-orchestration">Compilation Orchestration</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#ttir-ttgir-transformation">TTIR -&gt; TTGIR Transformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#ttgir-llvm-ir">TTGIR -&gt; LLVM IR</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#llvm-ir-ptx">LLVM IR -&gt; PTX</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#ptx-cubin">PTX -&gt; CUBIN</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#cache-key-components">Cache Key Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#cache-directory-structure">Cache Directory Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-compilation-pipeline.html#cache-lookup">Cache Lookup</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html">The NVCC Compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#nvcc-compilation-stages">NVCC Compilation Stages</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#ptx-assembly-output">PTX Assembly Output</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#the-llvm-path">The LLVM Path</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#llvm-ir-stage">LLVM IR Stage</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#ptx-generated-by-triton">PTX Generated by Triton</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#same-tools-same-artifacts">Same Tools, Same Artifacts</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#source-language">Source Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#compiler-stack">Compiler Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#compilation-time">Compilation Time</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#optimization-levels">Optimization Levels</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#can-triton-and-cuda-c-work-together">Can Triton and CUDA C++ Work Together?</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#advantages-of-llvm-backend">Advantages of LLVM Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#why-not-use-nvcc">Why Not Use NVCC?</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#trade-offs">Trade-offs</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#file-types">File Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#example-directory-structures">Example Directory Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#ptx-inspection">PTX Inspection</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#cubin-inspection">CUBIN Inspection</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#compilation-paths-compared">Compilation Paths Compared</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-cuda-comparison.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Traditional Compiler Limitations</a></li>
<li class="toctree-l1"><a class="reference internal" href="#example-matrix-multiplication">Example: Matrix Multiplication</a></li>
<li class="toctree-l1"><a class="reference internal" href="#mlir-philosophy">MLIR Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="#dialects">1. Dialects</a></li>
<li class="toctree-l1"><a class="reference internal" href="#operations">2. Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="#regions-and-blocks">3. Regions and Blocks</a></li>
<li class="toctree-l1"><a class="reference internal" href="#types">4. Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="#attributes">5. Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="#passes">6. Passes</a></li>
<li class="toctree-l1"><a class="reference internal" href="#why-triton-uses-mlir">Why Triton Uses MLIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="#triton-s-mlir-dialects">Tritonâ€™s MLIR Dialects</a></li>
<li class="toctree-l1"><a class="reference internal" href="#python-source">Python Source</a></li>
<li class="toctree-l1"><a class="reference internal" href="#stage-1-triton-ir-ttir">Stage 1: Triton IR (TTIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="#stage-2-tritongpu-ir-ttgir">Stage 2: TritonGPU IR (TTGIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="#stage-3-llvm-dialect">Stage 3: LLVM Dialect</a></li>
<li class="toctree-l1"><a class="reference internal" href="#stage-4-llvm-ir-actual">Stage 4: LLVM IR (Actual)</a></li>
<li class="toctree-l1"><a class="reference internal" href="#command-line-tools">Command-Line Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="#tablegen-for-defining-operations">TableGen for Defining Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="#debugging-mlir">Debugging MLIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="#official-documentation">Official Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="#tutorials">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="#triton-specific">Triton-Specific</a></li>
<li class="toctree-l1"><a class="reference internal" href="#key-concepts-recap">Key Concepts Recap</a></li>
<li class="toctree-l1"><a class="reference internal" href="#why-mlir-matters-for-triton">Why MLIR Matters for Triton</a></li>
<li class="toctree-l1"><a class="reference internal" href="#the-big-picture">The Big Picture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../learning-paths.html">Learning Paths</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html">CUDA Out of Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#out-of-shared-memory">Out of Shared Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#wrong-results">Wrong Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#nan-or-inf-values">NaN or Inf Values</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#slower-than-pytorch">Slower Than PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#low-gpu-utilization">Low GPU Utilization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#compilation-errors">Compilation Errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#slow-compilation">Slow Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#nvidia-specific">NVIDIA-Specific</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#amd-specific">AMD-Specific</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#wrong-gpu-selected">Wrong GPU Selected</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#print-debugging">Print Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#profiling">Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#assertions">Assertions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#unit-testing">Unit Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html#when-stuck">When Stuck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">Triton</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#cuda">CUDA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#rocm-amd">ROCm (AMD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#pytorch">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#flash-attention">Flash Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#normalization">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#optimization-techniques">Optimization Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#id1">Triton</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#gpu-programming">GPU Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#deep-learning">Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#nvidia-tools">NVIDIA Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#amd-tools">AMD Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#pytorch-profiler">PyTorch Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#benchmarking">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#tutorials-and-courses">Tutorials and Courses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#community">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#blogs-and-articles">Blogs and Articles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#triton-examples">Triton Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#production-usage">Production Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#nvidia-gpus">NVIDIA GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#amd-gpus">AMD GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#subscribe-to">Subscribe To</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html#conferences">Conferences</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Fast Concurrent Programming Guide</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Traditional Compiler Limitations</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/triton-compiler/05-mlir-concepts.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p>MLIR: Core Concepts and Triton Usage</p>
<p>This document explains MLIR (Multi-Level Intermediate Representation), the compiler infrastructure that powers Tritonâ€™s compilation pipeline.</p>
<p>What is MLIR?</p>
<p><strong>MLIR (Multi-Level Intermediate Representation)</strong> is a compiler infrastructure project that provides a flexible framework for building optimizing compilers.</p>
<p><strong>Created by:</strong> Google (now part of LLVM project)</p>
<p><strong>Purpose:</strong> Enable building domain-specific compilers with reusable components</p>
<p><strong>Key idea:</strong> Instead of one â€œuniversalâ€ IR, support multiple IRs (dialects) that can coexist and transform between each other.</p>
<p>The Problem MLIR Solves</p>
<section id="traditional-compiler-limitations">
<h1>Traditional Compiler Limitations<a class="headerlink" href="#traditional-compiler-limitations" title="Link to this heading">ïƒ</a></h1>
<p><strong>LLVM IR</strong> (the traditional choice) has limitations:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>High-level code (Python, TensorFlow, etc.)
        down
[MASSIVE LOWERING GAP] &lt;- Information loss!
        down
LLVM IR (very low-level)
        down
Machine code
</pre></div>
</div>
<p><strong>Problems:</strong></p>
<ol class="arabic simple">
<li><p><strong>Information loss</strong> - High-level semantics disappear immediately</p></li>
<li><p><strong>Optimization difficulty</strong> - Hard to optimize after lowering</p></li>
<li><p><strong>Single abstraction level</strong> - Canâ€™t represent domain-specific concepts</p></li>
<li><p><strong>Vendor lock-in</strong> - Different vendors create incompatible IRs</p></li>
</ol>
</section>
<section id="example-matrix-multiplication">
<h1>Example: Matrix Multiplication<a class="headerlink" href="#example-matrix-multiplication" title="Link to this heading">ïƒ</a></h1>
<p><strong>High-level code:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">C</span> <span class="o">=</span> <span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>  <span class="c1"># Semantic: &quot;matrix multiplication&quot;</span>
</pre></div>
</div>
<p><strong>Direct lowering to LLVM IR loses meaning:</strong></p>
<div class="highlight-llvm notranslate"><div class="highlight"><pre><span></span><span class="c">; LLVM IR - just loops and arithmetic!</span>
<span class="c">; Lost information: &quot;this is a matrix multiply&quot;</span>
<span class="err">f</span><span class="k">or</span><span class="w"> </span><span class="err">i</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">rows</span><span class="p">(</span><span class="err">A</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="err">f</span><span class="k">or</span><span class="w"> </span><span class="err">j</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">cols</span><span class="p">(</span><span class="err">B</span><span class="p">)</span><span class="err">:</span>
<span class="w">        </span><span class="err">f</span><span class="k">or</span><span class="w"> </span><span class="err">k</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">cols</span><span class="p">(</span><span class="err">A</span><span class="p">)</span><span class="err">:</span>
<span class="w">            </span><span class="err">C</span><span class="p">[</span><span class="err">i</span><span class="p">][</span><span class="err">j</span><span class="p">]</span><span class="w"> </span><span class="err">+</span><span class="p">=</span><span class="w"> </span><span class="err">A</span><span class="p">[</span><span class="err">i</span><span class="p">][</span><span class="err">k</span><span class="p">]</span><span class="w"> </span><span class="p">*</span><span class="w"> </span><span class="err">B</span><span class="p">[</span><span class="err">k</span><span class="p">][</span><span class="err">j</span><span class="p">]</span><span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="err">Generi</span><span class="k">c</span><span class="w"> </span><span class="err">loops</span>
</pre></div>
</div>
<p><strong>With MLIR, preserve semantics longer:</strong></p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>// High-level: Linalg dialect preserves &quot;matrix multiply&quot; operation
linalg.matmul ins(%A, %B) outs(%C)

// Mid-level: Affine dialect with loop structure
affine.for %i in [0, M):
    affine.for %j in [0, N):
        affine.for %k in [0, K):
            // ...

// Low-level: LLVM dialect
llvm.mul %a, %b
</pre></div>
</div>
<p>This <strong>gradual lowering</strong> preserves optimization opportunities at each level.</p>
</section>
<section id="mlir-philosophy">
<h1>MLIR Philosophy<a class="headerlink" href="#mlir-philosophy" title="Link to this heading">ïƒ</a></h1>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Traditional Compiler:
Source -&gt; [BIG STEP] -&gt; LLVM IR -&gt; Binary
                up
        Loss of information!

MLIR Compiler:
Source -&gt; Dialect1 -&gt; Dialect2 -&gt; ... -&gt; DialectN -&gt; Binary
         down         down         down         down
      Small, incremental lowering steps
      (Preserve information as long as possible)
</pre></div>
</div>
<p><strong>Key benefits:</strong></p>
<ul class="simple">
<li><p>[[OK]] Gradual lowering preserves semantics</p></li>
<li><p>[[OK]] Multiple abstraction levels coexist</p></li>
<li><p>[[OK]] Reusable optimization passes</p></li>
<li><p>[[OK]] Domain-specific dialects</p></li>
</ul>
<p>Core MLIR Concepts</p>
</section>
<section id="dialects">
<h1>1. Dialects<a class="headerlink" href="#dialects" title="Link to this heading">ïƒ</a></h1>
<p>A <strong>dialect</strong> is a namespace for operations, types, and attributes.</p>
<p><strong>Think of dialects as â€œsublanguagesâ€ within MLIR.</strong></p>
<section id="common-dialects">
<h2>Common Dialects<a class="headerlink" href="#common-dialects" title="Link to this heading">ïƒ</a></h2>
<p>Dialect             Purpose                                         Abstraction Level
<code class="docutils literal notranslate"><span class="pre">linalg</span></code>          Linear algebra operations                       High-level
<code class="docutils literal notranslate"><span class="pre">tensor</span></code>          Tensor operations                               High-level
<code class="docutils literal notranslate"><span class="pre">scf</span></code>             Structured control flow (for, while, if)        Mid-level
<code class="docutils literal notranslate"><span class="pre">affine</span></code>          Polyhedral loop optimizations                   Mid-level
<code class="docutils literal notranslate"><span class="pre">arith</span></code>           Arithmetic operations (add, mul, etc.)          Low-level
<code class="docutils literal notranslate"><span class="pre">llvm</span></code>            LLVM IR operations                              Very low-level
<code class="docutils literal notranslate"><span class="pre">gpu</span></code>             Generic GPU operations                          GPU-specific
<code class="docutils literal notranslate"><span class="pre">nvgpu</span></code>           NVIDIA GPU-specific operations                  NVIDIA-specific</p>
</section>
<section id="triton-s-custom-dialects">
<h2>Tritonâ€™s Custom Dialects<a class="headerlink" href="#triton-s-custom-dialects" title="Link to this heading">ïƒ</a></h2>
<p>Triton defines its own dialects:</p>
<p>Dialect             Purpose                                         File Location
<code class="docutils literal notranslate"><span class="pre">tt</span></code>              Triton dialect (TTIR)                           <code class="docutils literal notranslate"><span class="pre">lib/Dialect/Triton/</span></code>
<code class="docutils literal notranslate"><span class="pre">ttg</span></code>             Triton GPU dialect (TTGIR)                      <code class="docutils literal notranslate"><span class="pre">lib/Dialect/TritonGPU/</span></code>
<code class="docutils literal notranslate"><span class="pre">ttng</span></code>            Triton NVIDIA GPU dialect                       <code class="docutils literal notranslate"><span class="pre">lib/Dialect/TritonNvidiaGPU/</span></code></p>
<p><strong>Example:</strong> Mixing dialects in one function</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>func.func @example(%arg0: tensor&lt;128xf32&gt;) -&gt; tensor&lt;128xf32&gt; {
    %c0 = arith.constant 0 : index        // arith dialect
    %c128 = arith.constant 128 : index

    %0 = scf.for %i = %c0 to %c128        // scf dialect
        iter_args(%arg = %arg0) -&gt; tensor&lt;128xf32&gt; {
        %1 = linalg.generic { ... }       // linalg dialect
        scf.yield %1
    }

    return %0 : tensor&lt;128xf32&gt;
}
</pre></div>
</div>
</section>
</section>
<section id="operations">
<h1>2. Operations<a class="headerlink" href="#operations" title="Link to this heading">ïƒ</a></h1>
<p><strong>Operations</strong> (ops) are the fundamental unit of computation in MLIR.</p>
<section id="operation-anatomy">
<h2>Operation Anatomy<a class="headerlink" href="#operation-anatomy" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>%result = dialect.operation(%operand1, %operand2) {attribute = value} : type

// Example:
%sum = arith.addi %a, %b : i32
//  up       up      up   up    up
// result  op   operands  type
</pre></div>
</div>
<p><strong>Components:</strong></p>
<ul class="simple">
<li><p><strong>Opcode:</strong> <code class="docutils literal notranslate"><span class="pre">dialect.operation</span></code> (e.g., <code class="docutils literal notranslate"><span class="pre">arith.addi</span></code>)</p></li>
<li><p><strong>Operands:</strong> Input values (SSA form)</p></li>
<li><p><strong>Results:</strong> Output values (SSA form)</p></li>
<li><p><strong>Attributes:</strong> Compile-time constants (metadata)</p></li>
<li><p><strong>Types:</strong> Data types of operands and results</p></li>
<li><p><strong>Regions:</strong> Nested code blocks (optional)</p></li>
</ul>
</section>
<section id="ssa-form-static-single-assignment">
<h2>SSA Form (Static Single Assignment)<a class="headerlink" href="#ssa-form-static-single-assignment" title="Link to this heading">ïƒ</a></h2>
<p>Every value is defined <strong>exactly once</strong>:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>// Valid SSA:
%0 = arith.constant 5 : i32
%1 = arith.constant 10 : i32
%2 = arith.addi %0, %1 : i32  // %2 defined once

// Invalid (not SSA):
%x = arith.constant 5 : i32
%x = arith.addi %x, %x : i32  // ERROR: %x redefined!
</pre></div>
</div>
<p><strong>Benefits:</strong></p>
<ul class="simple">
<li><p>Simplifies optimization (no aliasing confusion)</p></li>
<li><p>Easier data flow analysis</p></li>
<li><p>Natural for functional-style transformations</p></li>
</ul>
</section>
<section id="operation-examples">
<h2>Operation Examples<a class="headerlink" href="#operation-examples" title="Link to this heading">ïƒ</a></h2>
<p><strong>Arithmetic:</strong></p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>%sum = arith.addi %a, %b : i32           // Integer addition
%prod = arith.mulf %x, %y : f32          // Float multiplication
%cmp = arith.cmpi slt, %a, %b : i32      // Compare: a &lt; b
</pre></div>
</div>
<p><strong>Triton-specific:</strong></p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>%pid = tt.get_program_id x : i32         // Get block ID
%range = tt.make_range {start=0, end=128} : tensor&lt;128xi32&gt;
%ptr = tt.addptr %base, %offset : !tt.ptr&lt;f32&gt;
%data = tt.load %ptr, %mask : tensor&lt;128xf32&gt;
</pre></div>
</div>
<p><strong>Control flow:</strong></p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>scf.if %condition {
    // true branch
} else {
    // false branch
}

scf.for %i = %lb to %ub step %step {
    // loop body
}
</pre></div>
</div>
</section>
</section>
<section id="regions-and-blocks">
<h1>3. Regions and Blocks<a class="headerlink" href="#regions-and-blocks" title="Link to this heading">ïƒ</a></h1>
<section id="regions">
<h2>Regions<a class="headerlink" href="#regions" title="Link to this heading">ïƒ</a></h2>
<p>A <strong>region</strong> is a container for code, similar to a scope.</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>scf.if %cond {
    // &lt;- This is a region
    %x = arith.constant 1 : i32
}
</pre></div>
</div>
<p><strong>Properties:</strong></p>
<ul class="simple">
<li><p>Isolated scope (can have local SSA values)</p></li>
<li><p>Can contain multiple basic blocks</p></li>
<li><p>Used for control flow (if, for, while, functions)</p></li>
</ul>
</section>
<section id="blocks">
<h2>Blocks<a class="headerlink" href="#blocks" title="Link to this heading">ïƒ</a></h2>
<p>A <strong>block</strong> is a sequence of operations with a single entry point.</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>^bb0(%arg0: i32, %arg1: i32):  // Block with arguments
    %sum = arith.addi %arg0, %arg1 : i32
    cf.br ^bb1(%sum : i32)      // Branch to next block

^bb1(%result: i32):
    return %result : i32
</pre></div>
</div>
<p><strong>Key properties:</strong></p>
<ul class="simple">
<li><p>Basic block (no control flow within the block)</p></li>
<li><p>Can have block arguments (like function parameters)</p></li>
<li><p>Ends with a terminator (return, branch, etc.)</p></li>
</ul>
</section>
<section id="example-with-regions-and-blocks">
<h2>Example with Regions and Blocks<a class="headerlink" href="#example-with-regions-and-blocks" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>func.func @example(%n: i32) -&gt; i32 {
    // Function body is a region with one block

    %c0 = arith.constant 0 : i32
    %c1 = arith.constant 1 : i32

    %result = scf.for %i = %c0 to %n step %c1
        iter_args(%acc = %c0) -&gt; i32 {
        // &lt;- For loop body is a region

        %new_acc = arith.addi %acc, %i : i32
        scf.yield %new_acc : i32  // Yield to next iteration
    }

    return %result : i32
}
</pre></div>
</div>
</section>
</section>
<section id="types">
<h1>4. Types<a class="headerlink" href="#types" title="Link to this heading">ïƒ</a></h1>
<p>MLIR has a <strong>flexible type system</strong> that dialects can extend.</p>
<section id="built-in-types">
<h2>Built-in Types<a class="headerlink" href="#built-in-types" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>// Integers
i1                      // 1-bit (boolean)
i8, i16, i32, i64       // Signed integers
ui8, ui16, ui32         // Unsigned integers

// Floats
f16, f32, f64           // IEEE floats
bf16                    // bfloat16

// Vectors and tensors
vector&lt;4xf32&gt;           // 4-element float vector
tensor&lt;128x128xf32&gt;     // 2D tensor
tensor&lt;?x?xf32&gt;         // Dynamic-shape tensor

// Pointers
!llvm.ptr&lt;f32&gt;          // LLVM pointer to float

// Functions
(i32, i32) -&gt; i32       // Function type
</pre></div>
</div>
</section>
<section id="triton-custom-types">
<h2>Triton Custom Types<a class="headerlink" href="#triton-custom-types" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>!tt.ptr&lt;f32&gt;                    // Triton pointer
!tt.ptr&lt;tensor&lt;128xf32&gt;&gt;        // Pointer to tensor
tensor&lt;128x!tt.ptr&lt;f32&gt;&gt;        // Tensor of pointers
</pre></div>
</div>
<p><strong>Why custom types?</strong></p>
<ul class="simple">
<li><p>Triton pointers have different semantics than LLVM pointers</p></li>
<li><p>Support block/tensor operations naturally</p></li>
<li><p>Enable Triton-specific optimizations</p></li>
</ul>
</section>
<section id="type-conversion">
<h2>Type Conversion<a class="headerlink" href="#type-conversion" title="Link to this heading">ïƒ</a></h2>
<p>Types change as you lower between dialects:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>// High-level (Triton)
%data : tensor&lt;128xf32&gt;

// Mid-level (TritonGPU) - add layout
%data : tensor&lt;128xf32, #ttg.blocked&lt;{threads=128}&gt;&gt;

// Low-level (LLVM) - flatten to individual values
%data : !llvm.array&lt;128 x f32&gt;
</pre></div>
</div>
</section>
</section>
<section id="attributes">
<h1>5. Attributes<a class="headerlink" href="#attributes" title="Link to this heading">ïƒ</a></h1>
<p><strong>Attributes</strong> are compile-time constants attached to operations.</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>// Integer attribute
%c = arith.constant 42 : i32
//                   upup
//              attribute value

// Dictionary attribute
tt.make_range {start = 0 : i32, end = 128 : i32}
//            up                                  up
//            dictionary with start/end fields

// Array attribute
llvm.call @func(%arg) {fastmathFlags = #llvm.fastmath&lt;fast&gt;}
</pre></div>
</div>
<section id="common-attribute-types">
<h2>Common Attribute Types<a class="headerlink" href="#common-attribute-types" title="Link to this heading">ïƒ</a></h2>
<ul class="simple">
<li><p><strong>IntegerAttr:</strong> <code class="docutils literal notranslate"><span class="pre">42</span> <span class="pre">:</span> <span class="pre">i32</span></code></p></li>
<li><p><strong>FloatAttr:</strong> <code class="docutils literal notranslate"><span class="pre">3.14</span> <span class="pre">:</span> <span class="pre">f32</span></code></p></li>
<li><p><strong>StringAttr:</strong> <code class="docutils literal notranslate"><span class="pre">&quot;hello&quot;</span></code></p></li>
<li><p><strong>ArrayAttr:</strong> <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">3]</span></code></p></li>
<li><p><strong>DictionaryAttr:</strong> <code class="docutils literal notranslate"><span class="pre">{key1</span> <span class="pre">=</span> <span class="pre">val1,</span> <span class="pre">key2</span> <span class="pre">=</span> <span class="pre">val2}</span></code></p></li>
<li><p><strong>TypeAttr:</strong> Type as a value</p></li>
<li><p><strong>UnitAttr:</strong> Presence/absence flag</p></li>
</ul>
</section>
<section id="triton-layout-attributes">
<h2>Triton Layout Attributes<a class="headerlink" href="#triton-layout-attributes" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>// Blocked layout: how data is distributed across threads
#ttg.blocked&lt;{
    sizePerThread = [1, 4],
    threadsPerWarp = [2, 16],
    warpsPerCTA = [4, 1],
    order = [1, 0]
}&gt;

// Shared memory layout
#ttg.shared&lt;{
    vec = 8,
    perPhase = 2,
    maxPhase = 4
}&gt;
</pre></div>
</div>
</section>
</section>
<section id="passes">
<h1>6. Passes<a class="headerlink" href="#passes" title="Link to this heading">ïƒ</a></h1>
<p><strong>Passes</strong> are transformations that modify MLIR code.</p>
<section id="pass-types">
<h2>Pass Types<a class="headerlink" href="#pass-types" title="Link to this heading">ïƒ</a></h2>
<ol class="arabic simple">
<li><p><strong>Analysis passes</strong> - Gather information (donâ€™t modify IR)</p></li>
<li><p><strong>Transformation passes</strong> - Modify IR</p></li>
<li><p><strong>Canonicalization</strong> - Simplify IR to canonical form</p></li>
<li><p><strong>Lowering passes</strong> - Convert between dialects</p></li>
</ol>
</section>
<section id="example-pass-pipeline">
<h2>Example Pass Pipeline<a class="headerlink" href="#example-pass-pipeline" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Triton&#39;s pass pipeline (simplified)</span>
<span class="n">pm</span> <span class="o">=</span> <span class="n">PassManager</span><span class="p">()</span>

<span class="c1"># High-level optimizations (TTIR)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">add_pass</span><span class="p">(</span><span class="s2">&quot;triton-combine&quot;</span><span class="p">)</span>              <span class="c1"># Combine operations</span>
<span class="n">pm</span><span class="o">.</span><span class="n">add_pass</span><span class="p">(</span><span class="s2">&quot;canonicalize&quot;</span><span class="p">)</span>                <span class="c1"># Simplify</span>

<span class="c1"># Lower to GPU IR (TTIR -&gt; TTGIR)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">add_pass</span><span class="p">(</span><span class="s2">&quot;triton-gpu-coalesce&quot;</span><span class="p">)</span>         <span class="c1"># Coalesce memory accesses</span>
<span class="n">pm</span><span class="o">.</span><span class="n">add_pass</span><span class="p">(</span><span class="s2">&quot;triton-gpu-pipeline&quot;</span><span class="p">)</span>         <span class="c1"># Software pipelining</span>
<span class="n">pm</span><span class="o">.</span><span class="n">add_pass</span><span class="p">(</span><span class="s2">&quot;triton-gpu-prefetch&quot;</span><span class="p">)</span>         <span class="c1"># Insert prefetch</span>
<span class="n">pm</span><span class="o">.</span><span class="n">add_pass</span><span class="p">(</span><span class="s2">&quot;triton-gpu-optimize-dot&quot;</span><span class="p">)</span>     <span class="c1"># Optimize matmul</span>

<span class="c1"># Lower to LLVM (TTGIR -&gt; LLVM)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">add_pass</span><span class="p">(</span><span class="s2">&quot;convert-triton-gpu-to-llvm&quot;</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">add_pass</span><span class="p">(</span><span class="s2">&quot;convert-scf-to-cf&quot;</span><span class="p">)</span>           <span class="c1"># Structured -&gt; unstructured control flow</span>
<span class="n">pm</span><span class="o">.</span><span class="n">add_pass</span><span class="p">(</span><span class="s2">&quot;convert-arith-to-llvm&quot;</span><span class="p">)</span>

<span class="n">pm</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="triton-specific-passes">
<h2>Triton-Specific Passes<a class="headerlink" href="#triton-specific-passes" title="Link to this heading">ïƒ</a></h2>
<p><em>Location:</em> <a class="reference external" href="https://github.com/triton-lang/triton/tree/v3.5.1/lib/Dialect/TritonGPU/Transforms">lib/Dialect/TritonGPU/Transforms/</a></p>
<p><strong>Key passes:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">TritonGPUCoalesce</span></code> - Optimize memory access patterns</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TritonGPUPipeline</span></code> - Overlap computation and memory transfers</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TritonGPUPrefetch</span></code> - Insert prefetch instructions</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TritonGPUAccelerateMatmul</span></code> - Use tensor cores for matmul</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TritonGPURemoveLayoutConversions</span></code> - Eliminate redundant layout changes</p></li>
</ul>
<p>MLIR in Triton</p>
</section>
</section>
<section id="why-triton-uses-mlir">
<h1>Why Triton Uses MLIR<a class="headerlink" href="#why-triton-uses-mlir" title="Link to this heading">ïƒ</a></h1>
<ol class="arabic simple">
<li><p><strong>Multi-level representation</strong></p>
<ul class="simple">
<li><p>TTIR: High-level block operations</p></li>
<li><p>TTGIR: GPU-specific with layouts</p></li>
<li><p>LLVM IR: Low-level machine operations</p></li>
</ul>
</li>
<li><p><strong>Reusable infrastructure</strong></p>
<ul class="simple">
<li><p>Donâ€™t reinvent parsing, printing, pass management</p></li>
<li><p>Use existing dialects (arith, scf, llvm)</p></li>
<li><p>Benefit from MLIR community improvements</p></li>
</ul>
</li>
<li><p><strong>Extensibility</strong></p>
<ul class="simple">
<li><p>Easy to add new operations (TableGen)</p></li>
<li><p>Define custom types and attributes</p></li>
<li><p>Write dialect-specific passes</p></li>
</ul>
</li>
<li><p><strong>Multi-backend support</strong></p>
<ul class="simple">
<li><p>Same TTIR can target NVIDIA (NVPTX) or AMD (AMDGCN)</p></li>
<li><p>Backend-specific dialects (ttng for NVIDIA, ttag for AMD)</p></li>
</ul>
</li>
</ol>
</section>
<section id="triton-s-mlir-dialects">
<h1>Tritonâ€™s MLIR Dialects<a class="headerlink" href="#triton-s-mlir-dialects" title="Link to this heading">ïƒ</a></h1>
<section id="triton-dialect-tt">
<h2>Triton Dialect (tt)<a class="headerlink" href="#triton-dialect-tt" title="Link to this heading">ïƒ</a></h2>
<p><em>Location:</em> <a class="reference external" href="https://github.com/triton-lang/triton/tree/v3.5.1/lib/Dialect/Triton">lib/Dialect/Triton/</a></p>
<p><strong>High-level operations, backend-agnostic.</strong></p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>// Get block ID
%pid = tt.get_program_id x : i32

// Create range
%range = tt.make_range {start = 0 : i32, end = 128 : i32}
    : tensor&lt;128xi32&gt;

// Broadcast scalar to tensor
%splat = tt.splat %value : i32 -&gt; tensor&lt;128xi32&gt;

// Pointer arithmetic
%ptrs = tt.addptr %base_ptr, %offsets
    : tensor&lt;128x!tt.ptr&lt;f32&gt;&gt;, tensor&lt;128xi32&gt;

// Load from memory
%data = tt.load %ptrs, %mask, %other
    : tensor&lt;128x!tt.ptr&lt;f32&gt;&gt;

// Store to memory
tt.store %ptrs, %data, %mask : tensor&lt;128x!tt.ptr&lt;f32&gt;&gt;

// Matrix multiplication (conceptual)
%c = tt.dot %a, %b, %acc
    : tensor&lt;128x64xf16&gt; * tensor&lt;64x128xf16&gt; -&gt; tensor&lt;128x128xf32&gt;
</pre></div>
</div>
</section>
<section id="tritongpu-dialect-ttg">
<h2>TritonGPU Dialect (ttg)<a class="headerlink" href="#tritongpu-dialect-ttg" title="Link to this heading">ïƒ</a></h2>
<p><em>Location:</em> <a class="reference external" href="https://github.com/triton-lang/triton/tree/v3.5.1/lib/Dialect/TritonGPU">lib/Dialect/TritonGPU/</a></p>
<p><strong>GPU-specific operations with data layout information.</strong></p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>// Define layout encoding
#blocked = #ttg.blocked&lt;{
    sizePerThread = [1, 4],
    threadsPerWarp = [2, 16],
    warpsPerCTA = [4, 1]
}&gt;

// Tensor with layout
%data : tensor&lt;128x128xf32, #blocked&gt;

// Convert between layouts
%new_data = ttg.convert_layout %data
    : tensor&lt;128x128xf32, #blocked1&gt; -&gt; tensor&lt;128x128xf32, #blocked2&gt;

// Allocate shared memory
%smem = ttg.alloc_tensor : tensor&lt;128x128xf32, #shared&gt;

// Insert barrier
ttg.barrier

// Async operations (for pipelining)
%token = ttg.async_commit_group
ttg.async_wait {num = 0 : i32}
</pre></div>
</div>
</section>
<section id="tritonnvidiagpu-dialect-ttng">
<h2>TritonNvidiaGPU Dialect (ttng)<a class="headerlink" href="#tritonnvidiagpu-dialect-ttng" title="Link to this heading">ïƒ</a></h2>
<p><em>Location:</em> <a class="reference external" href="https://github.com/triton-lang/triton/tree/v3.5.1/lib/Dialect/TritonNvidiaGPU">lib/Dialect/TritonNvidiaGPU/</a></p>
<p><strong>NVIDIA-specific operations (Hopper+, tensor cores, TMA).</strong></p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>// Warp group dot (Hopper tensor cores)
%c = ttng.warp_group_dot %a, %b, %acc
    : tensor&lt;64x64xf16&gt; * tensor&lt;64x64xf16&gt; -&gt; tensor&lt;64x64xf32&gt;

// Tensor Memory Accelerator (TMA) load
%data = ttng.tma_load %desc, %coords
    : !ttng.tma_descriptor -&gt; tensor&lt;128x128xf16&gt;

// Distributed shared memory (Hopper)
%smem = ttng.alloc_dsmem : tensor&lt;128x128xf32, #ttng.dsmem&gt;
</pre></div>
</div>
<p>Example: Lowering Through Dialects</p>
<p>Letâ€™s trace a simple operation through all dialects.</p>
</section>
</section>
<section id="python-source">
<h1>Python Source<a class="headerlink" href="#python-source" title="Link to this heading">ïƒ</a></h1>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@triton</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">add_kernel</span><span class="p">(</span><span class="n">x_ptr</span><span class="p">,</span> <span class="n">y_ptr</span><span class="p">,</span> <span class="n">out_ptr</span><span class="p">,</span> <span class="n">N</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">):</span>
    <span class="n">offs</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">x_ptr</span> <span class="o">+</span> <span class="n">offs</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">y_ptr</span> <span class="o">+</span> <span class="n">offs</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
    <span class="n">tl</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="n">out_ptr</span> <span class="o">+</span> <span class="n">offs</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="stage-1-triton-ir-ttir">
<h1>Stage 1: Triton IR (TTIR)<a class="headerlink" href="#stage-1-triton-ir-ttir" title="Link to this heading">ïƒ</a></h1>
<p><strong>Backend-agnostic, high-level block operations.</strong></p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>module {
  tt.func @add_kernel(%x_ptr: !tt.ptr&lt;f32&gt;,
                      %y_ptr: !tt.ptr&lt;f32&gt;,
                      %out_ptr: !tt.ptr&lt;f32&gt;) {
    // Create range [0, 128)
    %range = tt.make_range {start = 0, end = 128} : tensor&lt;128xi32&gt;

    // Broadcast base pointers to tensors
    %x_ptr_splat = tt.splat %x_ptr : !tt.ptr&lt;f32&gt; -&gt; tensor&lt;128x!tt.ptr&lt;f32&gt;&gt;
    %y_ptr_splat = tt.splat %y_ptr : !tt.ptr&lt;f32&gt; -&gt; tensor&lt;128x!tt.ptr&lt;f32&gt;&gt;
    %out_ptr_splat = tt.splat %out_ptr : !tt.ptr&lt;f32&gt; -&gt; tensor&lt;128x!tt.ptr&lt;f32&gt;&gt;

    // Compute pointer offsets
    %x_ptrs = tt.addptr %x_ptr_splat, %range : tensor&lt;128x!tt.ptr&lt;f32&gt;&gt;
    %y_ptrs = tt.addptr %y_ptr_splat, %range : tensor&lt;128x!tt.ptr&lt;f32&gt;&gt;
    %out_ptrs = tt.addptr %out_ptr_splat, %range : tensor&lt;128x!tt.ptr&lt;f32&gt;&gt;

    // Load data
    %x = tt.load %x_ptrs : tensor&lt;128xf32&gt;
    %y = tt.load %y_ptrs : tensor&lt;128xf32&gt;

    // Compute
    %out = arith.addf %x, %y : tensor&lt;128xf32&gt;

    // Store result
    tt.store %out_ptrs, %out : tensor&lt;128xf32&gt;

    tt.return
  }
}
</pre></div>
</div>
<p><strong>Notice:</strong></p>
<ul class="simple">
<li><p>No layout information yet</p></li>
<li><p>No GPU-specific operations</p></li>
<li><p>Pure block-level semantics</p></li>
</ul>
</section>
<section id="stage-2-tritongpu-ir-ttgir">
<h1>Stage 2: TritonGPU IR (TTGIR)<a class="headerlink" href="#stage-2-tritongpu-ir-ttgir" title="Link to this heading">ïƒ</a></h1>
<p><strong>Add GPU layout information.</strong></p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>#blocked = #ttg.blocked&lt;{
    sizePerThread = [4],
    threadsPerWarp = [32],
    warpsPerCTA = [1]
}&gt;

module {
  tt.func @add_kernel(%x_ptr: !tt.ptr&lt;f32&gt;,
                      %y_ptr: !tt.ptr&lt;f32&gt;,
                      %out_ptr: !tt.ptr&lt;f32&gt;) {
    // Range with layout
    %range = tt.make_range {start = 0, end = 128}
        : tensor&lt;128xi32, #blocked&gt;

    // Pointers with layout
    %x_ptrs = tt.addptr %x_ptr_splat, %range
        : tensor&lt;128x!tt.ptr&lt;f32&gt;, #blocked&gt;

    // Load with layout (coalesced access)
    %x = tt.load %x_ptrs
        : tensor&lt;128xf32, #blocked&gt;
    %y = tt.load %y_ptrs
        : tensor&lt;128xf32, #blocked&gt;

    // Compute with layout
    %out = arith.addf %x, %y
        : tensor&lt;128xf32, #blocked&gt;

    // Store with layout
    tt.store %out_ptrs, %out
        : tensor&lt;128xf32, #blocked&gt;

    tt.return
  }
}
</pre></div>
</div>
<p><strong>Notice:</strong></p>
<ul class="simple">
<li><p>Layout attributes added (<code class="docutils literal notranslate"><span class="pre">#blocked</span></code>)</p></li>
<li><p>Specifies data distribution across threads</p></li>
<li><p>Enables memory coalescing optimizations</p></li>
</ul>
</section>
<section id="stage-3-llvm-dialect">
<h1>Stage 3: LLVM Dialect<a class="headerlink" href="#stage-3-llvm-dialect" title="Link to this heading">ïƒ</a></h1>
<p><strong>Lowered to LLVM IR (within MLIR).</strong></p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>module {
  llvm.func @add_kernel(%x_ptr: !llvm.ptr&lt;f32&gt;,
                        %y_ptr: !llvm.ptr&lt;f32&gt;,
                        %out_ptr: !llvm.ptr&lt;f32&gt;) {
    // Get thread ID
    %tid = llvm.call @llvm.nvvm.read.ptx.sreg.tid.x()
        : () -&gt; i32

    // Each thread handles 4 elements (sizePerThread = 4)
    %c0 = llvm.mlir.constant(0 : i32) : i32
    %c4 = llvm.mlir.constant(4 : i32) : i32

    // Loop over thread&#39;s elements
    llvm.br ^loop(%c0 : i32)

  ^loop(%i: i32):
    %cond = llvm.icmp &quot;slt&quot; %i, %c4 : i32
    llvm.cond_br %cond, ^body, ^exit

  ^body:
    // Calculate global offset
    %offset = llvm.add %tid, %i : i32

    // Load x[offset]
    %x_gep = llvm.getelementptr %x_ptr[%offset]
        : (!llvm.ptr&lt;f32&gt;, i32) -&gt; !llvm.ptr&lt;f32&gt;
    %x_val = llvm.load %x_gep : !llvm.ptr&lt;f32&gt;

    // Load y[offset]
    %y_gep = llvm.getelementptr %y_ptr[%offset]
        : (!llvm.ptr&lt;f32&gt;, i32) -&gt; !llvm.ptr&lt;f32&gt;
    %y_val = llvm.load %y_gep : !llvm.ptr&lt;f32&gt;

    // Compute
    %sum = llvm.fadd %x_val, %y_val : f32

    // Store out[offset]
    %out_gep = llvm.getelementptr %out_ptr[%offset]
        : (!llvm.ptr&lt;f32&gt;, i32) -&gt; !llvm.ptr&lt;f32&gt;
    llvm.store %sum, %out_gep : !llvm.ptr&lt;f32&gt;

    %i_next = llvm.add %i, %c1 : i32
    llvm.br ^loop(%i_next : i32)

  ^exit:
    llvm.return
  }
}
</pre></div>
</div>
<p><strong>Notice:</strong></p>
<ul class="simple">
<li><p>Explicit thread indexing (<code class="docutils literal notranslate"><span class="pre">tid.x</span></code>)</p></li>
<li><p>Loop over per-thread elements</p></li>
<li><p>Individual memory operations</p></li>
<li><p>NVVM intrinsics for GPU built-ins</p></li>
</ul>
</section>
<section id="stage-4-llvm-ir-actual">
<h1>Stage 4: LLVM IR (Actual)<a class="headerlink" href="#stage-4-llvm-ir-actual" title="Link to this heading">ïƒ</a></h1>
<p><strong>Translated from LLVM dialect to actual LLVM IR.</strong></p>
<div class="highlight-llvm notranslate"><div class="highlight"><pre><span></span><span class="k">define</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@add_kernel</span><span class="p">(</span><span class="kt">float</span><span class="p">*</span><span class="w"> </span><span class="nv">%x_ptr</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">*</span><span class="w"> </span><span class="nv">%y_ptr</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">*</span><span class="w"> </span><span class="nv">%out_ptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="nl">entry:</span>
<span class="w">  </span><span class="nv">%tid</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">call</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="vg">@llvm.nvvm.read.ptx.sreg.tid.x</span><span class="p">()</span>
<span class="w">  </span><span class="k">br</span><span class="w"> </span><span class="kt">label</span><span class="w"> </span><span class="nv">%loop</span>

<span class="nl">loop:</span>
<span class="w">  </span><span class="nv">%i</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">phi</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="nv">%entry</span><span class="w"> </span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="nv">%i.next</span><span class="p">,</span><span class="w"> </span><span class="nv">%body</span><span class="w"> </span><span class="p">]</span>
<span class="w">  </span><span class="nv">%cond</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">icmp</span><span class="w"> </span><span class="k">slt</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%i</span><span class="p">,</span><span class="w"> </span><span class="m">4</span>
<span class="w">  </span><span class="k">br</span><span class="w"> </span><span class="kt">i1</span><span class="w"> </span><span class="nv">%cond</span><span class="p">,</span><span class="w"> </span><span class="kt">label</span><span class="w"> </span><span class="nv">%body</span><span class="p">,</span><span class="w"> </span><span class="kt">label</span><span class="w"> </span><span class="nv">%exit</span>

<span class="nl">body:</span>
<span class="w">  </span><span class="nv">%offset</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">add</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%tid</span><span class="p">,</span><span class="w"> </span><span class="nv">%i</span>

<span class="w">  </span><span class="nv">%x_gep</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">getelementptr</span><span class="w"> </span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">*</span><span class="w"> </span><span class="nv">%x_ptr</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%offset</span>
<span class="w">  </span><span class="nv">%x_val</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">load</span><span class="w"> </span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">*</span><span class="w"> </span><span class="nv">%x_gep</span><span class="p">,</span><span class="w"> </span><span class="k">align</span><span class="w"> </span><span class="m">4</span>

<span class="w">  </span><span class="nv">%y_gep</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">getelementptr</span><span class="w"> </span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">*</span><span class="w"> </span><span class="nv">%y_ptr</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%offset</span>
<span class="w">  </span><span class="nv">%y_val</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">load</span><span class="w"> </span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">*</span><span class="w"> </span><span class="nv">%y_gep</span><span class="p">,</span><span class="w"> </span><span class="k">align</span><span class="w"> </span><span class="m">4</span>

<span class="w">  </span><span class="nv">%sum</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">fadd</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="nv">%x_val</span><span class="p">,</span><span class="w"> </span><span class="nv">%y_val</span>

<span class="w">  </span><span class="nv">%out_gep</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">getelementptr</span><span class="w"> </span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">*</span><span class="w"> </span><span class="nv">%out_ptr</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%offset</span>
<span class="w">  </span><span class="k">store</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="nv">%sum</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">*</span><span class="w"> </span><span class="nv">%out_gep</span><span class="p">,</span><span class="w"> </span><span class="k">align</span><span class="w"> </span><span class="m">4</span>

<span class="w">  </span><span class="nv">%i.next</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">add</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%i</span><span class="p">,</span><span class="w"> </span><span class="m">1</span>
<span class="w">  </span><span class="k">br</span><span class="w"> </span><span class="kt">label</span><span class="w"> </span><span class="nv">%loop</span>

<span class="nl">exit:</span>
<span class="w">  </span><span class="k">ret</span><span class="w"> </span><span class="k">void</span>
<span class="p">}</span>

<span class="k">declare</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="vg">@llvm.nvvm.read.ptx.sreg.tid.x</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>This is standard LLVM IR</strong> that the NVPTX backend can compile to PTX.</p>
<p>MLIR Tools and Ecosystem</p>
</section>
<section id="command-line-tools">
<h1>Command-Line Tools<a class="headerlink" href="#command-line-tools" title="Link to this heading">ïƒ</a></h1>
<p><strong>mlir-opt</strong> - Optimize and transform MLIR</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run canonicalization pass</span>
mlir-opt<span class="w"> </span>--canonicalize<span class="w"> </span>input.mlir<span class="w"> </span>-o<span class="w"> </span>output.mlir

<span class="c1"># Run custom pass</span>
mlir-opt<span class="w"> </span>--triton-gpu-pipeline<span class="w"> </span>input.mlir

<span class="c1"># Lower to LLVM dialect</span>
mlir-opt<span class="w"> </span>--convert-triton-to-llvm<span class="w"> </span>input.mlir
</pre></div>
</div>
<p><strong>mlir-translate</strong> - Translate between MLIR and other formats</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># MLIR -&gt; LLVM IR</span>
mlir-translate<span class="w"> </span>--mlir-to-llvmir<span class="w"> </span>input.mlir<span class="w"> </span>-o<span class="w"> </span>output.ll

<span class="c1"># LLVM IR -&gt; MLIR</span>
mlir-translate<span class="w"> </span>--import-llvm<span class="w"> </span>input.ll<span class="w"> </span>-o<span class="w"> </span>output.mlir
</pre></div>
</div>
<p><strong>mlir-cpu-runner</strong> - JIT execute MLIR on CPU</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mlir-cpu-runner<span class="w"> </span>input.mlir<span class="w"> </span>--entry-point<span class="o">=</span>main
</pre></div>
</div>
</section>
<section id="tablegen-for-defining-operations">
<h1>TableGen for Defining Operations<a class="headerlink" href="#tablegen-for-defining-operations" title="Link to this heading">ïƒ</a></h1>
<p><strong>TableGen</strong> is a domain-specific language for defining MLIR operations.</p>
<p><em>Example from Triton:</em> <a class="reference external" href="https://github.com/triton-lang/triton/tree/v3.5.1/include/triton/Dialect/Triton/IR/TritonOps.td">TritonOps.td</a></p>
<div class="highlight-tablegen notranslate"><div class="highlight"><pre><span></span><span class="c c-SingleLine">// Define tt.load operation</span>
<span class="k">def</span><span class="w"> </span><span class="n">TT_LoadOp</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">TT_Op</span><span class="p">&lt;</span><span class="s">&quot;load&quot;</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">MemoryEffects</span><span class="p">&lt;[</span><span class="n">MemRead</span><span class="p">]&gt;]&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">let</span><span class="w"> </span><span class="n">summary</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Load from memory&quot;</span><span class="p">;</span>

<span class="w">  </span><span class="k">let</span><span class="w"> </span><span class="n">arguments</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="p">(</span><span class="n">ins</span>
<span class="w">    </span><span class="n">TT_PtrLike</span><span class="p">:</span><span class="nv">$ptr</span><span class="p">,</span><span class="w">        </span><span class="c c-SingleLine">// Pointer operand</span>
<span class="w">    </span><span class="n">Optional</span><span class="p">&lt;</span><span class="n">I1Tensor</span><span class="p">&gt;:</span><span class="nv">$mask</span><span class="p">,</span><span class="w">  </span><span class="c c-SingleLine">// Optional mask</span>
<span class="w">    </span><span class="n">Optional</span><span class="p">&lt;</span><span class="n">AnyType</span><span class="p">&gt;:</span><span class="nv">$other</span><span class="w">   </span><span class="c c-SingleLine">// Optional default value</span>
<span class="w">  </span><span class="p">);</span>

<span class="w">  </span><span class="k">let</span><span class="w"> </span><span class="n">results</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="p">(</span><span class="n">outs</span>
<span class="w">    </span><span class="n">AnyType</span><span class="p">:</span><span class="nv">$result</span><span class="w">           </span><span class="c c-SingleLine">// Loaded data</span>
<span class="w">  </span><span class="p">);</span>

<span class="w">  </span><span class="k">let</span><span class="w"> </span><span class="n">assemblyFormat</span><span class="w"> </span><span class="p">=</span><span class="w"> </span>[{
<span class="w">    </span><span class="n">$ptr</span><span class="w"> </span><span class="p">(</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="w"> </span><span class="n">$mask</span><span class="o">^</span><span class="w"> </span><span class="p">(</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="w"> </span><span class="n">$other</span><span class="o">^</span><span class="p">)</span><span class="o">?</span><span class="p">)</span><span class="o">?</span><span class="w"> </span><span class="n">attr</span><span class="o">-</span><span class="n">dict</span><span class="w"> </span><span class="err">`</span><span class="o">:</span><span class="err">`</span><span class="w"> </span><span class="n">type</span><span class="p">(</span><span class="n">$result</span><span class="p">)</span>
<span class="w">  </span>}]<span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>TableGen generates:</strong></p>
<ul class="simple">
<li><p>C++ class for the operation</p></li>
<li><p>Parsing and printing code</p></li>
<li><p>Type inference</p></li>
<li><p>Verification</p></li>
</ul>
</section>
<section id="debugging-mlir">
<h1>Debugging MLIR<a class="headerlink" href="#debugging-mlir" title="Link to this heading">ïƒ</a></h1>
<p><strong>Print IR at each stage:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set environment variable</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">MLIR_ENABLE_DUMP</span><span class="o">=</span><span class="m">1</span>

<span class="c1"># Triton will dump IR at each pass</span>
python<span class="w"> </span>kernel.py
</pre></div>
</div>
<p><strong>Use ``â€“debug`` flag:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mlir-opt<span class="w"> </span>--debug<span class="w"> </span>input.mlir
</pre></div>
</div>
<p><strong>Print specific pass output:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># In Python</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">triton</span>

<span class="nd">@triton</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kernel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="c1"># Compile with debug</span>
<span class="n">kernel</span><span class="p">[</span><span class="n">grid</span><span class="p">](</span><span class="o">...</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>MLIR Resources</p>
</section>
<section id="official-documentation">
<h1>Official Documentation<a class="headerlink" href="#official-documentation" title="Link to this heading">ïƒ</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://mlir.llvm.org/">MLIR Website</a> - Official documentation</p></li>
<li><p><a class="reference external" href="https://mlir.llvm.org/docs/Dialects/">MLIR Dialects</a> - Built-in dialects</p></li>
<li><p><a class="reference external" href="https://mlir.llvm.org/docs/LangRef/">MLIR Language Reference</a> - Syntax and semantics</p></li>
<li><p><a class="reference external" href="https://mlir.llvm.org/docs/OpDefinitions/">TableGen Reference</a> - Defining operations</p></li>
</ul>
</section>
<section id="tutorials">
<h1>Tutorials<a class="headerlink" href="#tutorials" title="Link to this heading">ïƒ</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://mlir.llvm.org/docs/Tutorials/Toy/">MLIR Toy Tutorial</a> - Build a compiler from scratch</p></li>
<li><p><a class="reference external" href="https://mlir.llvm.org/talks/">MLIR Talks</a> - Conference presentations</p></li>
<li><p><a class="reference external" href="https://discourse.llvm.org/c/mlir/">MLIR Community</a> - Discussion forum</p></li>
</ul>
</section>
<section id="triton-specific">
<h1>Triton-Specific<a class="headerlink" href="#triton-specific" title="Link to this heading">ïƒ</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/triton-lang/triton/tree/v3.5.1/include/triton/Dialect">Triton MLIR Dialects</a> - Operation definitions</p></li>
<li><p><a class="reference external" href="https://github.com/triton-lang/triton/tree/v3.5.1/lib/Dialect/TritonGPU/Transforms">Triton Passes</a> - Transformation passes</p></li>
<li><p><a class="reference external" href="https://github.com/triton-lang/triton/tree/v3.5.1/test/Triton">Triton IR Examples</a> - Test cases with IR</p></li>
</ul>
</section>
<section id="key-concepts-recap">
<h1>Key Concepts Recap<a class="headerlink" href="#key-concepts-recap" title="Link to this heading">ïƒ</a></h1>
<ol class="arabic simple">
<li><p><strong>MLIR = Multi-Level Intermediate Representation</strong></p>
<ul class="simple">
<li><p>Multiple dialects coexist</p></li>
<li><p>Gradual lowering preserves semantics</p></li>
<li><p>Reusable infrastructure</p></li>
</ul>
</li>
<li><p><strong>Dialects</strong> - Namespaces for operations, types, attributes</p>
<ul class="simple">
<li><p>Triton has <code class="docutils literal notranslate"><span class="pre">tt</span></code>, <code class="docutils literal notranslate"><span class="pre">ttg</span></code>, <code class="docutils literal notranslate"><span class="pre">ttng</span></code> dialects</p></li>
<li><p>Standard dialects: <code class="docutils literal notranslate"><span class="pre">arith</span></code>, <code class="docutils literal notranslate"><span class="pre">scf</span></code>, <code class="docutils literal notranslate"><span class="pre">llvm</span></code></p></li>
</ul>
</li>
<li><p><strong>Operations</strong> - Fundamental computation units</p>
<ul class="simple">
<li><p>SSA form (single assignment)</p></li>
<li><p>Have operands, results, attributes, types</p></li>
</ul>
</li>
<li><p><strong>Types</strong> - Flexible type system</p>
<ul class="simple">
<li><p>Built-in: integers, floats, tensors</p></li>
<li><p>Custom: Triton pointers, layouts</p></li>
</ul>
</li>
<li><p><strong>Passes</strong> - IR transformations</p>
<ul class="simple">
<li><p>Analysis, optimization, lowering</p></li>
<li><p>Triton has GPU-specific passes</p></li>
</ul>
</li>
</ol>
</section>
<section id="why-mlir-matters-for-triton">
<h1>Why MLIR Matters for Triton<a class="headerlink" href="#why-mlir-matters-for-triton" title="Link to this heading">ïƒ</a></h1>
<p><strong>Without MLIR:</strong></p>
<ul class="simple">
<li><p>[[FAIL]] Would need to build entire compiler infrastructure</p></li>
<li><p>[[FAIL]] Hard to support multiple GPU vendors</p></li>
<li><p>[[FAIL]] Difficult to add new optimizations</p></li>
<li><p>[[FAIL]] Canâ€™t reuse existing tools and passes</p></li>
</ul>
<p><strong>With MLIR:</strong></p>
<ul class="simple">
<li><p>[[OK]] Reuse robust infrastructure (parsing, printing, pass management)</p></li>
<li><p>[[OK]] Easy multi-backend support (NVIDIA, AMD, Intel)</p></li>
<li><p>[[OK]] Modular, extensible design</p></li>
<li><p>[[OK]] Benefit from MLIR ecosystem improvements</p></li>
<li><p>[[OK]] Gradual lowering preserves optimization opportunities</p></li>
</ul>
</section>
<section id="the-big-picture">
<h1>The Big Picture<a class="headerlink" href="#the-big-picture" title="Link to this heading">ïƒ</a></h1>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Triton Compiler Pipeline:

Python AST
     down
[Code Generator] &lt;- Converts AST to MLIR
     down
TTIR (tt dialect) &lt;- High-level block operations
     down
[MLIR Passes] &lt;- Optimization, coalescing
     down
TTGIR (ttg dialect) &lt;- Add GPU layouts
     down
[MLIR Passes] &lt;- Pipelining, prefetch, tensor cores
     down
LLVM Dialect &lt;- Still MLIR, but LLVM operations
     down
[mlir-translate] &lt;- Convert MLIR -&gt; LLVM IR
     down
LLVM IR &lt;- Standard LLVM
     down
[NVPTX Backend] &lt;- LLVM&#39;s PTX generator
     down
PTX Assembly
</pre></div>
</div>
<p><strong>MLIR enables this multi-stage, optimizing pipeline</strong> with reusable, modular components.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="04-cuda-comparison.html" class="btn btn-neutral float-left" title="The NVCC Compiler" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../learning-paths.html" class="btn btn-neutral float-right" title="By Topic" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Fast Concurrent Programs.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>